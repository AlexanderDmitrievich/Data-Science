{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=.01)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "    \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "    \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "        \n",
    "        print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 7.245, train_loss: 1.7601350500228556, train_acc: 0.55265, test_loss: 1.2999123871326446, test_acc: 0.6515\n",
      "ep: 1, taked: 7.307, train_loss: 1.0789860649311795, train_acc: 0.6722333333333333, test_loss: 0.9449721798300743, test_acc: 0.6762\n",
      "ep: 2, taked: 7.467, train_loss: 0.863167611588823, train_acc: 0.7067333333333333, test_loss: 0.8167662739753723, test_acc: 0.7094\n",
      "ep: 3, taked: 7.517, train_loss: 0.7685404703972187, train_acc: 0.73855, test_loss: 0.7466320350766182, test_acc: 0.7354\n",
      "ep: 4, taked: 7.513, train_loss: 0.7104806555078385, train_acc: 0.7587333333333334, test_loss: 0.6989318527281284, test_acc: 0.7548\n",
      "ep: 5, taked: 8.195, train_loss: 0.6686997966563448, train_acc: 0.7739833333333334, test_loss: 0.663357450067997, test_acc: 0.7683\n",
      "ep: 6, taked: 7.545, train_loss: 0.6364650584281759, train_acc: 0.7869, test_loss: 0.6356029383838177, test_acc: 0.7789\n",
      "ep: 7, taked: 7.470, train_loss: 0.6106998621149266, train_acc: 0.7962666666666667, test_loss: 0.613337654620409, test_acc: 0.7876\n",
      "ep: 8, taked: 7.472, train_loss: 0.5896216250480489, train_acc: 0.8036666666666666, test_loss: 0.5951053000986576, test_acc: 0.7929\n",
      "ep: 9, taked: 7.491, train_loss: 0.5720774489514371, train_acc: 0.80965, test_loss: 0.5799091190099717, test_acc: 0.7984\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 7.924, train_loss: 0.587893165933325, train_acc: 0.8109666666666666, test_loss: 0.4391354352235794, test_acc: 0.8439\n",
      "ep: 1, taked: 7.693, train_loss: 0.3846598372814503, train_acc: 0.8601333333333333, test_loss: 0.4147147431969643, test_acc: 0.8501\n",
      "ep: 2, taked: 7.795, train_loss: 0.35326170122369804, train_acc: 0.8705666666666667, test_loss: 0.3897495724260807, test_acc: 0.8611\n",
      "ep: 3, taked: 7.855, train_loss: 0.3323100947953285, train_acc: 0.8774166666666666, test_loss: 0.37809828817844393, test_acc: 0.8651\n",
      "ep: 4, taked: 7.861, train_loss: 0.31795938534939544, train_acc: 0.8820166666666667, test_loss: 0.409425650909543, test_acc: 0.8578\n",
      "ep: 5, taked: 7.945, train_loss: 0.3078056680395248, train_acc: 0.8858833333333334, test_loss: 0.3740345239639282, test_acc: 0.8683\n",
      "ep: 6, taked: 7.800, train_loss: 0.29441306952466356, train_acc: 0.8896333333333334, test_loss: 0.3830126073211432, test_acc: 0.8687\n",
      "ep: 7, taked: 7.727, train_loss: 0.2880462475913636, train_acc: 0.8930333333333333, test_loss: 0.4000159535557032, test_acc: 0.8647\n",
      "ep: 8, taked: 7.705, train_loss: 0.2844200738566987, train_acc: 0.8945833333333333, test_loss: 0.42131521217525003, test_acc: 0.859\n",
      "ep: 9, taked: 7.639, train_loss: 0.2758668180475844, train_acc: 0.8974666666666666, test_loss: 0.38535947985947133, test_acc: 0.8681\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 9.239, train_loss: 0.5796468372040606, train_acc: 0.78615, test_loss: 0.4751006603240967, test_acc: 0.8228\n",
      "ep: 1, taked: 8.900, train_loss: 0.39172746558138666, train_acc: 0.85625, test_loss: 0.4041179705411196, test_acc: 0.8591\n",
      "ep: 2, taked: 8.877, train_loss: 0.35894011354192773, train_acc: 0.8677, test_loss: 0.4030242063105106, test_acc: 0.8621\n",
      "ep: 3, taked: 9.734, train_loss: 0.33736372482269367, train_acc: 0.8757, test_loss: 0.36005138978362083, test_acc: 0.8682\n",
      "ep: 4, taked: 9.627, train_loss: 0.31821161629037653, train_acc: 0.8836333333333334, test_loss: 0.38276813067495824, test_acc: 0.8572\n",
      "ep: 5, taked: 9.720, train_loss: 0.3124156154216604, train_acc: 0.8847, test_loss: 0.3977614603936672, test_acc: 0.8589\n",
      "ep: 6, taked: 9.798, train_loss: 0.29894380639208123, train_acc: 0.8893, test_loss: 0.3727261498570442, test_acc: 0.8699\n",
      "ep: 7, taked: 9.691, train_loss: 0.2987341870652868, train_acc: 0.8895, test_loss: 0.40575418025255205, test_acc: 0.8668\n",
      "ep: 8, taked: 9.682, train_loss: 0.2879855716482122, train_acc: 0.8933333333333333, test_loss: 0.4592601843178272, test_acc: 0.8594\n",
      "ep: 9, taked: 9.863, train_loss: 0.2846481264271635, train_acc: 0.8940166666666667, test_loss: 0.4171394743025303, test_acc: 0.8618\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 9.618, train_loss: 0.47627001290625715, train_acc: 0.82325, test_loss: 0.4551668807864189, test_acc: 0.829\n",
      "ep: 1, taked: 11.698, train_loss: 0.37274380871590146, train_acc: 0.8638666666666667, test_loss: 0.4183744054287672, test_acc: 0.8501\n",
      "ep: 2, taked: 9.800, train_loss: 0.3368694584420387, train_acc: 0.8759666666666667, test_loss: 0.382206367701292, test_acc: 0.8653\n",
      "ep: 3, taked: 9.577, train_loss: 0.3111954168436375, train_acc: 0.8855, test_loss: 0.38737270701676607, test_acc: 0.8645\n",
      "ep: 4, taked: 9.721, train_loss: 0.29096772512222857, train_acc: 0.8923833333333333, test_loss: 0.38593940418213607, test_acc: 0.8662\n",
      "ep: 5, taked: 9.459, train_loss: 0.2785996473215996, train_acc: 0.8956, test_loss: 0.3617354419082403, test_acc: 0.8678\n",
      "ep: 6, taked: 9.714, train_loss: 0.26541429276162004, train_acc: 0.90105, test_loss: 0.36743786111474036, test_acc: 0.8703\n",
      "ep: 7, taked: 9.695, train_loss: 0.2555426927957129, train_acc: 0.905, test_loss: 0.3914118766784668, test_acc: 0.8657\n",
      "ep: 8, taked: 9.779, train_loss: 0.25093830995103145, train_acc: 0.9069, test_loss: 0.3900684269145131, test_acc: 0.8665\n",
      "ep: 9, taked: 9.791, train_loss: 0.24097554119343453, train_acc: 0.9104333333333333, test_loss: 0.38334818966686723, test_acc: 0.8726\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 2560),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0,5),\n",
    "    torch.nn.Linear(2560, 1280),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0,5),\n",
    "    torch.nn.Linear(1280, 640),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0,5),\n",
    "    torch.nn.Linear(640, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 29.867, train_loss: 1.204211634524325, train_acc: 0.76635, test_loss: 0.47525575906038287, test_acc: 0.8249\n",
      "ep: 1, taked: 30.029, train_loss: 0.4079807149603012, train_acc: 0.8504833333333334, test_loss: 0.4303401470184326, test_acc: 0.8485\n",
      "ep: 2, taked: 30.790, train_loss: 0.3764487272247355, train_acc: 0.8627, test_loss: 0.43754935935139655, test_acc: 0.8493\n",
      "ep: 3, taked: 38.728, train_loss: 0.37185923926373743, train_acc: 0.86385, test_loss: 0.4115158535540104, test_acc: 0.8577\n",
      "ep: 4, taked: 42.269, train_loss: 0.35209068288194373, train_acc: 0.8705333333333334, test_loss: 0.3933768939226866, test_acc: 0.8613\n",
      "ep: 5, taked: 40.765, train_loss: 0.33385013119971496, train_acc: 0.8781, test_loss: 0.4096515320241451, test_acc: 0.856\n",
      "ep: 6, taked: 37.845, train_loss: 0.32761769776648664, train_acc: 0.87765, test_loss: 0.40887233018875124, test_acc: 0.8538\n",
      "ep: 7, taked: 37.922, train_loss: 0.33163515830293616, train_acc: 0.87745, test_loss: 0.4142324265092611, test_acc: 0.8586\n",
      "ep: 8, taked: 38.365, train_loss: 0.32219485469320985, train_acc: 0.8811833333333333, test_loss: 0.426961637288332, test_acc: 0.859\n",
      "ep: 9, taked: 38.619, train_loss: 0.31385978948562704, train_acc: 0.8838333333333334, test_loss: 0.4313775759190321, test_acc: 0.861\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 8.251, train_loss: 0.4644355477170741, train_acc: 0.8303666666666667, test_loss: 0.4350229226052761, test_acc: 0.8396\n",
      "ep: 1, taked: 7.841, train_loss: 0.3661520337804835, train_acc: 0.8664666666666667, test_loss: 0.40292198173701765, test_acc: 0.8529\n",
      "ep: 2, taked: 7.789, train_loss: 0.3361668385723804, train_acc: 0.8771666666666667, test_loss: 0.3995236875489354, test_acc: 0.8553\n",
      "ep: 3, taked: 7.894, train_loss: 0.3135426676019709, train_acc: 0.8852166666666667, test_loss: 0.4074003094807267, test_acc: 0.8486\n",
      "ep: 4, taked: 7.917, train_loss: 0.2955461283313467, train_acc: 0.8906833333333334, test_loss: 0.4066134406253695, test_acc: 0.8585\n",
      "ep: 5, taked: 7.927, train_loss: 0.28052983987838664, train_acc: 0.8959166666666667, test_loss: 0.41030587246641514, test_acc: 0.8504\n",
      "ep: 6, taked: 7.933, train_loss: 0.26484038823462547, train_acc: 0.9004, test_loss: 0.4403573803603649, test_acc: 0.8629\n",
      "ep: 7, taked: 7.950, train_loss: 0.2568029174145232, train_acc: 0.9036833333333333, test_loss: 0.3639631917700171, test_acc: 0.8715\n",
      "ep: 8, taked: 8.018, train_loss: 0.24608114304694723, train_acc: 0.9085666666666666, test_loss: 0.3840856280177832, test_acc: 0.867\n",
      "ep: 9, taked: 7.978, train_loss: 0.2386353849730593, train_acc: 0.9099666666666667, test_loss: 0.3615647127851844, test_acc: 0.8765\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 7.787, train_loss: 0.33952321422860976, train_acc: 0.8802333333333333, test_loss: 0.5620562620460987, test_acc: 0.8065\n",
      "ep: 1, taked: 8.028, train_loss: 0.25805019121220774, train_acc: 0.9038166666666667, test_loss: 0.5188459839671851, test_acc: 0.8221\n",
      "ep: 2, taked: 8.027, train_loss: 0.24104834325770114, train_acc: 0.9079833333333334, test_loss: 0.5447124138474464, test_acc: 0.833\n",
      "ep: 3, taked: 7.834, train_loss: 0.22624286102487687, train_acc: 0.91405, test_loss: 0.458222671598196, test_acc: 0.8695\n",
      "ep: 4, taked: 7.726, train_loss: 0.21904112512760973, train_acc: 0.9176666666666666, test_loss: 0.515175261721015, test_acc: 0.8383\n",
      "ep: 5, taked: 7.751, train_loss: 0.211131962182674, train_acc: 0.9197333333333333, test_loss: 0.5323040628805756, test_acc: 0.8457\n",
      "ep: 6, taked: 7.746, train_loss: 0.20312167425104913, train_acc: 0.9217666666666666, test_loss: 0.5364961341023445, test_acc: 0.8512\n",
      "ep: 7, taked: 7.786, train_loss: 0.19139417400385472, train_acc: 0.9273666666666667, test_loss: 0.5574457699432969, test_acc: 0.843\n",
      "ep: 8, taked: 7.735, train_loss: 0.18469446361699002, train_acc: 0.9293166666666667, test_loss: 0.5150592666119337, test_acc: 0.8537\n",
      "ep: 9, taked: 7.750, train_loss: 0.1784323997637059, train_acc: 0.93215, test_loss: 0.5703846834599972, test_acc: 0.8457\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.RMSprop(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 7.861, train_loss: 0.18784283531155993, train_acc: 0.9284833333333333, test_loss: 0.46616086848080157, test_acc: 0.8792\n",
      "ep: 1, taked: 7.679, train_loss: 0.17732520502932528, train_acc: 0.9325166666666667, test_loss: 0.4581877153366804, test_acc: 0.8808\n",
      "ep: 2, taked: 7.778, train_loss: 0.17235297186577575, train_acc: 0.9344, test_loss: 0.4530596468597651, test_acc: 0.8826\n",
      "ep: 3, taked: 7.719, train_loss: 0.1689288723500485, train_acc: 0.9356333333333333, test_loss: 0.44932129234075546, test_acc: 0.8828\n",
      "ep: 4, taked: 7.611, train_loss: 0.16631260125878009, train_acc: 0.9366, test_loss: 0.4464335225522518, test_acc: 0.8842\n",
      "ep: 5, taked: 7.575, train_loss: 0.16419577138855102, train_acc: 0.93735, test_loss: 0.4440814480185509, test_acc: 0.8845\n",
      "ep: 6, taked: 7.832, train_loss: 0.16243436672586076, train_acc: 0.9381, test_loss: 0.4421222865581512, test_acc: 0.8845\n",
      "ep: 7, taked: 7.875, train_loss: 0.16092378045333192, train_acc: 0.93865, test_loss: 0.4404309745877981, test_acc: 0.8846\n",
      "ep: 8, taked: 7.823, train_loss: 0.15960685988055898, train_acc: 0.9391666666666667, test_loss: 0.43892940394580365, test_acc: 0.8853\n",
      "ep: 9, taked: 7.796, train_loss: 0.15844721545247323, train_acc: 0.9395166666666667, test_loss: 0.43756303153932097, test_acc: 0.8858\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.SGD(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью оказалась модель со средним количеством слоев, SGD и BatchNorm. Удалось выйти на результат выше 88% как на обучающей, так и на тестовой выборке. При данных параметрах на обучающей выборке потери показывают лучший результат. На тестовой средний результат, однако переобучения вроде бы нет, так как результат с каждой эпохой падал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
