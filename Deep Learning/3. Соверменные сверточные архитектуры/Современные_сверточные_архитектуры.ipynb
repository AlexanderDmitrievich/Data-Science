{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание \"Современные сверточные архитектуры\"\n",
    "\n",
    "Задание 1: Возьмите датасет\n",
    "\n",
    "1.Обучите на нём модели ResNet 18 и VGG 16 с нуля (5-10 эпох)\n",
    "\n",
    "2.Обучите на нём модели ResNet 18 и VGG 16 с использованием fine-tuning (5-10 эпох)\n",
    "\n",
    "3.Добавьте аугментацию данных к пункту 2. Сравните качество всех 3 полученных подходов\n",
    "\n",
    "Задание 2* (дополнительное и необязательное):  Примените fine-tuning ResNet 18 к Fashion Mnist. Удалось ли увидеть резкое увеличение качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "! pip install torch-summary\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': tv.transforms.Compose([\n",
    "        tv.transforms.RandomResizedCrop(224),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': tv.transforms.Compose([\n",
    "        tv.transforms.Resize(256),\n",
    "        tv.transforms.CenterCrop(224),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BATCH_SIZE = 256\n",
    "data_dir = 'hymenoptera_data'\n",
    "image_datasets = {x: tv.datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAJ7oAAAEICAYAAABH3HRvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz8eZxleV0f/r8+99beVb3vy3TPvjMDM8wAAg7KLgJGEYmaEE3UmPwiiTHRrLjGRE0wMe4IrsimCAYBBYZ9BmaYAWbfunt636ura1/u+f3Rt78UY8/Q011N3ct9Ph+PeVBVp+rcd53zuu/P+Xw+RZeqqgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAED7qC12AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw9tcUuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgKenttgFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8PTUFrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnp7aYhcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA01Nb7AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB4empf7xtKKVUpZayU8otPcnxHKeXFC18araaUckspZfdi1wEsjFLKm0spf7LYdZyJUsrbSym/sNh18I3RfPa4ZLHr+GZQSrm1lPJPF7uOM9FOz5Qy2jlKKW8spXx6sevgG0PPPD/apWeWUrY1a+1a7Fo4/8yFOpNxvbMY18+PdhnX6Qzy2DmM4QunneY97bQn2U4Zbae5EOfOc+bCa6c+2g5kdOG1U0aN9edHO4311j0XTjtltNXpo+eHjC4cGT0/2imj7TTWc+7aac7U6jx70kraKY/23M8P60y0onZ6zmynPtrqzIXODxntLO0yrtMZ2iWPnjMXVjvNhVqdMbyztEvP5Ny107wHaH/ttEfeDtplvG6nOU47ZbSdxnBrl+dHO+1T8s2vnfLYTmtF7TLWtwMZhbPTTnnUMztHO82FWl07zdfbQTv1zFZnbn5+yOjCkdHOZI2TVmUuRCuRR1qJPNJK5HHhmOMAtJd2WpM0XtNK2iWP7bTX6G+D4ZuXnrnw9Mzzw17j+WGtCM5cO/XMVtdO4zrnzhhOqzIXWnjtNBeCVmAPqDO10zy8nTLKNz95pJXIY+cwx+ks7bQutNjPlM1rNXEm74/aGZ7zuqqq/mPz5NtKKTvOpcBz8XRev9kkbl2g1z3jwaUZgFuexnm3nUNpp85zxou8zc2Utz+N8775XGo7F0/n9ZvBf+MCvOYZDy7y+KTnaek8Pt0F3VJK9TTOu+Ocivvquc54IHk62X86eTgfFiOPZ+vpvP6ZZuQMznPGDzv648J5Oq//dHrWGZzrjBd0FyOPZ2sxeubZkNEzOldLZ7TVe+bZWoxxvTyNP7aSx4WlZy68xcro2TAXetJzmQuZC3297zWuP/V5jOuLxLi+8GT0Sc/T0j2zWD+Sxyf/XmP4U5+n5cfws7EY856zJaPnx2LMhYp9ykVhXD8/ZHThyOj5Yaw/P4z154c508IxZ1o4+uj5IaMLR0bPD2P91z2Pef0iWKw5U2nxv4c/W549T3ueW0qL7x/J48Ll8WzpmQvPs+fXPU/Lj+vF39J1ZB9t9XH9bMno+SGjpz1Pyz97no3FGteLv106J/LoOfMMv99c6KnPZb6uZ57ue/XMr38uY/giWIx5T2mDfUp5PDft0B9bfbwuLb7/eLbkceGY45wfxvDzw7zn/FiMuXlp8T0gz5mLZzHyeDaM9Wd0LhntwIyaH52bYn1dzzyz77V+tEA8Zy4cPXPhGMMXlufMhSejC0tGv+65Wnr96GzJ6Nc9T0s/exZ7ReZCT/698rhA5PFJzyOPi0Aen/Q88rgI5HFhmeOc9jxvLC2+dtnqedQfz11p8TWgYq9xURivz+hc+uM5aIf+eDYWK49nYzF65tlajIyeLc+UT3ouPfMc6Jl65tOhZ54fizEXOluL0UfP1mLMj4q1onNmXF8c8rhwFmNcL22wftTq/fFsGcO/7nlaumeaC3VmzzxbMvqk59pR7AGdtXYYw8+GnnlG52rpec/ZktGvey498xzomfL4FN8rjwtEHp/0PC2dx7NljvOk52rpPJ6tdn2mrKrqjUlecSY/VztfBQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHB+1BboPM8updxXSjlWSnlbKaXv1IFSyqtKKXeXUoZLKZ8tpTxj3rGNpZT3llIOlVK2l1L+1bxjN5VS7iiljJRSDpRS/ue5FllK+fVSyq7mOe8spbxg3rE3l1LeVUr5o1LKiVLKvaWUG5vH/jjJBUk+UEoZLaX8u1JKXynlT0opR5q/2xdKKevOsb7vKKXc1axvVynlzfOObSulVKWUf1xKebyUcriU8h+bx16e5D8keX2zvi81v/7GUspjzd9neynl+8+lvnm1/Ifm6++Yf85SSm8p5Veb9R0opfx2KaV/3vGnysK/L6Xsadb6YCnl28+xxotLKR9r3p/DpZQ/LaUsn3d8Rynl35ZSvlxKOV5KeWfzni5J8jdJNjav5Wgzp/LYYnkspawopfx1Odk/jjU/3jzv+K2llJ8vpXym+ZofKaWsbh7+ZPN/h5s1PreUckkp5RPNPBwupbzzXOpr1vDTpZRHm69/Xynlu+Yde2Mp5dPN98yx5jV5RfPYLyZ5QZLfaNb3G+Wk/1VKOdis8cullGvOtcYkfc38nyilfLGUct28Gp+qR9fm/X5Hmnld2Ty24HlsWl1K+dtmrZ8opWydV88VzWNHy8ke8r3zjj1pbyqlrG5mZ7j5s58qpZzT2FhK+SellPubdT5WSvnRecduKaXsLqX8ZPNe7iul/JPmsR9J8v1J/l3zvn+g+fWO649Nr2xev8OllF+Zf19KKT/UvMbHSikffhpZeGXzvXiieU3/7bkWWUp5dyllf/NafbKUcvW8Y28vpfzfUsr/a77m7aWUi5vHTvWhLzWv5evPRx6bLi6lfL5Z41+deq8263hOOTkmD5dSvlRKuWXesWWllLc2c7qnlPILpZR689iC98ymtnimbJLRDuiZXy2l/J/mNXxg/jmf6n3SPH7aLJSTFnRcb2b9c837s6+cfH7omXe8KqX8WCnl4WY9/7dZx5VJfjvJc5vXcrj5/R2XxyY9s4N7ZtMPlVL2Nu/lT857vSd9/m0ef6p8mAuZC50rcyHjunH97BjXO3hcb/WMlhbvmcX6kTx+9dii5/GrpRjDFyKPTS0/75l33pbfk/zqaVs/o01tMRcq9ik9Z7bouN7U8n1URmW01TM677zG+g4d65use3ZYRos5kz4qozL61a/L6Nlri7G+mNd31JyptPjfwzd59uyQ/SN5tOdeWrxnNlln6rBxvfhbuo7so6XFx/WvlmIuJKOtmdHSBs+eTW0xrhd/uySPLZTHJs+ZHTYXKubreuZXj+uZT0MxhnfMvKe0wT6lPH7z98fS4uN1afH9x3m1tPweeTvksaktxuumlp/jzDtvy2f0q6dt/TG8ydplB+9TlhbfAyqeMzsqj01tsVbU1BZjvYx2ZkaL+ZH19RbKY5Oe2QHrR18tpfXnQqUNnjObWn6+XvTMjhrDm8zNZVRGOyyjpcXXj5qscXbYs2exV2Qu9NVj8njm5FEe5fFpkkd5lMenzRynQ9YuWz2PRX/8pl8DKvYaO2pNssl4rT+2RH9saos8NrX8XuO88/rbYM+UeubTq0/P1DP1THuNLb3X2GStyLhuXH9aZbZ+z2yHPDa1/Lhe2mD9qLR4f2wyhndYzyzmQh3ZM+edt+XnQu2Q0WIP6Jt+DG+yB9Rh856mtpiHN7VFRoueqWfK49OpTx4Xhjx2QB7n1WKO0wF5bGqLdaGm9nimrKrqKf9LUiW55CmO70hyT5ItSVYm+UySX2gee1aSg0luTlJP8o+b39+bpJbkziT/JUlPkouSPJbkZc2f/VySH2x+PJjkOV+v1jP4XX4gyaokXUl+Msn+JH3NY29OMpnklc1a/1uS257we7543uc/muQDSQaa339DkqXnWN8tSa5tXptnJDmQ5LXNY9ua9+L3kvQnuS7JVJIr59X/J/POtSTJSJLLm59vSHL1AtQ3m+R/Nu/htyYZm/cab0ny/mYOhprX57+dQRYuT7IrycZ5v+vF51jrJUle0jz/mpx8CHnLE+7n55NsbNZ7f5Ifm/d77n7C+eSx9fK4Ksl3N3/noSTvTvK+ecdvTfJoksuaNd6a5JefUH/XvO9/R5L/2Px9+5I8fwHu8euaGasleX1Ovl82NI+9MclMkn/WvGf/PMneJGVe/f903rlelpM9c3mSkuTKU+c6h/re3Kzhe5J0J/m3SbY3P/56PfpNSW5Lsjkn32e/k+Qd5zGPb09yIskLm6/360k+PS9fu5L8k5x8Pz0ryeFTGctT96b/lpMbr93N/15w6h6cQ63fkeTi5n361iTjSZ417301m+Tnmq/3yubxFfN+z1+Yd65O7Y9Vko83X/+CJA+l+X5I8tokjzTfA11J/lOSz55hFvYleUHz4xWn7ss51vpDzVz1NrN29xNyezTJTc16/jTJnz/h97xk3ufnI4+3JtmT5Jrm9Xlvmv05yaYkR5o5rDVzcSTJmubx9+Xke3tJkrXNXPxo89j56Jk70j7PlDLaOT3zjc0a/nWzhtcnOZ5k5Rm8T54qC+djXL8hyXOar7UtJ/v3m55wP/+6+ZoXJDmU5OXzfs9PP+F8nZjHW6NndmzPzFfnCO9ovva1Ofk+eXHz+Jvy5M+/T5qPmAuZC5kLGdfPrlbjunHduP7Nn9FW75nWj+SxlfL4xhjDFySPaa95z6nstcOeZDtl9M1pn7nQLbFPedb1Nc+5I54zO7mPyqiMtnpGb4mxvtPH+rfHumcnZtScqdJHZVRGZfScan1z2mesvyXm9WddX/OcO9I+c6ZW/3v4t8ez56nsdsL+kTzac2/1nlnFOlMnjuv+lq4z+2irj+tvjLmQjLZ2Rtvh2bMtxvXmefztkjy2RB7jObOT50Lm63qmnnl2tRrDz62+N6Z95j0tvU8pjx3TH1t9vL4lrb3/eCpn7bBH3g55bIvxOu01x2mnjL4x7TOGvznWLjt9n7LV94A8Z3ZWHnekfdaK2mKsl9GOzqj50bnVZ319YfOoZ3bO+tEb0z5zoZZ+zkx7zdf1zKqjxvC3x9xcRmW0EzPa6utHb441zk589rRXVJkLyaM8yqM8yqM8ymNL5fHWmON0xNplm+RRfzz3e9zqa0C3xF7jud7jHWmfNUnjtf44P7eL3R/bIo9pr73GU9nzt8GeKfXMp1efnrlAeYyeqWfaa0ysFVkrOvdraFw/t/remPbpmS2dx7TXuN4O60et3h/fHGN4J/ZMc6GqI3vmqey1w1yoHTJqD+jc6muHMXxH7AF14rzn1rTPPLydMqpnnlt9eqY8yqM8yuOT12eO0zl5fHvaZ13o1izyM+XpcnPa7zuDX+ZrHsJPc3zHqbA2P39lkkebH/9Wkp9/wvc/mJNv1puTPP6EYz+T5G3Njz+Z5GeTrD7XcD9F7ceSXDcv5H8379hVSSaeIuQ/lOSzSZ5xHut7S5L/1fx4W/NebJ53/PNJvm9e/U9susM5OWj3L1A9t+Rk010y72vvSvKfc3IRdCzzmmWS5ybZfgZZuCQnG/KLk3Sfp2v52iR3PeF+/sC8z/9Hkt+e93s+senKY4vl8TT1XZ/k2LzPb03yn+Z9/uNJPvSE+uc/lP5Rkt+d/zudhxrvTvKa5sdvTPLIvGMDzZrWz6t//ubQt+XkYs9zktQWqJ4352sH81qaC0H5+j36/iTfPu/YhpzcaOo6H3nMyYeA+QtEg0nmcvKB//VJPvWE7/+dJP81X783/VySv8pTjHMLUPv7kvxE8+Nbkkw8IXsH03yQy9/fHOrI/th8L7x83uc/nuSjzY//JskPPyG340m2PlUWmh8/npMPqef0UPoUdS9v1r5s3v38/XnHX5nkgSf8nvMXOhc8j5k3IW9+flWS6Zx8QP/3Sf74Cd//4ZycGK3Lycld/7xjb0jy8ebHC94z00bPlDLaOT0zJ8fr/++PN5pf+3ySHzyD98lTZWHBx/XT1P6mJH/5hPv5/HmfvyvJT8/7PZ/4R0gdl8fomUkH98x8dY5wxbyv/Y8kb21+/FTPv0+VD3OhylzoHGt9e8yFjOvG9bOp6dYY1zt2XG+HjJ6mxvelhXrmaep7bawfyeMi5THG8I6c96SN9iTbKaNpo7nQaWp/S+xTPt2adsRzZsf2URmV0VbPaIz1HT/Wx7pnR2b0NLW/KeZMZ1vrLdFHZVRGOy6jaaOx/jS1vyXm9U+3ph1pkznTaWo/lhb6e/h49uyo/SN5tOfe/Lxle2asM3XkuH6aGu+Ov6U721rfnjbpo6ep/X1poXE95kIy2uIZPU19r02LPXumTcb109S9PP52SR49Z55N7denxZ4z00ZzodPUfizm6wtV+/uiZz7dmtqiZ56m7uUxhj/det6YNpn3nKb2N6WF9inl8bzU99q0WH88TY0tNV6fpr63pIX2H9NGe+TtkMe0yXidNprjtFNG00ZjeKxdJh2+T3ma2u9OC+0Bnaa+N8Vz5jdtHtNGa0Vpk7FeRjs3o6ep3fzo3Oq7PtbXz6VWPfM81Nd8jfelhdaP0kZzodPU/qa00HNm2mi+fprar4+euZDXs6XG8Jiby6iMdmRGT1P73Wmh9aNY4zwvGT1N7e9LCz17nqa+18Ze0ULVvTzmQvIoj/Ioj/Ioj/L49Gu6NeY4HbF22Q55PE2N74v+eK41HksLrQGdpr63xF7j061pR9pkTTLGa/3xa3Pr+fHM6tyWNtlrjL8N3hrPlImeuRD1vTZ65tnWuS16Zkf3zNhrTKwVPbH2u2Ot6FzqWx7j+tOt541pk57Z6nlMG43rp6n9+rTY+tFparw7LdQfYwxPOrBnnqa+18Zc6Gzr3JY26Zlpo7lQO2T0NDUeiz2gc6nv+rTYGB57QEkHznvSRvPwdsroaWrXM8+tvuujZ8qjPMqjPCbmOB2Vx7TRulBa4JnydLk53X+1LIxd8z7emWRj8+OtSX6ylDJ86r+cvGEbm8c2PuHYf2hehCT54SSXJXmglPKFUsqrzrXIUspPllLuL6Ucb77esiSr533L/nkfjyfpK6V0Pcnp/jgnb9yfl1L2llL+Ryml+xzru7mU8vFSyqFSyvEkP/aE+k5X4+DpzlVV1VhOvjF+LMm+Usr/K6VccS71NR1rnvuUU/d7TU4ubt85735+qPn15CmyUFXVIzm5SfLmJAdLKX9eStmYc1BKWds8z55SykiSP8lZXssmeWyxPJZSBkopv1NK2dm8x59MsryUUn+69TX9u5wcMD5fSrm3lPJD51Jfs8Z/VEq5e17mr8mT3OOqqsabHz7ZNfxYkt9I8n+THCil/G4pZem51ph5/buqqkaS3TmzHr01yV/OO3Z/Tg7K63Ie8niaWkeTHJ1X681PqPX7k6zP1+9Nv5LkkSQfKaU8Vkr56XMtspTyilLKbaWUo83Xe2W+9r4fqapqdt7nT/Xe6cj+2PRUzxa/Pu9+Hs3J9+6mPHUWkpMTkVcm2VlK+UQp5bnnUmAppV5K+eVSyqPNa7mjeeipevlTXcsFz2PTE69ld7PGrUle94Tr9fyc3MTa2vy+ffOO/U6Stc3zLHjPfJJaW/KZ8gxqldEzr7Gle2bTnqo5w2o6db+/3vvkSbNwPsb1UsplpZS/LqXsb97vX8q59feOy2OTntmhPfMMa32y598nzYe5kLlQMRcyrp8F47pxPcb1b/qMtnrPLNaP5LGF8thkDO+weU9TW+xJNrVFRpvaYi5U7FN6zmzBcf0Ma22JPiqjMvoUtbZERpuM9R081p+mVuue56YtMlrMmfTRv1+rjJ4dGe3QjDa1xVhfzOs7as5UWvzv4Zs8e3bI/pE82nOfV2tL9swzqPW0zxaxzvSk2mFcL/6WriP7aKuP603mQjLashlth2fPppYf14u/XZLHFsrjGdbqOfPpaYu5UDFf1zO/lp55BozhnTXvKS2+TymPndEfW328Li2+/9jUFnvk7ZDHppYfr8+w1paY4zS1RUab2mIMb7J22cH7lKXF94A8Z3ZWHp+k1pZcKzqDWltirJfRzs1oMT+yvt5CeTyDWvXMM6+xpdePmtpiLtTqz5nztPx8Xc/srDG8ydxcRmW0wzJaWnz9qMkaZ4c9exZ7ReZC8ng25FEeT5HHMyCP8hh5PBvmOB2wdtkOedQfv/nXgIq9xo5akzyDWo3XZ16j/rgwWj6PZ1hrS+w1NvnbYM+UO5qH9Mwzr0/P1DOfWKueeW7sNVorslZ09vUZ1zuoZ7Z6Hudp+XG9tMH6Uav3xyZjeIf1zGIu1JE9s6kt5kLtkNFiD+ibfgxvsgfUYfOepraYhz9JrS2ZUT1Tz4w8Pp365HFhyGMH5LHJHKdD8tjUFutCT6w1LfxMWTvXEzRtmffxBUn2Nj/eleQXq6paPu+/gaqq3tE8tv0Jx4aqqnplklRV9XBVVW/IyV/+vyd5TyllydkWWEp5QZJ/n+R7k6yoqmp5kuM5eUHPRPU1n1TVTFVVP1tV1VVJnpfkVUn+0dnW1/RnSd6fZEtVVcuS/PbZ1tes8cNVVb0kJ8P1QJLfO8f6kmTFE+7Dqft9OMlEkqvn3c9lVVWdamRPlYVUVfVnVVU9PyffBFVO3vNz8d+a53lGVVVLk/xAzu1aymPr5fEnk1ye5ObmPX5h8+tnUuPp6ttfVdU/q6pqY5IfTfKbpZRLzra4UsrWnPwd/2WSVc17fM8Z1vdkNf7vqqpuSHJ1Tj4E/NTZ1jfP/9e/Sym1JJtz8j39lD26efwVTzjeV1XVnvOUxyfWOphk5bxaP/GEWgarqvrn+Tq9qaqqE1VV/WRVVRcl+c4k/6aU8u1nW2AppTfJe5P8apJ1zfv+wZzbfe+o/jjPUz1b/OgT7nd/VVWfzVNnIVVVfaGqqtc0a31fknedY43/MMlrkrw4Jx+ctzW/fqbX82ssdB7neeK1nMnJ98auJH/8hOu1pKqqX24em0qyet6xpVVVXd2sdUF75lPU2nLPlGdYq4yegTbpmUmyqZQyv6ZT9/sp3yd56iycj3H9t3LyGevSZn//Dzm3a9lReZxHz+zcnnkmtZ72+TdPnQ9zIXMhc6EzY1z/WsZ147px/dy0dEbbpGdaP5LHVspjYgzvxHlP0j57kkn7ZDRpn7mQfUrPma04rp9Jra3SR2VURp+s1lbJaGKs7/Sx/om1Wvc8N+2SUXMmffSJtcro2ZHRzs1o0j5jvXl9h8yZ2uTv4RPPnh2xfySP9tyfUGvL9cwzrNU609PX0uO6v6XrzD7aJuN6Yi4ko62d0ZZ+9pynHcZ1f7skj62UxzOp1XPm09PycyHzdT3zHOvr5J5pDO+seU+r71PK4zd5f2yT8brV9x+T9tkjb+k8ztMO4/WZ1Noqc5ykfTKatM8Ynli77Nh9yjbZA/Kc2SF5fIpaW26t6AxrbZWxXkY7MKPmR9bX00J5PMNa9cwz0CbrR0n7zIVa/TnzlHaYr+uZnTWGJ+bmMiqjHZXRNlk/SqxxduKzp70icyF5fPrkUR7Ppj55lMdzIY8dksd5zHE6Y+2ypfOoP3bMGpC9xg5ZkzzDWo3XZ0B/7Lg8nkmtrbLXmPjbYM+UeubZ0DP1zCfWqmeeG3uN1oqsFZ0943pn9cxWz+Mp7TCut/T6UZv0x8QY3ok901yoM3tm0j5zoZbOqD2gb/4xfB57QB0075mn5efhT1Fry2VUz9QzI49PlzzKozw+PeY4nZPHpA3WhU5Xa1r4mbJ2Lj88z78opWwupazMycXudza//ntJfqyUcnM5aUkp5TtKKUNJPp9kpJTy70sp/aWUeinlmlLKs5OklPIDpZQ1VVU1kgw3zzf3xBcupby9lPL2M6hxKMlskkNJukop/yXJ0qfxOx5IctG8131RKeXaUko9yUhO3uDT1XdLKeXvvYmfosajVVVNllJuyskJ1NOpb1tzcTellHWllFc3G8NUktHT1df83h2llDc+jdf62VJKT7NxvCrJu5v36feS/K9SytrmeTeVUl7W/JknzUIp5fJSyrc1F1Unc/IN+2S1VqWUW86gxqGc/J2HSymb8vQW0Q8kWVVKWTbvdeWx9fI4lJNZGW72nv/6NOo7lKSRr72GryulbG5+eiwnB7bTXcM3l1JuPYPXWNI8x6Hmz/2TJNc8jRqfeI+f3Xz/dCcZy8n3yunq29Z8n2w7w9e5oZTyD0opXUnelJP357Z8nR6dkw+Fv9jcBEspZU0p5TXNj89HHpPklaWU55dSepL8fJLbq6raleSvk1xWSvnBUkp3879nl1Ku/Hq9qZTyqlLKJaWU0qx17klqfWMpZccZ1NiTpDcn7/tsKeUVSV76NH7HJ973TuyPp/xUKWVFKWVLkp/IV58tfjvJz5RSrm6ed1kp5XXNY0+ahea49f2llGVVVc3kq/f77yml3FpKefMZ1DiUk++ZI0kGkvzS0/j9kr9/vxc6j6f8QCnlqlLKQJKfS/KeqqrmkvxJku8spbys+R7va74vN1dVtS/JR5L8WillaSmlVkq5uJTyrc0aFrpnntIOz5SnyGhn9Mzk5KT7XzXv1+uSXJnkg1/vfZKnyEI5P+P6UE7el9FSyhVJ/vkZ/n7JyWu5uTnGpkPzeIqe2bk985T/XEoZaNb0T55Q62mff/MU+SjmQuZC5kJnyrj+tYzrxnXj+ml8E2W0HXqm9SN5PNv6jOGtPYaf0g7znlN+trT+nmTSPhlN2mcuZJ/Sc2YrjuuntEMflVEZbfWMnvKzxVjfqWN9Yt2zEzNqzqSPyuhpyKiMPo2MJu0z1pvXd86caSit//fwiWfPTtk/kseFy+Mp9tytM7XDs2erj+v+lq4z+2g7jOuJuZCMtnZGW/3Z85R2GNf97ZI8tlIeT/Gc2VlzIfN1PfPp1KdnfpUxvLPmPa2+TymP3/z9sR3G61bffzzlZ0vr75G3eh5PaYfx+pR2mOOc0g4ZTdpnDE+sXXbyPmU77AF5zuycPJ7SDmtFp7TDWC+jJ3VaRs2PrK+3Uh5P0TM7Y/0oaZ+5UKs/Z57SDvN1PbOzxvDE3FxGZbTTMtoO60eJNc5OfPa0V2QudLb1yaM8yuNT1yePXyWP8iiP5jinY4+89fOoP570zb4GZK+xc9YkTzFe649nUp/nx7+vHfYaT/nZ4m+DPVM+vRr1TD1Tz9Qz7TW27l7jKdaKjOtnWmOnj+tJ+/TMVs/jKe0wrrf6+lE79MfEGN6JPdNcqDN75ik/W1p/LtTqGbUH9M0/hp9iD6iz5j2ntMM8/JR2yKieqWfKozyeIo9fSx7Ncc6UOc5XtcO60CmL9kz5dNTO5Yfn+bOcLPyx5n+/kCRVVd2R5J8l+Y2cLPiRJG9sHptL8p1Jrk+yPcnhJL+f5FTQX57k3lLKaJJfT/J9VVVNnua1tyT5zBnU+OEkf5PkoSQ7c/LNvetp/I7/Lcl/KqUMl1L+bZL1Sd6Tk6G5P8kncvLmnq6+z53ha/x4kp8rpZxI8l+SvOtp1Pfu5v8eKaV8MSfv7U8m2ZvkaJJvbZ7/azTfTKtycjH4TOzPyXu5N8mfJvmxqqoeaB779zl5j28rpYwk+bsklydPnYWcXEj95ZzMwP6c3Oj5D6epdXNONtKvnEGdP5vkWUmOJ/l/Sf7iDH+/NH+fdyR5rHm/N0YeWzGPb0nSn5O5uS3Jh860uKqqxpP8YpLPNK/hc5I8O8ntzXv8/iQ/UVXV9tP8+Bnd46qq7kvyazl5vQ8kufZMfm6eX0/yPaWUY6WU/52Tg/Lv5eT7Z2dOLqz86pPUtzPJnjN8nb9K8vrmeX8wyT+oqmrmDHr0r+fkdfpIMyO3Jbm5eex85DE5Odb815zM0A1Jvj9Jqqo6kZMbMN+Xkxnbn+S/52RvSZ6iNyW5tPn5aLOW36yq6tYnqfVM7vuJJP8qJ98vx3Ly4fn9T+N3fGuSq5q5fF86sz+e8ldJ7kxyd7POtzZr+MucvL9/3ryf9yR5RfPY18vCDybZ0fy5H0vyA0/y2mda6x/lq++3+3LmY+kpb07yh81r+b1Z4DzO88dJ3p6T16MvJzOa5kP0a3IyU4dychz6qXz1+fAf5eSG5305mef3JNnQPLagPXOednimPEVGO6NnJsntOfm7H87J54fvqarqSPPYk75PnioLOT/j+r/NyWt4onnudz71t3+NjyW5N8n+Usrh5tc6Ko/z6Jmd2zNP+UROXrOPJvnVqqo+0vz6kz7/fp18mAuZC5kLnRnj+tcyrhvXjeun902R0TbpmdaP5PFMGcO/VquP4ae0w7wnaZ89yaR9Mpq0z1zIPqXnzFYc109phz76lsiojLZ2RhNjfaeP9Yl1z07MqDmTPiqjpyejMvrNONab13fOnKkd/h4+8ezZKftH8mjPvdV75inWmTpoXPe3dJ3ZR9tkXE/MhWS0tTPa6s+ep7TDuO5vl+SxlfJ4iufMzpoLma/rmWdEz/x7jOGdNe9p9X1Kefzm74/tMF63+v5j0j575K2ex1PaYbw+pR3mOEn7ZDRpnzE8sXbZsfuUbbIH5DmzQ/I4TzusFZ3SDmO9jHZmRs2PrK+3Uh5P0TM7Y/0oaZ+5UKs/Z57SDvP1t0TP7KQxPDE3l1EZ7aiMtsn6UWKNsxOfPe0VmQudKXn8KnmUx6ckj3+PPMqjPJrjnI498hbPo/7YMWtA9ho7Z03yFOO1/viUPD8+qXbYa0z8bbBnSj0ziZ4ZPVPP9P+nOFMtv9c4j7Ui4/qZeHOM60n79MxWz+Mp7TCuvyUtvH7UJv0xMYZ3Ys80F+rMnpm0z1yo1TNqD+ibfAyfxx5QB8175mn5efg87ZBRPVPPlEd5TCKPpyGP5jhnxBzna7T8utA8i/lMecZKVVVP/Q2lTCaZSvK/q6r6z+fyYgut2TC+lOQZVVXNLHY9p1NK+f0k766q6sOLXcvplFKen+RfVFX1hsWu5esppfxAkqurqvqZxa7ldOTx3LVDHkspdyf59nmbjy2llPKfkhyqqup3FruWr6fV8zhfKeUjOTno3r/YtZyO/rhwmg/4766q6rmLXcuTafU8ztfqPfMUGV1YrZ7RVu+Z87X6uC6PC0vPXHjtkNFTzIXOXav3zPnMhRaOcX3htEPPbPU8ztfqPfMU4/rCavWMtnrPlMeFJY8Lxxi+cNph3nOKjJ4frT4XaoeMes5ceProwpLRhSej54ex/vxo9bF+PnOmhdPqGdVHzw8ZXTgyen7I6PnR6mN9O2TUnGnhtHoe5/PseW7kcWG1eh7n0zMXnmfPhdXqGfWceX60eh9t9XF9Phk9P2T03BjXF5Y8nht5PD88Zy6cdsioMXzh6JkLpx16pjwunFaf98jjuWv1PLZDf2z18bodnh9PkceF0w798RQZPT9afQyfr9X76HytPq7P1+pz81bPaDv0UXlceMb6hSWjC68dMtrq43o7PHvK48LTM8+dudDCaYc8nqJnLpx26JmtPobP1+o9cz4ZXTgyen60ekZbfVyfT0YXTqs/e7ZDzzylHZ495fHcyOPCksdzI48LSx7PjTwurFbP43zmOOdGHs+d/njuWn1+bd184bRDHk/RH8+d/rhw2iGPp7RDzzyl1TM6n2fKc6dnnhs98/zQM8+PVu+Z87X6XGi+Vu+j87X6/KjVM9oOfbTV86hnLpx2yOMp7TCu648Lxxi+cFq9Z5oLnR/t0DNPkdFz1+o9sx3y2Opj+CntkMdT2qFntvoYPp+MLhw989zJ48KRx3MnjwtHHheOOc65a/U8ztdmz5RvTfK6JAerqrrkKb+3qqpvTFUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsiNpiFwAAAAAAAAAAAAAAAAAAAAAAAABA+yqlvLyU8mAp5ZFSyk8vdj0AAAAAAAAAAAAAAAAAAAAAAAAA0ClKVVWLXQMAAAAAAAAAAAAAAAAAAAAAAAAAbaiUUk/yUJKXJNmd5AtJ3lBV1X2LWhgAAAAAAAAAAAAAAAAAAAAAAAAAdIDaYhcAAAAAAAAAAAAAAAAAAAAAAAAAQNu6KckjVVU9VlXVdJI/T/KaRa4JAAAAAAAAAAAAAAAAAAAAAAAAADpC12IXAAAAAAAAAAAAAAAAAAAAAAAAAEDb2pRk17zPdye5+YnfVEr5kSQ/kiTdXfUbVq0cSpLMzNWzdKAns9OzmSkzqacrJ0ZOpJSSRqNKo6pSSlKv19NbqzI2Np2urnoGBroz2N+dqlbPXKNk/9HR1GolXb296UojXbVaqlJPd09PeqanMzQ+kVKSuUYjc/WSvv7+pG8gc1MncrS3J6mqrBxam3pfXw4e3JFGYy5Vo5GpqZL+3t709w3k2ImxlNmJrN2wMSWzmTpyLLV6Mp2e9Pd0ZXpqKvValUOjkzl2Yrx8A649AAAAAAAAAAAAAAAAAAAAAAAAAB2ua7ELAAAAAAAAAAAAAAAAAAAAAAAAAKBtldN8rfp7X6iq303yu0mycd3K6nXf+6pMnxjO44cmsnJwVa4eWJulVy7Psu65bH/kkfQNDmZ4ZDx7du9JX09PbnreTdn+mffmsw9PZmbfkRzqSf7j99+cNct7Mltfmr2zKzI0NJQly9dksqqle2BZRmeSwfXbMvvX78vzP/qRTE9OJF1J94XLsm7tlmTV+hy96oL82vYvpqde8lNv+KUMXHppfv5nX5PJ6alMT01m/66efOszn5vxqVrK9HDue+zL+Wc/9EMZ6JvNJ377zzM9250L1g9m/+Pbs6yvkcn+5fnvH7nrfF9zAAAAAAAAAAAAAAAAAAAAAAAAAEiSdC12AQAAAAAAAAAAAAAAAAAAAAAAAAC0rd1Jtsz7fHOSvU/1A/39fbnyko05cbg/G9bX83efuDPf/4+/Jd1Ll+SLn/9cLrnyinT39GZqaiZXXXVFToyeyJq1a/LLn92TtSuXZd0Fy/LTb3he+mvT6S9zue+xXdn0kpfn6Fc+nMO77sjw0X0pF317rrzpW9JYsSET09OZK1WSZK5U6ZuZTIaGkuP7UnYey+iJ8fT3dGdi9FgGUmV8fDIzszOZmprOBRsvyuqhVfnSyNGs7jqeZ1y4JL31JKWW5ZffmLv++i8y3n9Flqy5KPW+Wka3P5Kqqs7bxQYAAAAAAAAAAAAAAAAAAAAAAACA+WqLXQAAAAAAAAAAAAAAAAAAAAAAAAAAbesLSS4tpVxYSulJ8n1J3v9UP1BVjSxv1LL22JJsmVqRZ2+9KJtXr0sp03nsA5/P5+98OKNjk6nXS/oG+rNm9crMzUzn5puuz8rBkmPDYzl4+HhmZmoZm05m+lakvv39+fLHP5Iv3bc9dzye7Pi7P071tz+Zeq3kxNhoqsZcal0lJ6ZmM7t3JqmOJ12zyUxvGo2k0ZjLoZ0PJimpGkmtlFRzyepla1N6+jPQvyTrN12a+uyJTB7dmakjuzN4yaVpXHxJRrc/nhVlNg/tPpT7q4GMTMx9I647AAAAAAAAAAAAAAAAAAAAAAAAAKS22AUAAAAAAAAAAAAAAAAAAAAAAAAA0J6qqppN8i+TfDjJ/UneVVXVvU/1M7WqllUT6zI0sTJH9xzKy698fo4+MpLGXHcyNZO9f/vF/O2n7srBoyfSXarUa7U0qqS3u+RNb7g5Y3ON7B7pzej4TIZHxjPYk9z75UczOTWXfXv3ZcnyVcn0VDZtXJ7+4/dm9fqNGR6fyvRclcdHJjO5oj85MpYcGE0105WqSpJatj3jeUmqVI0qszNzmZmaTX/3YMZm5rKqvyu17u48+yWvS7r6MjMxlkceuj+rL7gwYxdckqOjR7NhxdI8+8ptqU6eEAAAAAAAAAAAAAAAAAAAAAAAAADOu9piFwAAAAAAAAAAAAAAAAAAAAAAAABA+6qq6oNVVV1WVdXFVVX94tf7/omZqay85IJcdP3lufC6K7P+WZtTTlQZv/14NvcOZGW601Wv5+O33ZfH9x3NxOR0GrOzeeGVK3LXPbty5dWXZM2qZfnKoXruO9KV0tOXfY2BXHn12tRWX5F9o8dzd2NdHj3em4+/6/dSaiXDqTIyMZUTpcpwTz2Ng8PJ3HRy7FgaSaokpVZLUmVycjZTE9OZm60yOLQqx6dKLt66IocPP5bJQzszNzuTrv6lGZuezfjB/ena83COHRvP393/aB4/NpKq3nW+LzkAAAAAAAAAAAAAAAAAAAAAAAAAJElqi10AAAAAAAAAAAAAAAAAAAAAAAAAAJ1joGcoex/dnyNjw6k9fDTHJ8YydOm6LKn3p6sxl/XLl+Tm665PGo387efuzqFjI5kaHc6aVQOZ6luRzRvXZG5qJJtX9GT5sv5M1vpztL4pn9rXn1VLpvOMTaty9bd+V7689A1Zc/VLMj07mSozeaSnkU+t7kl3YzZT1Vxmu3syvf9gert7k9RyYmw405OTmZmaydx0Uks93f0DOT4+ndrA0lx04YZMTs5lbGouU3O19D3wN7lycDT7pydSDdZy+TOenaHSnd5aWexLDAAAAAAAAAAAAAAAAAAAAAAAAECHKFVVLXYNAAAAAAAAAAAAAAAAAAAAAAAAAHSIVRuWVq9+3Yszm/EcO3Yk1f51uWTjFRnPvqzq/VCePX1dVj/v3+ZY92R+7r3/JZOHJ/JDr/2JXPjM2zJ2ZC6Pvv/zqdd7c3ByZaYvHMtsYzQff89oDh4eydIlPUmSufpAurq7UyvJD7/6gvyLb9+Tma4qw48cSG1uKFsuHcjk6ERGu1bnocEX5nff9Yn86Gu3ZPWma/Jrv/Y7ufiCq3P88EhG6t+a8dlGuurJxOihdHV1p5FG5mZHc/cnPp2quy//6yc356NfPJYP3z6XsRPHc/jIRKamZssiX2YAAAAAAAAAAAAAAAAAAAAAAAAAOkDXYhcAAAAAAAAAAAAAAAAAAAAAAAAAQOco9WR6w4GMHx/N8JGx3Hvfffniw5/PthuH8i+eOZaNfb1ZsW5LNmQmS7qW5PIrLs47P/22vGH16oweOpGh7qm84gWD+Zm3H8yV1/VlycWzGX7bRCanpjI5NZ2qqlLKiVTVyddr1NdnYNV4uo8cznRPd5ZvmshMbTpdQxPpW7Exb3/rB3LzFcn27V/OIztvy5Y1E/nsF3Zl9dqJXHLhtoxOHM9sfy317u6Mjh5NT+9Qpk5M5vhsb9YNbcu//NUHUnUtyeTkeAb6ulIt7uUFAAAAAAAAAAAAAAAAAAAAAAAAoIPUFrsAAAAAAAAAAAAAAAAAAAAAAAAAADpHVVU5fmg0pSvZfMVgVl4wkPUbNqZ3RSNv/czy/NHnHkg1Vcv044fzLy+8KC/Z8C35oVf8UL74+UM5tH02776zym/97WAuWj+U9V0XZkXfUFIlSUmSlFK+5uN6LRlYszpZsyz9tUbGx7ozUMYydMGadPf1ZsXSrgwODuTSq16emZGxPOPqK/KGf/zM3LezZLS2J1euG8oNG7bm8vVbsqF3STb0DGbD0vV5/Ut+Lj21dUljY67btjzrBpZmy7Kl6e/uWrRrCwAAAAAAAAAAAAAAAAAAAAAAAEBn8S/gAQAAAAAAAAAAAAAAAAAAAAAAAPANU1VVugfq6ekp6eut51mvXJ8Nwy/PPaPvys6DXfmJf/q7aRzYnb/4wM/nNa/+57nr+LGsmFqb7v4qux6YyiteuCoPbZ9Kd2Mkw1/Zn1u2LU1vb1fq47X09vRk+eCSjE1OJ1WVE+PjGTsxnbmZeuoDS7LqW1amVu9K6d2Uanoi1cR0nnP5ntx44/OybPVMcrSWydnHcsW6XfnvP9mXd31ybx4tR3PZ1Npk94FMHNiX5RduzMCmLVkxfGPWrbgi+48+kkce/s0cPXYgG5cvTW93bbEvMQAAAAAAAAAAAAAAAAAAAAAAAAAdomuxCwAAAAAAAAAAAAAAAAAAAAAAAACgwzSqTM3OJOPdqaa783jf+7NysC8vWff6bBpclanZRl76op/I3+y+P++57S/zn9/w83n0wX2pRntyYmIo9Z5karw75Wgjd99zPFduWJ7tPcnF265Oo3YwPauSwWX1rF49kMHa6kyO70p377KU7hWpl6OpMpTJ2YGcGJ3JkYNz+cwnP53v+6Gt2XTF5nz2r/fkc/dM5ssP9GbfsUdz7Q2XZ+/6nnzysfuyoa+WO790POuPHcuzbvnnmZiYyJrhKjdd+6zs2bs2++79fO6tDS721QUAAAAAAAAAAAAAAAAAAAAAAACgQ3QtdgEAAAAAAAAAAAAAAAAAAAAAAAAAdI5akjLXlZmZRmo9JdOTMzl+7ERWbVyS7q/cmd5rvzt3HLg/k8NH8kef/IM0VvTkl/72l7NtW0923zOXDUPjuWzDXGZ6t+aRB6cydmI6Pcv6s6a3kY1rN2VmvCvjWx5Mbc1YDjZm0n3kynzygcmsWbUsf37H9vzK6zdndnQ8v/2h6YyPzGXpQE8G+mey/eHBLFv1gnSv/XjuvO1o7n3oRA7seTCTkzOZu6mkvrY7eyZqmRtIHtixI6+amkqtmsnczGz27lmT7/rOVXn4iivzZ194z2JfYgAAAAAAAAAAAAAAAAAAAAAAAAA6RNdiFwAAAAAAAAAAAAAAAAAAAAAAAABA55iba6R/Zi5DvUsyNVWSMp31q1cmc43UM5z7Hrk7z7j0iixZfnneff+f5OjE8YzODmf/9qls3bI1z79qX1Jr5J2fm8hEJjM9nSxd35tqdjjVmi9l/YpVGenuyZUXX596WZn922fyltvuysiRvUmtlp0PHsy+8Z785vuP5MKrB/LTr7kwx0cuymfvOJwL178nfb1z+eHvvi4/+2uP5lj3oex8aGd6uuq58vptOTa6L+tXX5qJscns23Mg01PTOTEymunpy7J9X1du++yB1Ov+mT8AAAAAAAAAAAAAAAAAAAAAAAAAvjFKVVWLXQMAAAAAAAAAAAAAAAAAAAAAAAAAHeKqiy6o/vRnfzoZPZqeweXpWrEstZ7epDGXd7/zP2f/obmsXjaQ7q4qR47vTWO2nse3V7ngRa/Mzc97Ti7avCIjI2MZn0yWrViW8cnJfOJTd2b0xGT6B7vS1V0y1N+TXdsPZXxmKvVl9Yx1H83M8bGkSjbOjud5S1anzJQ8vHlJXra5ns/dsS9fundXhqdn0t9dzz989bdl5UXX5O8++qGMTTVSBpZm49J6ZqrZTE0nqXVlstqWnp7k4osvyRdv+1z2Hh3Jpg1b8kfvek/2HThQFvs6AwAAAAAAAAAAAAAAAAAAAAAAAPDNr2uxCwAAAAAAAAAAAAAAAAAAAAAAAACgc3TNNTI0PZ3ZWk/GDu7Nww8+kK1r+lNV/Tl66HAaM3OZnUpOHJ9LbSIZPdzIsqo7r3rNa1Ov1zJT60lVr2V66mh6e/oy16hnyZKhTFdL06iS1SuXpqunNxddsizTjeTAke1Z++BjeXz1mly3ajC3LFmRDfWeHJ04ms9PTaRMb8ytH7k/ay+9IJundueFz785g93JhiUzWbqkJ1NdfZlZ0pVDB45kyVBfujObmZlaVm6uZ8P6tdl60WAefLDK52+9Oz/8jAtTZW6xLzEAAAAAAAAAAAAAAAAAAAAAAAAAHaJrsQsAAAAAAAAAAAAAAAAAAAAAAAAAoHNUVZWp4UPZueuB/MrH7snR2XqevWQ811+9NUvqtZw4NJPprioHdlVZUs2lr5Qs7ZpKX29P+gcGcvjQ4axYviJ9/f058uh9ee8fvicbvuWVacxMZ8PKJTl6eCSTU9Pp6ynp7etOZqYzWmYzXZ/Ox/bvzNGhzdnQvyPHMp76wIb80i//XW64sDsrLlyeS1/6zFx7w43Z+cA92X9oIrWe3mT0eG774GO5cN3S9C4fyFVXXJDhYydy5QXrs2zFukzN1bPxgq1ZueyObNi2NbVaWexLDAAAAAAAAAAAAAAAAAAAAAAAAECHqC12AQAAAAAAAAAAAAAAAAAAAAAAAAB0kHpXThw4nD//zJdz7OhI+mZP5HDq2TNWpX54OtPDyeHHqiyZrbK2P+mrVVl3wUCOHT2U6amZDC0dSk9fX+qNuXz8L96d57zweZmcnk7VmMlcVaW7pzubNqzI4NIlGT56PF3d9UxctDEDa4eSnlrWD/XmcLbl+8r+fPvUo3n9d2zLR3cke0eW5Td+468z25jL1qtvyBc/fVuGlvRl2cpledZ1W3LlDZdm4+Y1GegfzMDgQLr7etM70JV6rSc3PPcFedNP/tMcPfxIenq6F/sKAwAAAAAAAAAAAAAAAAAAAAAAANAhaotdAAAAAAAAAAAAAAAAAAAAAAAAAACdo5RaetZuzMZaV16yZW3ecO2lef0N1+dlz3lJhroaeda6Rq5f3cilK6qMz5RMziaNJL29A6l3dWV2di6T42NpNOZyw3e8Lrs/85ks6UtW90/nwI57s3ltb/p7Svp7u1JqJZMzcyklmZueSb0azKfuG8vB2+/J+Nx0Nh6ZzPXPvjJbl8zli1++P2Njs/nVX/q9/N1fvT+v+t7vyMT0bHpq3Vm3dmlWrVierRvWZnq2ke5UWb3xkhw5fCDLli1PT29Plg4tz9TMbGZmJhf7EgMAAAAAAAAAAAAAAAAAAAAAAADQIboWuwAAAAAAAAAAAAAAAAAAAAAAAAAAOkep1bNm25V51cteneN7dmTzs29O//SxLL30+jzy/mRktsoly+YytaI/1wxM5JJnN3L3X4xkeno6mZlOV1d3xsdOpGo0snrjpqy6+sIcrXfn4JGJpH8oy5YPZXhkKo8/vidV6mnU6jl4ZDT1ekmj1p0LVx/MlpED6ekbzJGpWna952M5caBK1X880z09ee4Fl+Xyyy/LZz70kRyf7Um9XtLX1ZXZ8dHMlK709fVlbrKWru7u7N61P1svuS4H9u/Lvkfvztr1F6aqymJfYgAAAAAAAAAAAAAAAAAAAAAAAAA6RNdiFwAAAAAAAAAAAAAAAAAAAAAAAABA52hUjYwd3p+p48ey8brrM7B8dfoGL8xcd1ee+x1zqY2VNGaTJRdPZWhTLZmr53k/Xs8Hd+3O2pXLUmtUGejrydEDBzI5NpZNz3pBHv3Szqxctznbtm3O4MpVqfccz8jYWEZOTGd2bH/6V/Wmu28oU8eGs6ynK1Nr16Zvcjy91UDWb7skg3fcn6F6ya7GXMbuGM3ju06kUdWz6vn1TM/UMjx8NCeGR1PVelK6e7Nt86o0pqdz2RUX5a47Pp/du3bk5ue9IH/4nj9Mo6oW+xIDAAAAAAAAAAAAAAAAAAAAAAAA0CFK5R/BAwAAAAAAAAAAAAAAAAAAAAAAAOAbZP2q5dW/+Rcvz+CKWrqXDOSezz6eZatXZcfw7hzaeWeGDzYyVyUrVvbne77z+qxfd116+o7kso/9ZVZdsTqN5fVMTX1XDnzugdx7z4N5eLyR+57fk57RqYylJKWeNRc28vDD01m5ZSYvX3FNbh7+SgYurlJ/1ubMLPvepGpkTX02uw6N57v/wdtybPhEenqSmcZcuquSzNTT3dWTH/vfl+bL9+zL8d219B5bkk0XXZWxfY/k0Mh4fu3tH8p73/F/cssLL8/IoamsWX97th98eX7mp34uDz74cFns6wwAAAAAAAAAAAAAAAAAAAAAAADAN7/aYhcAAAAAAAAAAAAAAAAAAAAAAAAAQOdoVFUOTh9Nz8qNGRvvynDjSA6eOJEXfcsr8/jumezeO519e6dz/2OzmWysycatl6VrbirbloxlaHJnlvWuyf7/95kc/IsP54t3Ppb1D+/I/ffszUdv253ZvpFsvDTZ/tjeHOvak117D2bLmt5sGZjLsn1z2TR5d7ZuqOWCTSvSv35N9j7+ePYfGcvWiy7P2gsuzOv+8T/M0gs2Z8/UWHaMHUv6ajmRYzl+oCu9/VO5/yt3Z/PyRjYuqbJn16O5uD6RycNLMn7scN7/0f7Ual2ZnplZ7EsMAAAAAAAAAAAAAAAAAAAAAAAAQIfoWuwCAAAAAAAAAAAAAAAAAAAAAAAAAOgcx0fHcsGGq/OSb/mH2fHI47l42zOybvllqdcbeeHzL8uH/urBLF/Zl4mqJzt2H8uhv/ytfOcrvieZencmHy05fO/hDD6yM3eONXJNo5FqJukfLKl3V3ngjtEc2zmd7qV9WTK0LFXXsYxWh9IoVaYaJQcf7s3aS+9IWfqSJFU+f+vDmamXXHzFtbloS8mLvu1b8523XJNX/8OfyfT0dKq56cxN1XJ89Hi2LF+WW174sjQmdmfPjq/krW/7+SzbN5ttd9+dw8dnMnTtDfnKPfemVmss9iUGAAAAAAAAAAAAAAAAAAAAAAAAoEN0LXYBAAAAAAAAAAAAAAAAAAAAAAAAAHSOJQM9eeFzX5IlAyUbNq5N33DJ6tVL81e3vTtXXT6ddT98TTat78m73rMrhx98MH9y74E8vud38rbe5P5PJu/Z81ieWy9JIxlJsrcqWTFUz+6VVcYOzebY/kY2TfRkdLrKQw/N5KHBkVy5bHmmuroze7gr/Y/emqFnvjRVSh587Fie+6xnZ+c9n8+dnzuWhx8+mK3rZvOPvv/78/tve1vmpo9kZqaRgaX1TCf5/G0fzbe96FXZuOLh/MS/f0u2f+ZjqdW+kr9436ey/+6H89off0l6ut652JcYAAAAAAAAAAAAAAAAAAAAAAAAgA7RtdgFAAAAAAAAAAAAAAAAAAAAAAAAANBBqpJS782DDz6Yhx98NGs3bcvOo7dl+MRInnfB87Or/9FcfNELc/ONd2XnF+/Ns1b15ebnvyK57Q9yda3KWxsls13J0SSjpWRtlcyV2axPlYP1Kt0XNjKaepZuSC7t7c7OvQP52JJnZHauNxP7H86+xmRWDn8pd915f+qN6Xzny1+S/Z/6yzz321+XP/2bT+RLXziQw9WxJEnJSCYPl5QlExk+MpAlGc9lVz4zd3zuAzmw71De/+An8m1bdqWxppG1Wy/OBdsuTVX8M38AAAAAAAAAAAAAAAAAAAAAAAAAfGP4F/AAAAAAAAAAAAAAAAAAAAAAAAAA+IaZazRy+11/ma5cnD956x/ltT/4uoxPP54V3euyeulw7r3veMqW6awZGEnfTRdl5MN355KNK5OZkp5tVX5+VcmOh5JalXx0pmQ0yYZLazl2JOlemUwfL5nqnUnvklrWdfWmcayRu2/9YKY3XpNrb3hOPnP3+/LY+9+Zqdm5vOIf3JBbpt6Xjd96f+q1h7Jx26qMrGvkr3YcyZeSjI3PpoyuzJqukdSWDWZuZDb/7x3/J3fvnsj7PvSBvPiZ35uP3/6OrFx3SdasqPLY9gcyfHDvYl9iAAAAAAAAAAAAAAAAAAAAAAAAADpE12IXAAAAAAAAAAAAAAAAAAAAAAAAAEDn6B/oztjc/rzo2W/MRzf9YR54+DO57PptOXJ4V44fH83s1LF89APvydrNK/Lrv39/nnvRYDK1L7Nj3anWVxnqL1l3tJZ7D5dc05scqpLG8q5cdG13Lu7qzvYHZ9LTVTI1OZs9987k5ucN5MiO7uzbc38+8fiX09NVMj1xPD/6plfmmuc8K/1v+7mMT9Xy4NhsrhycyL6h5Ke29ufTDwxlVX1T1iwfycSyKuP7h9M3sDmT9aSv3sjW9dty+NhIXvaiH86ll16UNWvWZs/uxzI4OLTYlxgAAAAAAAAAAAAAAAAAAAAAAACADtG12AUAAAAAAAAAAAAAAAAAAAAAAAAA8I1VSvmDJK9KcrCqqmuaX1uZ5J1JtiXZkeR7q6o61jz2M0l+OMlckn9VVdWHm1+/Icnbk/Qn+WCSn6iqqnqq1x7qTV649t4seegv80+unMv0I3fnwkcfSX3Fc/IHXz6WqamSgbXj2Z3JbN6yNJuf+exM9V6eT37Xf8rY+Hg2Ll+b/iUDWb/nQKamJrLq6GSWXzeZ2rVHk/Sk69UrMthfsueRXdl10eHsPVBL46J6XrxpXaamZvLlvd3pG9qYj3358Xz6vgMZvnNzGr1d+eK9u9NXa+ToeLJ25WzKuqH0rVmRq24p6Zu8IF29AxlctjYP3POlPGNdb5YNLcv01ER273w8//2X/0fWr16RV3/36zNT1Rb8fgEAAAAAAAAAAAAAAAAAAAAAAADA6fgX8AAAAAAAAAAAAAAAAAAAAAAAAAA6z9uTvPwJX/vpJB+tqurSJB9tfp5SylVJvi/J1c2f+c1SSr35M7+V5EeSXNr874nn/HvGR05kYuehdC35cp514zPTGOnP1AOHs/7xu7K8r5ZSlubRXf258/bJXHjJlbnhWddn0wVXpfvi6zMxsCp7a90ZX7MxPZdfme6Nm/Jzf/iebFi2LM9/7nOyee1NuW7rplx72UVZPzSQ5998RVYvX5mXba1n+PDxNPrWpZSl6WkM5MTRE7ls40AOTM9m7dZLMpre3L9vJodGZ/PokUYmGsmGx7fmqnxLqnt6su/hvbnzznuzfElXLt22MsdGxnLwyLFsf+zRXHbxRclMI7XGTGYbjQW4PQAAAAAAAAAAAAAAAAAAAAAAAADw9dUWuwAAAAAAAAAAAAAAAAAAAAAAAAAAvrGqqvpkkqNP+PJrkvxh8+M/TPLaeV//86qqpqqq2p7kkSQ3lVI2JFlaVdXnqqqqkvzRvJ95cnPJX/z+0XzmPZ/L3e/781z3z7qy/kXfn09+cEcmZ+5Jo/ehrNx4IIcOLUt/vScf+fAn8qW7H8zsxHB27jmQ3oHe7HrovjTm5vL4F+/Iq77zpsyMT2Zuei5//IefyF//7juy52/fkfUXbsza9RsycWIujx0fytr1K3Lk+EQefXxXjo428sIbVmTttt4845oLs379yjzzqq1Jo6SWklpVkqrKru1jWTpVz9a1q3JoeiarBxvpXzqUR7cfSakltXpXju14JDfe+Ox89/d9b/r6+lKv1c/5/gAAAAAAAAAAAAAAAAAAAAAAAADAmagtdgEAAAAAAAAAAAAAAAAAAAAAAAAAtIR1VVXtS5Lm/65tfn1Tkl3zvm9382ubmh8/8et/TynlR0opd5RS7mj09OaFr3lebv+7o/n00aTvS7PpG9uXzFTJkrEM9FeZPbY848PH8ulP3Z5HHtmdB+9/II1aT7atWZmp2VoOnZjLJz70yXzoQ7dmw+ZNKbVadt/6rtx3++fye+96KPf99V2Z2rs30yPjWbp8IPcd7k/fum0ZGFienv6x7Dm6IydqwxmbGcuRIyM5sH9fnnXNRRkY7Emq6lTNWbFxVbbv3pdHjkzk8SNTKfWuHD0ymp7evjTmqnTVu7Jm6wWZq+YyOzudI8MjC3tHAAAAAAAAAAAAAAAAAAAAAAAAAOAp1Ba7AAAAAAAAAAAAAAAAAAAAAAAAAABaWjnN16qn+Prf/2JV/W5VVTdWVXXjilWDmVnRl+Ubkpe9YUUmbqqn+/Lr8oETyeo1F2TZ0mV55OGZbLlgMPV6LaVWZfvenZmaGM++++7K3oe/ks++731569v/KLfuPJgjh4ezev2aTD76pWycPpSLuqaz72hPkukMrupLqc1my8ZN+d13fzx3PvCVTM6NZe36mWy9ZHVO7NuT3ftOZOz44Szpb+QZ11yQVFVSVSkpeWz73pTunlyweXVKV1emU09XTz1DS5el1OoZHOjN6o0XpFZKpqYmUjvdFQEAAAAAAAAAAAAAAAAAAAAAAACA86RrsQsAAAAAAAAAAAAAAAAAAAAAAAAAoCUcKKVsqKpqXyllQ5KDza/vTrJl3vdtTrK3+fXNp/n6UxqbGsmnPvGxHJpIPvbe4Tz70oEcffjP8u03JEs3vTQPP/zeHDnanXXr5nLFtdfnphuend6+Jfnb97wzWy69JvWe/ozMzubFL39RThzan5GZRnbe+ZVMHlmdm7YdymMH65lZ1p2uMpDtj4xkdHo6c5O7s25LlS3rxnJxb2+e98J12f/oY6n6BjJ8aDS9W0q6qxN5xjWX5c7bH041N5e5udmsXjaQzSsG85UTS3LJhVsyPj2RnvpclizpzezMdGYnJ9M/sDS1WpW5ajZdpaRKtUC3AwAAAAAAAAAAAAAAAAAAAAAAAACeWtdiFwAAAAAAAAAAAAAAAAAAAAAAAABAS3h/kn+c5Jeb//tX877+Z6WU/5lkY5JLk3y+qqq5UsqJUspzktye5B8l+T9f70V6+5ZltG8k00ONPHS0ntFHqnQPH0331NIc++Q708h4LrjgORk/cV/q9RM5dOhg9u3flyO5MwfuOZx1Q+tz2U03ZrpR0ujtyWzpyqrLNmVmYC5fOXxrLrlkcy5/0YXp2bA2oztGsuvASDauPZxX39Sbet+y9C3pyfjx4XT31tI9sC6rVsxleKyenq6S1etWpae3J929Pal3dWdsZi6P7jyQmVWX5rk3XpUH7r8/S/rncuT4iSwdP57VK1elquYyO1ul0ZhNbzWVVNX5uDcAAAAAAAAAAAAAAAAAAAAAAAAA8PeUyj+CBwAAAAAAAAAAAAAAAAAAAAAAANBRSinvSHJLktVJDiT5r0nel+RdSS5I8niS11VVdbT5/f8xyQ8lmU3ypqqq/qb59RuTvD1Jf5K/SfL/q77OP3J3yba11Z///n/I8KFdWbuyL2u3PTsTJyZzdN9IfuWtv5OVQ32pGkvzna/59gz1JaPjvVnWO5pf2vkXGehbkp6urgwOrUxfTy2N+liqxniG5p6RqcaJjI/NpLe/nq7unsxMzqSansqyE4O56aqLc3xsZ1asGsjhww+mUWazfNmKzM4OZOnUSzMzOZ7+/nrGp+aya9eBTE9PZ2p6MhOPPZjHT8zlquUz6dr4jHzirr/KqjVVDu2dyrabn516V3fqVSN9WZFUtcw1pvPW33p3Duw9VBb8pgEAAAAAAAAAAAAAAAAAAAAAAADAE3QtdgEAAAAAAAAAAAAAAAAAAAAAAAAAfGNVVfWGJzn07U/y/b+Y5BdP8/U7klzzdF67K40s71+SVVu2ZeT4nqzecF1OdD2U5UPrctc9h/Otlw5m2ZLDWTn0rVm/picjI8tyybrRNMbnUvXPpuruyWTPWGaT9I3MZf2GwWzfl0zX+jPZk8xOTCeTU5mdaqQqk7loppG9o0eS2mCWHp9L/7FaDnclW7b0pPTMZMXMlsxMz2RuZiZz4+PZdMFAJsbHMjU9lbVDd2V97aWZu+8j6d9wYW7ofknuvP3jmWmcyL7x+1OrdaerNpfe6WWZOTyUI0eOZXp28ulcDgAAAAAAAAAAAAAAAAAAAAAAAAA4a12LXQAAAAAAAAAAAAAAAAAAAAAAAAAAnWNqpsr0+GiWLO3P1itfkmryRKqZuXz6o+9KT3dSTRzN0csvzf+767Z81zOflVpVZW7svtS7plPqXUmtK/XSk1rVnaPH92dq6brU08js3GSmp8YzPTWVUpXU60k1U0+jMZvH9x/MpUsuybv+7E/TKI0887nX5+iaVVm1pJEMlszONTIxNZXp6emMjIykZ3I0g42p/NUHHsmrfvBbs+p1/yap9ebKXJEXPPvF+asP/IfUB2/O8MTjednNL8vU8RO550s7cmTPodTmymJfYgAAAAAAAAAAAAAAAAAAAAAAAAA6RG2xCwAAAAAAAAAAAAAAAAAAAAAAAACgc4xPzeV33vLnGRjcnK6u/lSlJ0f2bc+nPn1nrrxhY5ZtXJOqry87hg9nbnBrLr7mppSBq1NLd7pKX3pq3amllka9lpWXX5B6b18Gjx3NhkfvTyYmMzMxkekTE5k8MZ252cnMVd2ZmuvJO//4L/L4oXq2rlqWvkOrc+AjI3n4k7szNzeV4yMHcuTwkRw5fCxjJ8YyPFfL4dmezHYtzcf/3wfSneGsWtGf5ctqWbt6MJvWrUz/khWZ2debd77t/fnwX386k5NTWb50beYa1WJfYgAAAAAAAAAAAAAAAAAAAAAAAAA6RNdiFwAAAAAAAAAAAAAAAAAAAAAAAABA51i7ZlWuu+6yHNq7M8tXT6R0Decrd9yZBx4fz9oXXpT7H57NmjSSqi8P7N2Vi7ZuS6O2Lt1ZklIlM3NJvbuR7npP+noamZ7tyg8dOZxbl61LGdichyf2ZmpuOtMzk5kbr1Lr687SgSW59tXr03hwZ75w66701Q5kZLLKlZcuzzUvnMiqFWuzakXJ4QMHMre0L8tWr0mjkXzuQ7158PEjedO//vf5s3f+RkbHh9Oo+rJ27cX5xG0fzfJcnBVD27J8w0iGD0/ngq2XZ2DJpxb7EgMAAAAAAAAAAAAAAAAAAAAAAADQIboWuwAAAAAAAAAAAAAAAAAAAAAAAAAAOkep1fOaf/RP093flcbk8ex84O4cGj+cw42hzH1pfz57+/35pzd+Z6raVD54+9+kt7c3t1y7OalVKV1z6eqq0mjUUtWqzM70pl6fzfH66rxo33j2XHc0L9h0TYYODObx2lh2HzmQnqmZVNVwVq/vyg03X5U7br0tX9p5LPVa8mNvuiprN2xKKbU0Go0MLV2WlJKqqtKoqrz++1+RuXI0A4MDmZy8L6NjB9Lbc0GuuvqibPzisZTJ1ZlqTGbfvqO5YP3qfOWer6RWK4t9iQEAAAAAAAAAAAAAAAAAAAAAAADoEF2LXQAAAAAAAAAAAAAAAAAAAAAAAAAAnaO7qzdpTObxhx7J4f178uDDD6T0dKW3PpvR/ScyPjaVD77rs3n5dz4nfb3L87b3/2G+/abfS1etkTRKMlulpJ6UkcxNr0qtntzf96zM9K/O+3/hZ7L8hffm1XObMr5+KtsuvTrL9tazb/jxLO8ezLcsfyRv+blluXPHUIYPHMsztx1KX19/qqpKVVVpdHd/9eNGI/Whx7Ksb3m6u0eze8+epH48yVh6uoZSTa/IyPjuHDh8IKvXDqRRrc+LXviqPPTIo4t9iQEAAAAAAAAAAAAAAAAAAAAAAADoEF2LXQAAAAAAAAAAAAAAAAAAAAAAAAAAnWN677HM/t6OvH3HO/Lcg71579rDefFlz8rzLqnyiXsfzvd816szeeRwnnvFy1MGurJvx/Y8tns6vX+6JxdsXp3hR3dk1ZbBDL3wW/KlT92RDVvXZ9WKZ+Ztb39HaocuzOgH5nL3pVdl92fuz2UbVmd7uTefevjzWbe8yrt/fSKTU4309nRlbGwmf/OJKi/73rdlcmoymapSr6osW1Nltl5ldiJ57rNuzNrV6zM5dTR//MfvyY03b0l9fF3Wrh7MTc+7MPu235/rbn520tuTlcuWp79vVaampxf7EgMAAAAAAAAAAAAAAAAAAAAAAADQIboWuwAAAAAAAAAAAAAAAAAAAAAAAAAAOshsUvv8A/mOnm1ZV+ayrn86W3cvzUv6X5RyyxczM1ulvnFj9u3el76u7nTXBrN373BufOFzc+jDn82Sqdn0LN2YcnQs+3ccyvFDJ/K6H1yfH/nBH8hv/fbvZHZmSbrHejOypzt37Ppyutftzc5H9mVnkqGlq1JqvZmdHs/SZeuzc9/+rLn7L/PAwwdz5YapVOON/NiP/PP85p/8Rmr15G/ed22+7w0vzYP33Jf67Hi+fMdIahOP5bort2Vu+Vz2PvRglgzsyqorr83cmg05UaZTq9UW+woDAAAAAAAAAAAAAAAAAAAAAAAA0CG6FrsAAAAAAAAAAAAAAAAAAAAAAAAAADrHwe6j6RpYmktOnMjsqlWpje3PowMHc13fkgz2dWXpmo1ZsXpNRo8fz/T4eGZnpvPI/V9J7daPZfixo7nyx1+X2urB7Hpkb3pKcvDxkWy86HNZt+Ejec133JVDBy/MX//dsSzpHUpjNpmrzWblsoFcdPWrc9GlN6dvyeYcP/p4xicbeeCLv5lXPe/SfOtFz87DOz+fPTO709MYS293yYbBKnfduT/vfedHM3zkWF77XZelVFdldsdEbrvtb7Px+S/NXF9fhp55Ux6+64t55raLMz07k6lGY7EvMQAAAAAAAAAAAAAAAAAAAAAAAAAdomuxCwAAAAAAAAAAAAAAAAAAAAAAAACgc8w0kveteTCv3PacbF+3NEO335GLp7bmI2N3ZGrpTGamxzIzuTT17t5cfOW2HB8+mv6B/oxsvzR3PHB7hrZuyf1f+Gzuf3h/Lrp4ecZnjufuW/9d7vrK8Vy8dS5DA/tSTbws33Lxt+WiLdfm0yf+R67cNJXhpc/Ixo1XZy5zObpnT46N9GXNumuTwZE8+Nm7ctOlW7N2yVT23f9o6oNVcn89l194QZauWpfZsZEcP7Y8g7XZ7Dz8lVx2xcWZW7kmSy+7NjM9/dl8w43Z/9ijmRscTFVVi32JAQAAAAAAAAAAAAAAAAAAAAAAAOgQXYtdAAAAAAAAAAAAAAAAAAAAAAAAAACdY01ZnrKmJ3uWlIwcHs5rLn1NykQjv3Dn72T8nuO5+sqLctNN355nXPeMDA8fy8ZNW7NkaDBf2jmcx6a68ugj9+S227fnZa99Xj7ziU9kerqWj/3dS7O0eyA7xydzx4NVRmdKbrzgpfny4c9nzdplGV36Y7lo1fqMT01memIyZeDSjO38RI7t+1KuXvOaHLtsb758YHf2HZjK/Qd2JBcOpLZuMrUTydFDB9Lbk1x44c1Zt2Z5LrnskqxadVHe/mc/n9KYzmA1m9HRsVQTkxmrdWXqxMhiX2IAAAAAAAAAAAAAAAAAAAAAAAAAOkTXYhcAAAAAAAAAAAAAAAAAAAAAAAAAQOdYkr68Zvi63Hv5UAaHRzM03puHju7MRO9kJg438tIXvzof+7u/zaHH780LX/rqNBpzmZudyeHjR3PTd9yQ+774YL7lxZekv683Dz88naGhnnzi7kZW9K7Msy58QZ5/4QV55qaJHOo9kmOjB1NtvTADS/oytGZDDtx5V0anpzJTJcOHd2Zy8mje/p4/zrMuuywveuWF2XP3F9J/wXNz2S2vy6/+6uuz8UTJ3u0zqepd6RofSHcuzdUvvCyjx0cyPDub6rGH0r1qZU70L02j1pUjjz+e6WqxrzAAAAAAAAAAAAAAAAAAAAAAAAAAnaJrsQsAAAAAAAAAAAAAAAAAAAAAAAAAoHPMdXclSzflmTOXZ/LKWvYdPJwT930hkyMTeevvvy1zc1P5Z5delMcefSQrVq9LT289jarK9PK+bL6yP9OPdyUztUyMz2RqqqS3r+TE1EPZc+Se3Hvos/mu6340PV0DefTIsdy958O58crrsnTDxTm651COT89kYGAgB3Y8kEP7v5SlQ115zi3Py4c/9snsPzySF9x0cUZHl2Tv7gdSm+rKM59zYZ55SX9Ghpfm4msvydSJZbn3c7szk8cyPbg8J9KTnu7eNDZflMNJpkenM3fwscW+xAAAAAAAAAAAAAAAAAAAAAAAAAB0iFJV1WLXAAAAAAAAAAAAAAAAAAAAAAAAAECHuGzbhdV3v/jFef0PvindAwP5g9/5L5mqJrNr8mhu/NbnZvvuE1nW1cgrXn153v5nn8r3vO6i/P5bP59Lu2tZ3rs6n/v8g/mxH/v+3HHfbO768mdyyaWrs/KOep656rI8uOOx3Lv3sayuD2TzJRdm16E9GX1WTy5+5k35y3e+N8vXLclcbSJVz2Qeun93tm7akJuveUGOj05lemoiy5f259jBqSxZ2Z25mZL+jXenu+fSbF1/SYYfeDAjcz0pSyezZUNvPv7pF2RudDy9pZEMLU/V3Z2Uej76Fz+VY0e2l8W+zgAAAAAAAAAAAAAAAAAAAAAAAAB88+ta7AIAAAAAAAAAAAAAAAAAAAAAAAAA6Bz13p78yH//7+nq6cnY5Gz29gxn89ZLsm16fYbrD+XCNZfnZcOvySWPXpKdJ7ak/5N9edk1ycEv3p9VtX059Ogj+e1f+pU8crQr3/2Db8zn7nxv/n9LvjvPufbi3PaZj+avjn48r2isz9q+uVy+dn0eq01m6dBcepYfz1TPVMrcoXT1rsyS5UvSMziQ0bEl6e1enq6uKqPjw2n0dGe2Wpbu3u5Mj38x19z4guy++29zZPfxpH4iSy4ZztHG0gxMvyyNwW2p17tS76pnbnY201OTqRr1xb7EAAAAAAAAAAAAAAAAAAAAAAAAAHSI2mIXAAAAAAAAAAAAAAAAAAAAAAAAAEDn6F2yJJtWLk93dz21WsmqNZsz2Lc8q5evy7brp/LPNv7zXF42ZnL6REb278lf3v4HKbddl2tX7sk9jxxPd293jo5M5Ee/59KMjE3nhmv+RfbtezwPzX0wr/yV56a7JF+oDmTlkuU5PnwwY2Mn8vEvfyT1wYEcO3YwPf0rc/TwZAb7B9KVWo4d3p2R/V9Ijt+fZ1/Znwfv/XS2rjyaqppLvT6Zhx79YGr7uzIzPZfVywdz3bZLctONz85Ln7E3K5YPpNRKJsfHMjpyNNOT4ykpi32JAQAAAAAAAAAAAAAAAAAAAAAAAOgQtcUuAAAAAAAAAAAAAAAAAAAAAAAAAIDO0VWrpTsl9cZs6rXprFx1QarUUpJc1POKDOxupHFiOr/73rfk6NzxfOwrt2X/7JHM7X0sBw8dzbK+Kl2N6ezbsT+1LM/w4bHs2LMzkzOjuey6yWzpWZLv3fL81Lq6clnXlhyePprx2bG86MYXpVYa6enrycT4TOqlnrGx0XQPrs19j+7M5+76XH7h1/4gz3tmLQf23JGJ0SO57uqbMjr6UI4e35Fqbix79x9O99TFOXJgf1713Nl838tHMj0xnqoxl56+gSxZujK1en2xLzEAAAAAAAAAAAAAAAAAAAAAAAAAHaK22AUAAAAAAAAAAAAAAAAAAAAAAAAA0DmqqkqS9JRa9ux7PFde9awsX9qbyZnZ/Mpv/m5uX/bJHHveaB6fO5SPNv4sfRu686mRD+RDjzTSPXEsq3um84wNPTnac2P6enuyY//ncmJ6LLe+a3v23j+aH7nyVVk505+RvaN5aM/2rOwdTL3UMtM4kVp9SWYac1k2uDTLV61MX99gDux6MHNlMBOz9fT0dOWTnz+Ud37wsWx/7L5cvvGZ2TiyKRMTJbNz06nVkswdyfY9e5J6d77wzv+Z1T37079kKAMDQ+nr60up+Wf+AAAAAAAAAAAAAAAAAAAAAAAAAPjG6FrsAgAAAAAAAAAAAAAAAAAAAAAAAADoHLv27MqO/Qez+8iBrFi+Jg89siNHxkr2HNqVB774aN550dvS89CaHNhwMAfuH041OZ3G0MMZPNHI0dG5rF/en3VXXp/tex7JrqMPZsejB7K1WpXj1XQe2D2cZX217J0ezYVbt2X3/u3prfVndnYk9+54MI3Z7tTryar+wUzPlTQatfR2d2ftmo0Z7ulKf1eycdVsDh3dleUr1mbvkUczNdKXF11/RVJVebTni3l84rGsWbkhs5NjWd03kWdedV/e+eWl6VmyIXP1gdRrtcW+xAAAAAAAAAAAAAAAAAAAAAAAAAB0iK7FLgAAAAAAAAAAAAAAAAAAAAAAAACAztE/MJi5nr5s37snK8bHc/HFl+QP/s9vZPWm3tz4jBuztLo826cfzoNffjT1vt688NUX5eCxg1k1vCTXXNGdFduemw99/K7Mlpmc6J5I78B0ZkZWZeZYT9785r/IS64dyqGR3myeuDDLevozWnWnXnXl2PDxrFm+InPTJ3L4+LH09A6kMV0y2N+d9RsuztDR5SmTx3J4Yi5XXbY8q9dsSu/q5ZkY2pe9++vpHejKyOax9M6ty8ZtWzLy0NGsXL40E4e35+hdH8yGW/4ojcZsGo3GYl9iAAAAAAAAAAAAAAAAAAAAAAAAADpE12IXAAAAAAAAAAAAAAAAAAAAAAAAAEDnOHHiSO697R355Af+No/s3Zfennp2PHZPRo8P5pKbJrP99l2ZWjacNctms2pqWXY/cE+qvrmsWH5RJubGM/n4g3nFxWtTHxzIaP149o3uzc7NIxm6aDA3zW7KyOrBVNcO5/btd2dwU0+GR3rzPVtek4888Ce58DnPyAcf+GD2TI6n2lXPFUuWprG2J8sHl2fdqpWZnlqarp6+NKoqo2OTuazvWVk29f4sHbo/ux89mJvLtlRzw1l11wvy9sd+P1WSw7t3JBfVMzz2a2lUtTSqg4t9iQEAAAAAAAAAAAAAAAAAAAAAAADoELXFLgAAAAAAAAAAAAAAAAAAAAAAAACAznH8+Ege2fvZ9EyN5+H7v5ShVVP5rn/ynKzYNperLtiUvpXjWXJ0WYZG+9O9dCqHd41nqEzm4i1rct36DXlmby0XD3VnXWMu1yztydJ6V46tOZaZyw5ky6W9+fGbZ7Jm/bKMzu3JfZOPpKd/KmseOJQv9R3OW7/yR1lzyWyuv3Eov/k/fiPPGmnkOVu60pPH0pjdnaPH9uayyy9JvZ6sX7cin3n0zrzz0ZJ3PnRFqq3fn8bNL83bH708j37y/+bBQ4fy4JFDOVavkuU9mZx7KCmPp1ZmF/sSAwAAAAAAAAAAAAAAAAAAAAAAANAhaotdAAAAAAAAAAAAAAAAAAAAAAAAAACdo6ur5MDjO/JvfurN+dE3fH++8sVHMzd7LM99wdLsO3Qw3eumcujYZBp9yYnuiaxZW0/qVd53+4FsWr05O3quyKHhg3l8eW++MHYol65fl66u2azrqzIzdiyP/t+dWfEXj+aZj0/lgrmxLO3rz0MTt+X53T35vTf8pzyjvjY/UL84V/euz+WvfG1Wd83kqgsGcvm65bn28m05ceJ4enp6MjAwkE9+8NOZXHV5Bq++LjsmGjm87PqcmOjL3/VvSpKUJFVKkqReq6erayCl1Bfx6gIAAAAAAAAAAAAAAAAAAAAAAADQSWqLXQAAAAAAAAAAAAAAAAAAAAAAAAAA3zillC2llI+XUu4vpdxbSvmJ5tdXllL+tpTycPN/V8z7mZ8ppTxSSnmwlPKyeV+/oZTyleax/11KKV/v9RuN5PYvPZx//V9+JitW9OeidRvyN++9K3/+tu1Zu6UnIzuTRtdkRg5MZdXy5OBj3VlSlmbX8M589Nhted/nP5WLX/QjWbb1WXne89+U4VVbMnG0L9vW1fIvX7gqf7YnuWb1eHavGcqa41XWX/2c7Og9nA376/ns+/8kq2cHcmBiJDvu/e08sO/zydK+bF7Rl4GBvmzZtjl9vX2p1WoZGxvL8N0PZkk1nq71l+Wt73xf/s+P/+s89IUv5QN37szQ4NJUSUpVJalSpaRW6ik1/8wfAAAAAAAAAAAAAAAAAAAAAAAAAN8Y/gU8AAAAAAAAAAAAAAAAAAAAAAAAgM4ym+Qnq6q6MslzkvyLUspVSX46yUerqro0yUebn6d57PuSXJ3k5Ul+s5RSb57rt5L8SJJLm/+9/Ou9eGOuysGJY9k1/Ln833e8Ndc/Y10Gewbyyu++KsOH5rJt0wXpagxmzWAjM0d785wXD6a2vJFrL1iX/XtW5wdXTOeP7nh75k7szO1/8ae59KKXZqh/Zf72syP5s9v355kXrc9f3VfL1JZ12XGiKz2HD2R9z9W57Pobc0XXxmzruSmPPHg0+9f25MTSnkz1DGTf4ZWZqi3Nrn3H09PTm4GB/z87fxpt6XmXB97Xs4czz6dOzXOpJGueJUu2bMmjPGEMdsBA4ySAaSAdCBmAvOnQhBDoJNDddKeZwUwBDDbYGMsGz5ZkWfNYJdU8j+fUmYe999n7eT9E71qsBDtJt6PzrtTvt9ZZ9ez/fu59X3Xd3+++7NmzJ28fmsu25efy6Y/9aYqilfHWTHqbc5k9ezpbNu7Njk17U61VkjJpd1pZ7awm5Tf2sAAAAAAAAAAAAAAAAAAAAAAAAADga6mtdQAAAAAAAAAAAAAAAAAAAAAAAAAAXjllWZ5Ncvbl5/miKPYn2ZLk3Unuffm1307yhSQ/9vL8D8uybCQ5WhTFoSR3FEVxLMlQWZZfSZKiKH4nyTcneeDr7d/dX+Sd774+R4+ey2ozObZ0PLuu6U1XrS+1kTKtqbls3TGQ+kwnPdsXs5KenLqwnJ/48V/M/NRszj360XzXO/9Wlj7757nxrten9fAXs3MkuWJ8Y37g/oF0thX5x6e7Ulk8mdMbe7I8eyGbNtyQE09/Nt/5c7+eX/n8v83K2GieXTiXH77v+/OVs89m56135rn9RzO/MJdG80L6+/szPz+fDV3zOfxCMrz6uVy3fSkpOxmtN3JbcSG3X/e2lAuX8mfzp7Mwv5R2WWa5eSntTusbel4AAAAAAAAAAAAAAAAAAAAAAAAA8LXU1joAAAAAAAAAAAAAAAAAAAAAAAAAAGujKIqdSW5O8tUkG8qyPJskZVmeLYpi/cuvbUnyyF9bdurlWevl5/94/jft88EkH0ySek+RT/7Zc+mq9eXb3vf6HDx5IFdeP5RKbTH7H6hm3URfsulslha3ZH6uncHxapaXWnn+03+S1rlD6R+fyNSTf5xDU+ey7sSLKYpq2rvGcuHSsfzIr87kO+8fz4//7EC2bN2Yf/HbK5mfbmT7nrHcf/uPZbF6MW94x3358cOfzbHfezEnehZy+5veln2HL2R8/bZ09y1kamoqc3NzqdWq6asn2zYvZmWykg3DnRxd6cme5tk062WqldV0F52kLNJJme56b1qtRjqd1W/gCQEAAAAAAAAAAAAAAAAAAAAAAADA11Zb6wAAAAAAAAAAAAAAAAAAAAAAAAAAvPKKohhI8pEkP1KW5VxRFF/z1b9hVn6d+X86LMtfTfKrSTIw1FW+8fZ3Zeem21JZ7uT2DdelMz2dlcFOvv3eh7MydWfao1/IwOZvyeTJeoqhIq+9szdf/NPfy0B3keWzs+k71pPFYiXLla6kspp3jmzIwclW3nLzppza18jwq0bz0sfP576rdufgkdWc+OIDWZ6vZmzvzqx2NfLqZ4dye7M3XfX5XHvD9Smr1Xxlscgb9mzOps1LOXnqVCq1Wp4f2pD63j05/2IzR88dzIkzlTzVGUpPz2Be/NBvZ2hgKM89dSjzq53s3LQlS63VdFa/Zo8AAAAAAAAAAAAAAAAAAAAAAAAA8A1VW+sAAAAAAAAAAAAAAAAAAAAAAAAAALyyiqKoJ/lIkt8vy/KjL4/PF0WxqSzLs0VRbEpy4eX5qSTb/tryrUnOvDzf+jfMv67GUjsjvYu5+5prc2ZmKquLZaYmD2e4ezU99SIbN23NC8erWb9uT5Znz+d1dz+Updl/mj9Y+OWs7x5OrbuehdZqmq0ip2tFuiqraR07n7fsGExt6lwapztZWb2UUwdmM/vVI9lz+1uzeucbMv0nH8u5Rx5Pc6WRnZ1OGp1OqkWRiYmxFKnl/s2D2Tk2nOX52QyPjufshcmcG6nk2omLaezv5ODUUo6eraWrZyCD5Wiqp8+kWR7NiROX0qlUc+n8Sxmf2JBO+//t6QAAAAAAAAAAAAAAAAAAAAAAAADAf5nKWgcAAAAAAAAAAAAAAAAAAAAAAAAA4JVTFEWR5DeS7C/L8hf+2lcfT/KBl58/kORjf23+7UVRdBdFsSvJ3iSPlmV5Nsl8URSvfvk3v/uvrfmaBnp6cuPypXzk//O9eemxL6WdVhqVMp3qQB59tCsPffaxnD26PQf2/btcfdNfZWbuZGq9v5vVVHNuppne7q7UarWkUsmpi3M5eG4hYwP1nJk6n9//0olUatP5+BdPpbevkkqSsy+dyHBXT3Z+z3dlebSaxkBXqn31rCy3cvHcpbSLev7Xf/2v89CnPp3zp8/ld//oY2m1minbrTz0/A35xV+/lPd+x7tz9RVdqVQrqRRFyk6RpZXl9Hd15+qx0XRW22k0VlKrVdJsNr4xBwUAAAAAAAAAAAAAAAAAAAAAAAAA/xm1tQ4AAAAAAAAAAAAAAAAAAAAAAAAAwCvqNUn+hyTPFUXx9Muzf5rk55J8uCiK70lyIsn7kqQsyxeKovhwkn1JVpP8UFmW7ZfX/UCSDyXpTfLAy39fV71eyR/+yfOZXaqm/4XDGd64OQvlpex7/kC2NsuMbzuZlfPbU6+UKaqHMnmxK5XaZGbn51JWe/Po0nKuv2IkZSPp6upKZ3Ul+46cyp6JItdt68u500vZmU5+98FzuXq8lvGuVvLxT+QvGpOZmZ1LrX80N41Ws6ccyMmTZ/NT//yn0tecyw17NuX0yaPZ/9UvZ2VpNvfd/erMnDmddneR46e+mLe+Kdm8azwf//O9Kct2mjNH8tXZmVw3MpjB1mrmF5ZTlGUq37BjAgAAAAAAAAAAAAAAAAAAAAAAAICvr7bWAQAAAAAAAAAAAAAAAAAAAAAAAAB45ZRl+WCS4mt8/cavseZnkvzM3zB/PMl1/zX7Ly43c7FvItesb+fw8mqmz57MFbddlYHxemonP57+sXZ2713K3OJiDh8fyamjWzK7WklPV1e2jPdmcWUpM7OrWV1eSrvVyehALS8eX87zL67k3HI77WaZMtUcn2vm1KVG3rWhO6+aX8odM4107r4yz56YzkuXpnI+7fQM9Wa4v5r73vTWzF48my1XXp+3f+t78zu/+Zu54aorsmn4fG6/aTaXlrryoQ9VctVVqykqq1ltTqdWSeaXG3lmajW33HxTvvTlh9JpNlKruuYPAAAAAAAAAAAAAAAAAAAAAAAAgFeGG/AAAAAAAAAAAAAAAAAAAAAAAAAAeMVUqkV6R4YzfM323NhVy+yRR3Ny43i2bt+W3/rlIlduGc5ddzRy+sJQ+nsaOXR8JteM78yG4b7Uu7uzrquSk9MrmZprZN3ocDop8+SZVuYWVtLpJCmSerGaWoo0VzupFLX0DA7kmi2bM3Hvdbl+3/58/MlOhvuXsm91Jd96121ZbjQyMjaes4f254X5Vu599S25MDmfb/uWxXzTe+/PvsPN3PJT6zI1U+apZ4+n1jWehVYnO3ZszfnJmbz00kupVKuZX1xOq+ysdcUAAAAAAAAAAAAAAAAAAAAAAAAAXCYqax0AAAAAAAAAAAAAAAAAAAAAAAAAgMtHtShy6zXDqSyeTbXrfI615/OqV42nt2t9lldqOXuxnmcPFXnisd48/sJAikp3FlbmMjzcn+GBriw0OtmzoSdXbOxLc2kuy8uLKVJkpLvI+t5qRmtFesqk0exkbjlptdrpHR/JlT/yvVle6snySi07+rpTPdVKOb+QdRs2ZOvuKzM8tiHVej1vu/6GTOy8Mr399Xz2+R1ZXKnnd377y1k+fzBLK6v5lz/dSr1SZP3mjdl+xVWp1So5c/Z8Go1Gal211GrVta4YAAAAAAAAAAAAAAAAAAAAAAAAgMtEUZblWmcAAAAAAAAAAAAAAAAAAAAAAAAA4DIxNNZdvus7r83YeHdmFhup1XuybsNYiupgdk4NJrUiK/ONrJbtDA8Ppa+7NwvT0/mzZ57L1r1DWZhZTb3enf6R7swvtNPdU8lTH3sineZSLi22s2F0e+58ywdTXWxnvns4m2pPpXXk0bzv/V1ZXZ5P0WpkcmY2zcWlXJjvyevesS1Fd3+qK0Xmqsn2DSOZnD6bZlbzJ39cy5Y7duXMmUtZLReyfvO5nDy3PYtT2/P+t39nfvf/+MX0btyZ3vZMbn7N3Rkc35x/9I/+cQ4ePFSsdc8AAAAAAAAAAAAAAAAAAAAAAAAA/PevttYBAAAAAAAAAAAAAAAAAAAAAAAAALh8FPUiq+sqmR+opX9Df6pFkWZ3O2Umc+3mq1JWujN58XyGhkfS01WkUunKzEyZcw+fza19E2mvLGV1fU9W++oZ2NCXMu00M5RTszNZXW1nYuyK9HfdntF19QyPbknvuYOZ6Z1Nb+V8+oYbKZMMDycz82UG2/WsPvNMZmaKLE4nA1fUMnhbIyP1MmVPcuW7fzgX5z+d/u0jWVnuz2J5W6o9qxne0snUycNpTs7kypt25PhXD+Ti41/Ne//tL+Wnh39mrSsGAAAAAAAAAAAAAAAAAAAAAAAA4DJRW+sAAAAAAAAAAAAAAAAAAAAAAAAAAFw+etOV/np/+lvVzD5XSd9wJfX1/RnbXaTebmZyZiGjw0MZHB7OyspcVlfbSaUrtUp/ui4u5Jqe0cxPzWZqpD9lUUmKIgvN2Vyx5daMDXelNrYp47v6MjoymuGikmPPN7I5J9Na7s50mVyYruXsbJmLnXZOz9dyW6OSl87+h2xvqazmLw9U86Z3tHN8qZJ9Sx9OV9dshmuvzvYdt+Tk2aOZnX0+1UozH33gozlXHczsMy+kp3djNs0v5RO//n+l0WisbcEAAAAAAAAAAAAAAAAAAAAAAAAAXDZqax0AAAAAAAAAAAAAAAAAAAAAAAAAgMtHpV1k0+SmPPv4s1nt2ZTB/nruHt+WDRs2ZOXUYoq002g009daSdFezfz8QjrtTv7nf/j382d//GcZX53PxFBPXvzSmYy+diJlpZaxDbtz013vzm273pBK+5E89fiv5sLG27J5z/2pFp3MN4tMn19JpztJb7J7tJNreso02qv5X3452Xxtb2YuNlI52Uma/bl1cT6Tg8nkvm2ZbzYy3ncpPdW5dNf7smXjRI4+9lLa5VAaC4sZX19Na3EpG/f0Z891V6Zed80fAAAAAAAAAAAAAAAAAAAAAAAAAK8MN+ABAAAAAAAAAAAAAAAAAAAAAAAA8IpZbjRy6KVz2bZtPNVGJ69+2/0ZGh3JSLk+C8ufz2998qnse+l4uruSn/uhd2doZF0e/PIj2dbfm/f9rftzaP/5PPXgX+X6Pf05Nr+UwU0j2XbFPbn9nvel2P8rOXn08Zw9dD6Lx2ppV7dk89Bqbt/TyfB4me6epNbVSqWapJrMNspU+qsp60mnWks7rXz+yHD+UW0ud4x08qmJa9I+P5Khgf70rU5mdXU5s42F/K/f1sqP/4uljE5syqnDL+a662/M4XNn8m1XXpGi7Kx1xQAAAAAAAAAAAAAAAAAAAAAAAABcJmprHQAAAAAAAAAAAAAAAAAAAAAAAACAy0d3b386S/MZ3LguDz3zTJaXPpTFSn8++CM/kecOHE+9Ustrrt2eL79wLF99+lBOnn8k/X21/Nkv/X7uu+fV2b19e4bHNmbf8ZUMXL+coYGB3PPGb8mDH/0/s6vy1RxfuSnX3PrOPHN8Z3qH1mdwfi4bN5fp6k6qtaRSSYpqmVSSZpncNdrJuYvN7Oorc1Onk/6J0+keKVPtSl7/2vtzfupsTh15IicPPZFG0Zd2rSfjM8v5pr/9d/I7v/un2T6SVJfO5h0f+NYszk6m7KyudcUAAAAAAAAAAAAAAAAAAAAAAAAAXCZqax0AAAAAAAAAAAAAAAAAAAAAAAAAgMtHtVrLNXfdl2uuuSlnl3uydfP69A2O5LOffiDt6VO5adO6LJ45lBuu2JyHnzucesq028tpLidPfuVg9r1wLK973e25ef1Iinp3njrwZHq6V3Plbd+Rw0/enMH1g6nt3pOe5bOZPDuTK4ZaqXcn9XqRVMtUakWKapGySIpWkZvXdbI8X2a1nZR9yf/4TzqpbkjSm2Sxmmqtmq6h3py/NJCBvtEkyemDyTt/9NtSpJnHn3oh3/KOO7N55+aMrF+fSr17TfsFAAAAAAAAAAAAAAAAAAAAAAAA4PJRW+sAAAAAAAAAAAAAAAAAAAAAAAAAAFw+euqV7Fnfla3DrfzQd707s7OzaaeW2cnTaZ17T85PvphHTr6Yd73n5mzftTezjfm0spDf/IM/TDE8k/6uoTxx8KG8ZsfmNBa7s7moZsfW6UzNVbPxjesyPjqY5/c/mHfety3rJjZl9sidmRy8Nr09RdqddjplO/V6LUmRxU4rn597Mcvz1bzj3ttzYv5iljdekZ5NRSYvJE9/5GOZm5/O0GB3NrS60p5czs5rd+a5sXflkV/+v/PZT30ms119eeaxgXz1oWczOr4uMxcvrHXFAAAAAAAAAAAAAAAAAAAAAAAAAFwmamsdAAAAAAAAAAAAAAAAAAAAAAAAAIDLR6UosmGwlnOHnk69uze1aj2pVdJVlLmx77vy1OSDaV08mLe88Vuy+VWbs7B6NrXKYH7rT383jU4773zNT+Z86+lUhr+Qcwdm0nu8md1v/tG8qrs3jcZKDh8+nN/7zX+dH/uJH8vGsbHMnerO089OpWdwKJ//ylOpDW7O5pEiN125MRu3XZ9HXjiS8fGRLAy8MVu3rk/PluEsF5WcvjCTs4//fOrlci4NrssVN43n0KPHM7BtKMN7bspf/dGHc+zEybS6+1PfuzVL58/kpf3701heXuuKAQAAAAAAAAAAAAAAAAAAAAAAALhM1NY6AAAAAAAAAAAAAAAAAAAAAAAAAACXj9XV1Zw9cz5nTx7Nhi070j8ymlpRptNpZXbpTHqXa/nWO/5WenfMZW6lTLPTychQPfWhTlpz9VROXZ31Xdfmqwf+NOsmk+H1PalUKunp6U5/X18OlYfT29eXEydO5Nprr80TzzybL/zFx9O3/ooUremMjp1PdajII2f6c9vNl7Jnz7o8tW82v/WLP5g3f/Nv5vkXH8qOsWqe2//FNLuq2X+gmS3XN3Lvnl155DPPp+gZTjqd3Hrdq/LcgaP53tu2ZUt3kfGeSv7ki0+lLOprXTEAAAAAAAAAAAAAAAAAAAAAAAAAl4naWgcAAAAAAAAAAAAAAAAAAAAAAAAA4PLRWFlJvVZL0dWX5cZyetuDWViaSqXWnYw1M1U7mNvfuzW1+b5U+7fn4twz6e8ZT9HVyRsn/n4OnN+fc11/mJl2J92XBnK2bOd1ZZlKpZqz585lZXklmzZvSn9/fxqNRnq7u3L04kIGlw/nra+9Op/50lN5/bffk4sXJjN3/qW0Wrel2rsur3vdriw2fj9f/Nwnc+XmrXn6wL685w1XZf+x+WwuF/PSw8/mqnvelo3bdmTHjmvSPLOUN95zd2aOvJiu48czu7ScK+tF9i821rpiAAAAAAAAAAAAAAAAAAAAAAAAAC4TtbUOAAAAAAAAAAAAAAAAAAAAAAAAAMDlo9FazYf/4sF0VhbTrtbyPd/1jswvzWZ0/dYc2/aZrN/en0rfSHrTm9VOJYuLS7l0bjlJct3ee/L5r3w42zf8rcxW/m0ujndlodlKpVrNzMxM1k+szw/+wA/mrW97S/bs2ZNms5kyRarVIuv6i5w7O5mllUYuzC5nYtPmfP6hZ7M6eEtu3nNFHn7mX2dqZjmDvSM5M30hZ89fyN69b89Q93CGh7vTNTialcWlHHzumSydOp9PP/xilpdXMltWcujsTJY7nZwv6llcXlrjhgEAAAAAAAAAAAAAAAAAAAAAAAC4XNTWOgAAAAAAAAAAAAAAAAAAAAAAAAAAl4/Bgf6M93ZyYb6RK3ZuytNPP5+F+eW0D01l5+tOZEPnhoyXV2e12Uq7M5elqTLjfcNZbSbHD53J5trrM3ZpLJ3hpBxNKsvtnDp1Mv0DwymKpH+gPz09Penv78/g4GCqZSdvuOOGDHZ3cniyyHfcf1s6q6t56OkT6ar35+ylRtb1P5KXDp3KpZn5jI2NptZZyve+rivPPLEvs5NT6erpzuZ19SysFKk0GpnpOZBX7bkr40OD+dwjX80jJy6mryxzZqmRslKsdcUAAAAAAAAAAAAAAAAAAAAAAAAAXCZqax0AAAAAAAAAAAAAAAAAAAAAAAAAgMvH7Nx8Rob3ZtP2XVleWk6j0UmlUslwf3dqvfWUxWDSPJPm7EDqIz0pz7WyumElK/OrWVoayvrxSs4M/0qWTreyvNhJ2dXI4OBgxsbHk7LMz/zMv0yz1UylUkmtVsvmTZvTmZ1MtdPI2Hhy3bWvyu//+z/Oq+97c179mnvz2c+dz8z8usws3ZNG63PpNJfyr96f9A/X89i+C1lp1bLabmbk7hty4OHHc99Vo+ltzuf219yaqenZtDrtNLvqOT+zlOVWO2m317piAAAAAAAAAAAAAAAAAAAAAAAAAC4TRVmWa50BAAAAAAAAAAAAAAAAAAAAAAAAgMvEYF93edvV2zIwOJhqtZblpaU0ms2kUs09b78+r9q1J1dNjKdsLeXksWfz1MGZ3H3zthzo7Mp446YM7V7OUvNkFpaL1PsHslqZz8q+Mrtu2ZrxLXsy3zqcsZ6rs7S0mOHBkbzw5BPZtn5HZs4dT7W7L8uLi5l+8tO55f0/lKXlRlaPfSiHjh9N2dWVv/qrF3PiTF9uvLqWQ+fG8iNd9+bi/KE80j6QvUO7c6H3bO5uXZlK92Caf282nfJiLlyYz1P7Xspqp5XlVvLZP1rM5PnVYq17BgAAAAAAAAAAAAAAAAAAAAAAAOC/f7W1DgAAAAAAAAAAAAAAAAAAAAAAAADA5aNabaedS3nyhYupVCrp6evP4vx8OmWZ+5bvyfaxjTlz8XP5zKcPpHPpSI5MDefI00/n7/6LX8vGXTtSKzo5eng2O668JuvHt+fshZP5hX/5g3n/yq0Z/paR1AcnUulvZ+PY5lxcOp+u7nrWb9yUsfVb8j3f9335o9/9tdS396c9+WLmRnZm77aH8tqxM2mO1PP7f3R1dm1p5cmDYxkaHckb6rdmqjWaX2t+NZdqL+ZVc8PpOT+Qwz3zOT33R+nv6cvKYDsD1ywnRZmt3dV84eOdta4YAAAAAAAAAAAAAAAAAAAAAAAAgMtEZa0DAAAAAAAAAAAAAAAAAAAAAAAAAHD56O2p5B2vS979xoFs2LAu9Vo9PQODqVQqefVNNyatsxnZ8uZ0jd+S507WUu/rzedfama1aGTzuu3pro2nqPSlVilz/OgzSZr5ph/9rnTddneKdlIs1VMvqqlVGxnobae/tyvPPf1oDh49npmFdsbW9aR7+xVZnbuU9uEnUs520ikmcvhIb/7dB47mN35iMW+7t5qx8e509Y1ndNvO/MC7bkr/SJF77n9NZoZns6M5kMW5Sg4+2JXOaifV5mBq1WqWm9UURbnWFQMAAAAAAAAAAAAAAAAAAAAAAABwmaitdQAAAAAAAAAAAAAAAAAAAAAAAAAALh9FrTd9fRty720LWT/RnceebebS/Gi6d+7I+LqJDK3fnd/6zX+bt73t+7N1vJ7n9h3Jze2+jI3vyuTUdBaXm/mNn/pX2XXDjdl69ZV59ZvemetueVN6B/tybuZYLk0dycJUb3ZduTcXFy9lcmo+y7Pz+ZY3vi43bR/N3Mxsent6MnbP/Vk4fCyZ6k45u5KrerqTsfmUcwsZ6BzI6OBsTj3/bMrKUm54x+vTWb8zXTuvTt/ji9m2dEX2/+XOjPYP5tCXL2RgfU827G6kXivT6ZxY64oBAAAAAAAAAAAAAAAAAAAAAAAAuExU1joAAAAAAAAAAAAAAAAAAAAAAAAAAJeRMukfHkvRvS3btgzmW+/fnbH+xcxdmsrEug3p792Y2665PUf3PZrrb7gtd9x8Zbas78/K4mSajVY67dVsv+manD53Jp/493+QlZnJzMzM5omDj6fT7k21a1NWugYzPdtOf61I30hf7rvvTZmensvg3Ey6urrS3VNPtbc/tZF1aa9uS/NMM2lUk0Y9nWYjb3nLVZkc2papmdNZmJtNMdmVjdMX8uCHP5Jrhl6TsR07s9S6mFpnJMee6c7MwS2ZPLCUmdmLqaa61g0DAAAAAAAAAAAAAAAAAAAAAAAAcJmorXUAAAAAAAAAAAAAAAAAAAAAAAAAAC4fK8vLmbpwKNO1jdm9vStDYwN525uvytx8I6uV7nzpL347Z44fzOz8fA4cOJj2ajubxwfS3zeRZquRI4ceym2vfUuWVloZ6BvKzPTJzBQ9qY8UmV2aTmu1mcWl2fT21jNQr6VaSybWTeTosSPpDK/PT/+b38s/+5HvTF9/PZVqV37lUwfzndeW6a61s9hqpbtaz4Xlixlf3JOyU6ZRttI8v5SB2Svz/be9K6Mbdmby0w9k101LqU4fzvbensxdvJRTf1XJq97VTLvdXuuKAQAAAAAAAAAAAAAAAAAAAAAAALhM1NY6AAAAAAAAAAAAAAAAAAAAAAAAAACvnKIoepJ8KUl3/sOddH9SluVPFkUxluSPkuxMcizJ3yrLcvrlNT+R5HuStJP8/bIsP/3y/NYkH0rSm+STSX64LMvy6+0/v9jO//7bC7lq17m8/5vGcr5RybV33JJKcy6Hn/tCequdbFo3mM0bJ9Lb25+5uZUMdY+lu2c4x489nyuvuTuTF09kcHRrOmWR+blTOTv1UjZ170i7U2awfzCbxtan0WxmrGtvLraeSLPZzhV7dmVw7zU5dvJ4urt70miUKVLJv/rUQr7/B4dTXmrlgX/fzBU7l3K0cl0GhnvS1TWQstbOrs7t+fn2D2TXn3dn/qo7MvjqN2Sw2p2lvrPpbSbrxvZmetd8+mplvv7/HgAAAAAAAAAAAAAAAAAAAAAAAAC+cYr/zB2AAAAAAAAAAAAAAAAAAAAAAAAAAPx3pCiKIkl/WZYLRVHUkzyY5IeTfEuSS2VZ/lxRFD+eZLQsyx8riuKaJH+Q5I4km5N8JsmVZVm2i6J49OW1jyT5ZJJfLMvyga+3/8Bwb/nmt92dF08/kxt3j+Waq9+QzuqpzKQ/r91xR776uU+m0zuedeNnMrxrW+ZPjaY2PJdTS7V8833vyUTvRE4dfCzHGsezqVif6eq5fOLCUEbWbUrKSipFJbVqV4Z7+jK7OJfrjrfz+qnNuTB3OCsXm9m2eVu6eutZGqjkuSsaeezUr+WmLQNZN/Jcnnz+Ula7qqmOXJmLM1P5O6c+kEMHX8yd7/3mfOrYR/LugVvz3P4TWa325rlbl3NsciaN5Xa6On3ppJXe7f35g5/6w1w4M1n8NztAAAAAAAAAAAAAAAAAAAAAAAAAAHhZba0DAAAAAAAAAAAAAAAAAAAAAAAAAPDKKcuyTLLw8sf6y39lkncnuffl+W8n+UKSH3t5/odlWTaSHC2K4lCSO4qiOJZkqCzLryRJURS/k+Sbkzzw9fbv6m/nW94+lAcff3XmZ+czONjOHzzyVM6fu5Te3aspR/fkK098Jvd921Dmuk9k9z192bH5W/PYr/1U/vLRydx84/acOnkpBye/mq47bkv/cHemJ/fkxKUyYwOVJGVWO8tZml1Kq6hm4oXD2Xb05jz82L9LX7Wa4e2vybFbp3Nw08W0e781b+19Oj/4kz258pbRvPsHJjK7dDzTi0+ka6CV2f7FVNePpDV2Jt9603vy6Y99Mtvfdk3Wr9+dxx47n3KwnvW7NqVsFVk8djGN5WpSfuIbdlYAAAAAAAAAAAAAAAAAAAAAAAAA8PXU1joAAAAAAAAAAAAAAAAAAAAAAAAAAK+soiiqSZ5IckWSf1eW5VeLothQluXZJCnL8mxRFOtffn1Lkkf+2vJTL89aLz//x/O/ab8PJvlgkmzaXM+Zl55O60R/Oo1OXn9zI9uuHstv/2Uzzz/yaM4vDKS3VuTIsSN5x/0fyJmzZ9MzezrpaWbdxtk8fujBXLXlm/Pghx5OJhdzxT2dDAx0pV5U091VZKlVpt3ppDO3kOr0xdRT5PGTn0pRGc3Ulvnsfvf2TFxal6vufnPOja3kl/5VI9MXyxx9tJIH+/tyzes2ZmJoJOmbSv/Jc5lt1XPowKFsXlrMkZf25+TMch796m9l247X5i8f+0p2Xn1HhsY3Z2h4PH0L/Wk1Fr+BJwUAAAAAAAAAAAAAAAAAAAAAAAAAX1tlrQMAAAAAAAAAAAAAAAAAAAAAAAAA8Moqy7JdluVNSbYmuaMoiuu+zuvF3/QTX2f+N+33q2VZ3laW5W3jo53cfeeZfPmJ43ns+TMZ6Hs2u9Y18s8+cEd23HllrnhVPVffuDsbz9+aya+00nqqns6F4+m5YlsmmwspKsP51KceSV9Zy6kDFzM+OZbKwmKWm+00Fprpbq5m6XOfSeuBj+base6cnT2YJ2a/nOUd7UzeNZ/De1/IdDGTTz76V6ldupRa9xtSdKo5eW4qPSfOp3KgOyemLqSYujmN+fkUs1PZONqVxx57Kjt37s5HP/7FzMzO5/zFcylXW+k0mqmsdpJmJ6N75tPVXf+vPg8AAAAAAAAAAAAAAAAAAAAAAAAA+H+ittYBAAAAAAAAAAAAAAAAAAAAAAAAAFgbZVnOFEXxhST3JzlfFMWmsizPFkWxKcmFl187lWTbX1u2NcmZl+db/4b517Xaamf5QpnB/mqqtU6WLjZSGzialfqWFFN92VRsyJe/tD/VspXJqUau3rMzLz7+UhavbGd/V3/uvPbqXH3zQOaOPJfR6sksLo9m77o7U+8fSC3VjA32ZvFNr0//YG8upcxM37E0F/dl/U+8Lc/+9i/nxGN/lIl1t2R1eCYvffl8rl33vrzxfW/J//yRf55NW5fyh396Lne+fUPueuv3ZHr/RzK2YSjThw/mwvRyPvPVl7Khu8iP/eTfyy//+pcz2N+X3lon6zb05q63Xp11W5M/Huv/RhwNAAAAAAAAAAAAAAAAAAAAAAAAAPxnVdY6AAAAAAAAAAAAAAAAAAAAAAAAAACvnKIoJoqiGHn5uTfJm5K8mOTjST7w8msfSPKxl58/nuTbi6LoLopiV5K9SR4ty/JskvmiKF5dFEWR5Lv/2pqvqSyLlD3J976lkR//O8uZmU4mp+ppN0/khtfvzUtHz+UNr39tvu8HfygvHTuX4+enc//b7sv82YM58fSp7Nt3Kg+d+1QG76nn3NZKjlQrqa20srme9BUracxdSG14IEtdE5lsDKWvGE616M+hf/PptG68Ko1yNGcOH86pFyfzxMJktu0az8Do9dm5cVP+8unNuWrPrmxe/Nv5/J//fqors5k6ey6/8clnsrywlOWykkr/aF5zz2uyfl09r3n9Dfn+f/r+XHPXQLbvncjSUpky1W/kcQEAAAAAAAAAAAAAAAAAAAAAAADA11Rb6wAAAAAAAAAAAAAAAAAAAAAAAAAAvKI2JfntoiiqSSpJPlyW5SeKovhKkg8XRfE9SU4keV+SlGX5QlEUH06yL8lqkh8qy7L98m/9QJIPJelN8sDLf19XpyzS7K6ksbVMOVrPpZXVHJsrs3q2TOPcZPr6+3PsxOl834/8eL7y4JcyMzuXzbuuTfsLnWzfWEnz7L5cu21TvvTFi+mvVfLioX25Yu9NafQvpCfNnDo9l3X1kWwbX8r61XaW64O5tHdzpmbO57r7fyCNsieVU4cz291Kd6M7tafP5uzFvuyauDfrh6t5/VtvzpFHtuTOH+nk+X/5m9lxzY159S17c/vNV+TBfSezcV1/Ws8+kDu+6zuy+drr0my3M9Iu8sQTz+TM84/m0qVz3+DjAgAAAAAAAAAAAAAAAAAAAAAAAIC/WVGW5VpnAAAAAAAAAAAAAAAAAAAAAAAAAOAysWNdd/n+m2qZOtuV192wJX39yWJzLgderOa67/uR1Lp7c/Zzj6ae3my478acOXoi919xXX728V/I4sxqtu6eyGtuvyXHDh3P+fMrGe4dSKU6nvrqSqqVSi6dP59Go5k7br8hreXFzJ3qy1LRlfWXRrLy5vGsNFvp6epOp91Jc2kxt/VfyMmnLmal05+Z+YW8dOpk7rr52lz5zh356O//r7liz/YMrNuY3nonn/jSUxnuWcrWdWO59Y0/n9UHDueJ8wfzmVPPpT53KWNFM7/30AtZWW4Va90zAAAAAAAAAAAAAAAAAAAAAAAAAP/9q611AAAAAAAAAAAAAAAAAAAAAAAAAAAuH52FanqeHEumz6Q+tTeDoyMZSV8mFmazfnxH+obXpX3pM5l7/kzON6u5/s2vzeB0mcqxdo4dns7c0TL3bOnO+sZobrhhTzqdTh7fdyB/+tknc/t1O7NztJ1GsZpy9lwunp5Mq297xne9JtWuerpmlzPYty6d5aWsltV0V8bTnPl0Nu1YzsL0bHbuGM8Vt21OX86kmN+cqQ3H066dzngxkc5qMn7TZKbnl/Po1Mnc94vP5tMP/2k+N3U4J1Zms7O7O5M9PRluu+YPAAAAAAAAAAAAAAAAAAAAAAAAgFeGG/AAAAAAAAAAAAAAAAAAAAAAAAAAeMUUKbJpbCK1RjM7r9yTYm45RbuWo9XTaT70YBonzmW6MZ/+kVqe+uiXc9ObXp/pW7bkurN789Azn01XVy0DAwPptJZTq1VTr/fms597IsdPTefw8Yt57XUbsrG/yNjwYP7sCwdy773rcvHAo9k4vjOd1lI6q42srFbSN9CdFD3ZUE5nYHggs3ONHF7syh239qdvcHsWlmczOdvKaqeVVvtkiiJZbpbpVJK+weR/e+B/y4urs5lbrabS253jxWrKzqW0a+21rhgAAAAAAAAAAAAAAAAAAAAAAACAy0RtrQMAAAAAAAAAAAAAAAAAAAAAAAAAcPko2kmtWcnusY1ZnppKdyPpGezPXVe/Ie23vjmHf+MjqTXn09zUl907t2fp+f3Z/Zobs2njRCYGu3L7DVelWq2mu6cvXV1dqde7s32kKyO9Y3lw/2Se2n8hb7rnqswttvJd77ktM+Vwap3xHDpyLEcPP52iuZD+vt5sv+L69AwMZ6ankheOncpXnzidof7TOX12IcXIjnzTW67PYG9vevuaqVWrWV1tpd1J+oeT5fnk8cZMLq6uZqXTSK1Wz9hALUM9RVZm22tdMQAAAAAAAAAAAAAAAAAAAAAAAACXicpaBwAAAAAAAAAAAAAAAAAAAAAAAADg8lEtilRbRTqrtew78FwuTV7M8sJ8ls/PpdJd5Op//Pdy4xU3Z2ttY6Y2LeXU0IXUZpayfv3GvOl1t+TN992eSqWS4dF1aa+2U5Zltm4cyfU7x/Ptb74+rUoth0/N5rc/+UIunJ/NyvJyXtj3fJ597vHUe0ayace1Gdu4O3Nz0zl7+kjSuJRqUct3vefuDPUmWzdU012ZTaV3KFfs2JSR7t0Z7NmdagazOJvMzyVlPVlsFxmsdqWeIiuddq7YO5or93SnXZZrXTEAAAAAAAAAAAAAAAAAAAAAAAAAl4nKWgcAAAAAAAAAAAAAAAAAAAAAAAAA4PIxv7qck1MX0l10Z7hnOK3aQjrz01mZmczkuen0bdiQ0e3bcuVrbsmeW+7KdXe+JYfOn053d29uvP7K1Or1FEWRsizTXm2lLMtU2p2cODeTHZtGc+8149kx3pO5ldUcODWX5ZXVrCaZ2Lgp60Z70q7WslquZmZhKfMrqxnfsjNbrnhNLi0NZd3oYC4cezH33rk7leZstg5O5dzUqRw5cjKt5Xa2rB/KRHc93UXSVyRbugZzU99E+qqV3La3ndtv2ZhOZ60bBgAAAAAAAAAAAAAAAAAAAAAAAOByUVvrAAAAAAAAAAAAAAAAAAAAAAAAAABcPoqiyIX2xbxu/Y2pjI5ldXkmZbmQ5uqlbNqwI5V2J+duuyqLlVquW9mWWrOR4tzFNDZWMjA4mlq9O51OJ83mUrq6ulOWZbbdeGOu6ymye8/29LRnM7fUypMvFPn040fzQ9fdmE7RSlFZyWJjNbXuThaWV1KrJbWurhy5uCntlKmmyJ6d4xnfsj21skxj+kIOzy2l0lukq6c/G7bekEZrNfOXHsvUciuXVldzoj2Zn93++iydezJffXYxtfpi2u21bhgAAAAAAAAAAAAAAAAAAAAAAACAy0VtrQMAAAAAAAAAAAAAAAAAAAAAAAAAcPloD1RTfcc1+dTR2ey6aTjnT1dS3difHVevy0jtSOYOPZXpM4fyuYeWcuT0hTRWFjNeHczWN96b2vitGdw4kHazk/Nnn83i/CMplztZHLqQ/lo1zx5/Posb5jJ5cT6r165mfdGf40snc2r+WEb6k+7upTRX+7LxiuFMnVvK/FSZ5XozrWpXJs9fyLqh0UydbqQz9WI6U808v9KTHRNjWVnoy8L8dJ57cSbTK5VUt3Rnz6vXZbg6mqnBSm7bvjPn+4tcml/N8ODyWlcMAAAAAAAAAAAAAAAAAAAAAAAAwGWittYBAAAAAAAAAAAAAAAAAAAAAAAAALh8zC218xfPXEh/vcjed1ydsx85m+aJ1bz+n16dmydPZXlpX5YXXsqb33Nffv1PTuXFIz3pKTo5efjG9HZq2bPnzjSSHFndkuee/FCWTpzKpncsZKmxmHq9nlpZT9FVzdgt69LX3Z+F+fO51HoyfdW+ZLgrXT1lGn3jqS0v5XxzIU8ePJyJjRvz8L5T2dRfz865Zprb6xk+08yl1kI2Li7nU39RZPeWnjx7aCUj62qZWFfkDTfvzsTo9nRWVjJ6aSo7BrszNVfm6Rdc8wcAAAAAAAAAAAAAAAAAAAAAAADAK8MNeAAAAAAAAAAAAAAAAAAAAAAAAAC8Yrp7u7J4djnL1Wpm//mz2XDjQIZu6ctj/+RC7n/XVzM6MZyhjevTWTmSv//tG/MD/+ZMpuaWM37uVFrb7szM+Vb6R+vptNtpL25LMXw4nRQpKkWKJONP7szQwNZM9F3IwUuz2XnTq/O691yV558+kruvvzepTeXpc/vy1Nhj2VjZkMH2tuxovy659mMpz1yb+roDGVyazth4I+XFuZxbHsgVu7tz9/pbM1A5lTff/a053/hqbnjVTTn+4hfSWGqnVpnMdHNDKj2jqRSu+QMAAAAAAAAAAAAAAAAAAAAAAADgleEGPAAAAAAAAAAAAAAAAAAAAAAAAABeMavNThZWG+mUZTqzq5k8sZC+kXrqrb6Mf/+daS1czMz5mXQPLqe7byD/4E2N/M4jmzJ81UJWqz2pFEXmZ8psmhjL5/Z9Ntvf3ZtKZTWD7Yn0zfSkttSV1eZCemvdqU22MtIaz2u23pTbK3dlrno2zxw9nzftflduGbsnSwszWXppIAMX3pxrdn025eyrM7dwRyqrv5H9p2bTvyF59oWFvP++O/Otd/2TXP2XL6R7YkPmji7nxMlDGVq3M+1qTxaWl9OzvJLh/t4UlepaVwwAAAAAAAAAAAAAAAAAAAAAAADAZaKy1gEAAAAAAAAAAAAAAAAAAAAAAAAAuHxUu5I9d09k1w3j2f3a3dlw82C23DeR0dtqqbUvZHTDDdmy7bbMXlhOc2EmE+O9+f7XXpvq6OvT3T2SolNLZ6WZA0/9k3SNFlk+UEtRKZPeVjobm9m+ZU/uuOu6DG27Mhs3jKUzO5PTrWfTbq3m4c/+ZT7/6KOZyKZcMXxVrht/c6o79qfe7M3M0ZtSm3t1eqqDmbr4zpye3p4zS0l7pZq3bv27yUIr267ckVZnOiOVvly7dVPGF9u5bsuOtPe9mK2DI/nLLz6fdumaPwAAAAAAAAAAAAAAAAAAAAAAAABeGbW1DgAAAAAAAAAAAAAAAAAAAAAAAADA5aN3a0/u+Pm9qS1Wcv3ub83gUiftSiUvHXsxnckjqRdlTpzel3r6013pz7mzJ1PUX0j/hu9LKt2pl2UunH8xC4uT2XH7WKaenk+lqKZa6UpP12iaOZAnFtqZPVikZ7lI1ncy1NiUyvZk7+nX5fylj2di3WgOX3ouI/392Tj5rhQ91axbuC+11fn0F31Z33Vr3rLzvvwf829OpSjT0yny9AO/kav3vDNd8yupNYuszCzniWONjC0czJefPZsHnjqdN7z7XXn4hT9d64oBAAAAAAAAAAAAAAAAAAAAAAAAuEzU1joAAAAAAAAAAAAAAAAAAAAAAAAAAJePgfZwdu6/M81LK5k+fDIrGUl3vS87O1dlqXEsF849laH1WzPUbOTc2cVMbB7Mpanj6R4cTlEpszK3koWlVi5eeD533rErRy4eS5FLSdFJV1nNuWtXstyaS/PKpKs2mGPNY7n35J15rvvJtEb6MnDdRP74E/8+x6oP557rvy/989dnaaGZrgtletZfzGKrTLW9mN5qf1Zmk029Q9n9za/JFx74hVx7RS0XL5zPrje8Jjvfcn8ONf84+/a/lL/1D/5R1o0P5ebbX5Nf/f2Pr3XFAAAAAAAAAAAAAAAAAAAAAAAAAFwmamsdAAAAAAAAAAAAAAAAAAAAAAAAAIDLR19tIDdvvjuzgxczPzufxkoz1ZWr01wpcmzms1nu9GTmxbPpKTqp1GvpGl2f5tK6dM7/Xuqro0mrkx3jldR23paRynB2bFqXs0e/mLlLC5lePpZUk4m9AylbrZw5M5NtY5vywuzjGdpcz2cOfzInTkynffFguoZq6Sx8MjcVc/nywePpq5fJqVZ2btyZpaFmms1O3n33ezPU1ZvPf/ETufODfz+t1TKbRsdSji5mZmE4O/fsyVTjUp7Y/0yqRSuff+TBLCwvr3XFAAAAAAAAAAAAAAAAAAAAAAAAAFwmamsdAAAAAAAAAAAAAAAAAAAAAAAAAIDLx+LSUs5Mn870wpmcPn4qJ19YyJaJmzMwtD6nTvVl78beLLe7MrO8kOZqkdMvzuXMpbN57we2Zv8jf5D69mtTT7Jr4urUan2ZuKYnT/3y53P64HKW08lAvZrW6UrWXd2VDcV4+ppz+cyBD2X1uSJbNtZTWanmUhZTXejk4pMzGbtuOl88fyTV7u4sLsxmw/REbrzq6tRXT+X73vczSZKyKFKUSafsZMPu3UmKzM43M7jxiuwt6/mhf/g9WW2VqRVFlhfKNe0XAAAAAAAAAAAAAAAAAAAAAAAAgMtHZa0DAAAAAAAAAAAAAAAAAAAAAAAAAHD5aLVW8tLzT2Vxci5LF2fSWhnPyLrk/m/alLIsc2ZyKVOzizl4dj4nLsxmfqmVWjVptBay0NOVnno9Rx7/Slanz6e/08xqu8zK1GqKIhkcrGd4Sy2XjqzktXvfm7/3zv8t81MDKYvk/FSZU6daWVlazVBPO12VThqNdvrLc3nLNSO5ec/O7Fw/moOnJ/PQ40+k09efFEXKTjvptNMpO+l0OinLMkmZp154LLVqJTdcd3N+9Id/PPVaLe12udb1AgAAAAAAAAAAAAAAAAAAAAAAAHAZqax1AAAAAAAAAAAAAAAAAAAAAAAAAAAuH43mcv78Tz6Wv/jkR/P00SdyaOGBXH1rLV21Sk5eauSZk9M5enY2V7Vnsr6nSLssM7+8mr7+0Xznd3xvNvZVMrM4k3PPPJVGp5NqUaSsFukbrmfHnb0Z3dWV8au6c1f5t7Nl60Q27r4ixeC6dPUXaVSrGRkpMz7YybU7y6wfLfLJJ2aytLyUNKZybraRKzYMZ3Tdlqy0ulIURYpKNUWlmkpRpFatpiiKJMmG9evT39uXyfOnsm2wL295yzuTSiUvfw0AAAAAAAAAAAAAAAAAAAAAAAAA/81V1joAAAAAAAAAAAAAAAAAAAAAAAAAAJePaq0r4+s3Zv2enRnbsiE3bbop/dmcX/zVX0ynXM39u8Zza2Uqv/LEibxwYTEDA/2pVIr09vRkaX46V117fSb6Krnpda9NX39vitWlLDfaqaaSpJNOs8j73vL3MrVyLPNTKxmo1nL7ledz3x2r2bS+O6cnk6t2rGbPjnY2jietZjNHJltpNJtZarSzddOW9Hb1ZdeGTpKkqFTSWV39D89JUpZJkqGe/syeeDj/9Ae/I+ObtudH/94/zL/4yZ/9/30NAAAAAAAAAAAAAAAAAAAAAAAAAP/NVdY6AAAAAAAAAAAAAAAAAAAAAAAAAACXj+XFpazfMZI0Orlm3VX54Lf9nezalNx+07Z02q08/fzTeXp6OevXj2d2sZGy3Ux3Vz3t1U5q9b782Sc+lovz7WxeN54333V7qtPnU0s17UaRxkxy9TtH82zj99PVPZj5Swvpymp6+pKB/uSKHbN5422refzFSl54qczb72lntbcvG0e7MrO8mv7uSp4+ejqzk4fS0zuU5tJiVmamsjw7nUqlkqIo/sNfikxOTuWxJ57OzoGlHDn4Qnq6u3PPq1+X3t7eta4YAAAAAAAAAAAAAAAAAAAAAAAAgMtEba0DAAAAAAAAAAAAAAAAAAAAAAAAAHAZ6VTy2OPPZvlUcnTDZL7r7d+XkfHB3H//t+Rzf/z7efhCO91FsmX9eBaWV7PSbGRstD8PfeHPc/tdb8n04nymOu186TN/mbve9PYMjI6kSJHOSiWVeiWXXqimMlvJQ9VPZP2RHalUz6coyjSbSbuV9FZW8/bXFNl5xXh60szVe7ZmpLuVZx6/kEq1ltnpmTRqye/9xVO5523fnUvnL6Te1ZP+kXYqtWrSaafT6WRucTGve+sHsthIbr3znjz9zBOZn19OT1fvWjcMAAAAAAAAAAAAAAAAAAAAAAAAwGWittYBAAAAAAAAAAAAAAAAAAAAAAAAALh8DA/05p33Xp2Fk93p7u3J4cOP5ezRF7Ju667cfs/rcvfqcjqdTjqpZHZ5JZ12I7317lzo+UKeOvXR3PSWXenedSF7t03kyOlns+Pq3ux543XZub43u+7py4XjM5k52J8vHvxw+rpHc8tEf2rFzix2rWa1azUpimSkyKb11+Tk8bnMNC7l7Hwj1169KSfPzaSrdziVosi60f60Bx9PY3s15eF6XmxeyPEXz2VpqZ2yTD796Qez7epvzu5X96Td+0K27OrPkQOdVGuVta4YAAAAAAAAAAAAAAAAAAAAAAAAgMtEba0DAAAAAAAAAAAAAAAAAAAAAAAAAHD56Oup5NvvuS/VykAGhwbz0Bcezu6JrlTXdfI/fNv9+chv/nxSrWZwZCyjPcuZungxKwutvOq9tXR1zaXdvpCbrqpmdXl/Hnp0Luv3lvme69+Q9/7EDyZFO195/K8y946TeeGffTmt6lwWu4ZzqWdbppozqXQ1M90sc2qxK/NnR9Lbvy3/43v+KN0bk6H6TAab7SyuJlPzybodc5nf/NVcPLk+R88/nAefXc6JiwtpN5M0k0310Tzy4i+mt3tHhnfens997kj2bH1j6t2u+QMAAAAAAAAAAAAAAAAAAAAAAADglVFZ6wAAAAAAAAAAAAAAAAAAAAAAAAAAvPKKoqgWRfFUURSfePnzWFEUf1UUxcGX/x39a+/+RFEUh4qieKkoirf+tfmtRVE89/J3v1gURfGf37ia4eGtmV9YzMz0fPbecFs+/ZX9qWQ1fdVWbr96S65cV8tI43g+85UX8tRLpzM2NpqiaCZFJ9smKimKarJSz4b6hlS2ns9tnzmfC198KQcffyQn/+jZLFxayW1vui5lT3+6qz3pa9VTb3bS1V5NV7uZWyZ2pbnaSr1ezXJvLUdPbszpA52cOr6SmZMrGVi/lCf2LedLT57NT/7op7KnvCqVTjuVTpHO6SLL82W2X72cj/xJJ3/0x8fyyY8eyMLseI6dOZ25xcX/JucFAAAAAAAAAAAAAAAAAAAAAAAAAP+x2loHAAAAAAAAAAAAAAAAAAAAAAAAAGBN/HCS/UmGXv7840k+W5blzxVF8eMvf/6xoiiuSfLtSa5NsjnJZ4qiuLIsy3aSX0rywSSPJPlkkvuTPPD1Np2fX8iDn/2rXHfzjVlZnMnq6kJuuvnGnD9zMtt335J1Y+sy0F3LyRPNdCafyIFTizl3cS7vfddgllZ6cvzM+Vy1qy8vPbknzR37srHWk+fums3pv/vjea6+kOq64VSHu9O1sZp6sT699cH0ribj9eFcqvbmpr7ZtBszKXvHUqvU8r/88pXpWW3kym0b8u4bT2ZguJPBepH9U8lnnzmZV20bSmt+NjtO1DO82JejO6dyYSoZ6m/lrjdVM3XwyjSWJjI/v5T+/mbKsvPf4qwAAAAAAAAAAAAAAAAAAAAAAAAA4D9RW+sAAAAAAAAAAAAAAAAAAAAAAAAAALyyiqLYmuQdSX4myY++PH53kntffv7tJF9I8mMvz/+wLMtGkqNFURxKckdRFMeSDJVl+ZWXf/N3knxzkge+3t4rjdXMFhty7NDzeXR/MyO9l3LqxHze/z98e5rN1ZStlfSv256rxrbmp6+6KftfOJzPPPxYVlqtlMVyjn312qR4IjvfdCmXWr05c2kpT7f3Z2V0MRdPzqU9P5l1p3dk5eBcTh2YytLe3rRH6xlbP5aZhbMZ767mwccu5OY79mTnC72ZOn8m44Pr8+KR5WzbNJR7d11Kp50UreTUM0V6VhrpurYvEzuLDMz25EStK8VUI5VLI3nVG4Yy03NPDh96Kecvzaa3q5pqtfoNPCkAAAAAAAAAAAAAAAAAAAAAAAAA+Npqax0AAAAAAAAAAAAAAAAAAAAAAAAAgFfc/57knyQZ/GuzDWVZnk2SsizPFkWx/uX5liSP/LX3Tr08a738/B/P/xNFUXwwyQeTpLe7nrnpcxmvtfLS/v257uoNWZ45mbK9nJ7ekSydP5auhZnUx3enu38iN986lquu2pNPVH41k6fGMpItOXfgdNbd3sre9a/N43OP5MDxsxm4vpFiuCftfc1Mff5MTozOpntgMK3VVubajUxfXErPZCdvPPumDDfO5tVdV+fCviMZ6V/O3NzZ3HntcMrOpfTUkhPzyYatyYZ2PTe/6dqc7ZvM4uG+vO66K9Ls6s6nTh3NpbMTyeSuPPnMA5k+U6RVqeepx0+n3S6/AccDAAAAAAAAAAAAAAAAAAAAAAAAAP95lbUOAAAAAAAAAAAAAAAAAAAAAAAAAMArpyiKdya5UJblE/+lS/6GWfl15v/psCx/tSzL28qyvK1ereTSuaN56oXz6e+v59Dh8zl4diUPfv7BVHsHk+7xHHvuqbTLMt1Dw+kdXZ/hdRvTU+lNb4bSbJ/Phj0ruXLH5rx44XPZu30sc0t9OX6xncmh5bSvHc3x/uXMLjYyf+liGrVm2u0y3/zElvyTZ9+SgbP9ed25LZl+eH/GVlp517cu5lU7FtNfv5CDR9enq6uS6XbS1ZvcuLs7xcHT2dk9kjuv2pTpvYeyaWQhb3zHWK68fmMOHj2SJ756KnPNqSzNreTooamsNpb+C2sFAAAAAAAAAAAAAAAAAAAAAAAAgP93amsdAAAAAAAAAAAAAAAAAAAAAAAAAIBX1GuSfFNRFG9P0pNkqCiK30tyviiKTWVZni2KYlOSCy+/fyrJtr+2fmuSMy/Pt/4N86+rUq+mUduSnbuuTqf3UC4t9GX38Epa9TIf+cifZWm6K3Nd12R9MZBqp56kkkrPaEZm7kh/s5rGts9m+Wg1vzN/NLet3JH2SCV3XzmfowenMrxUz/DOajZOJ4ObXpVOahkvklrvhYwNVvKxqz+RG06uT1fKfKbzQt696YrseNX/mBu2NfP8kb7cv2MpzU2vze5Wmf7+ModP/FU6890pi7ty4tKhfP6z53PlrmszP/li3nrvtXn0mb68/4P96e+r5qE/vZT+nXtz9tzh//cnBAAAAAAAAAAAAAAAAAAAAAAAAAD/BWprHQAAAAAAAAAAAAAAAAAAAAAAAACAV05Zlj+R5CeSpCiKe5P8o7Isv6soin+T5ANJfu7lfz/28pKPJ/n3RVH8QpLNSfYmebQsy3ZRFPNFUbw6yVeTfHeS//M/t/9SYznr143k/X/7B9PuTKara2v+4qN/nH//ez+V577yaJZbZc7NL2bbUCdXXvWqdFWSolrL5gvvSeP84Tx48JP5fNel3Di2J4ut4Qw3bs3bdh3OM0tTqT5eT3HuYra8upYbF4r03XdX9j/6fIa6j+TAq49koJMc3vBS1g/X8r3bVrNaHsj3fPOnk0qR9yZZabVy+PDRXHvtVUmKvP3vbssbr9qU73jfN2XL7UP5zE98R5aa9Yw2b8odN92X1975xixWDuexvxhLbfNg2kMb8qHT7/tGHhcAAAAAAAAAAAAAAAAAAAAAAAAAfE2VtQ4AAAAAAAAAAAAAAAAAAAAAAAAAwP9f+Lkkby6K4mCSN7/8OWVZvpDkw0n2JflUkh8qy7L98pofSPLrSQ4lOZzkgf+Sjf7q4Q9n/5d/Izt37sjCyYfy4Mf+XarppN1uZ6nVzHBXJSuLi2ktz6eSVtrt1Tz+1OfS+VA9V63/oXx37aezbv/O7D725nz14gMZ+fyFTDxcy4mTZY6Mj+bEseRzzy3kl37mU5maTl462pXuapGluWrWj9ZyzVVbU3aSk9NJqtWkWktq9XzrN78v99375pw/ey6p1jI/1cyffvFYFhtJtVrJq2+5PXfvHs/EeH8Ov3gsZw5056GfuSkv/O9XZeH5jamkJ/WB1jfyTAAAAAAAAAAAAAAAAAAAAAAAAADga6qtdQAAAAAAAAAAAAAAAAAAAAAAAAAA1kZZll9I8oWXn6eSvPFrvPczSX7mb5g/nuS6/9p9V9LKQ3/1cHZedU/+6Jd+IccPnkzfxpF0yqSapFatZmG5kYWF+fR2VVLUa7l25F2ZK57PkQPHc/LiVDbu2ZqPNn4lz2Rfbj9zKdcXfblpUy0zozvy/NhkPv7Usax0Kqmd7eTUuU66utbl6QONjO1bza4nzuTuqyuZnEleU6snZZknv/pIjr10ILUUecf978rjzz+XcrWT4YmefPpzn8t9970rp0+dycXTS5lvFRn68NUZWXcu55/rSbU2nKIczOCGpVTbQ/+1dQAAAAAAAAAAAAAAAAAAAAAAAADA/yO1tQ4AAAAAAAAAAAAAAAAAAAAAAAAAwOWlWhR55InTmfy3/zyD3ZUktXSWi0xXkt5KJbMrrVQq1YyNjCSVSspKV366+fezfkMzxdRinn3xQspDA+l+/XR2VJNnKxMZWp7PpqFk8omnc/0H96Y1XmRdq57DQxO5NH8xsyt9SdlMkXrOTRdZaLZzfr6SFNWkSA48/VT+5U//ZH7tl381X37imTz2pS+md6iaPRMD+fznP5bFlTLDI8P54heey+imDdl58440B1bTGDqXsfEr07x0MaeeWU1jpmut6wUAAAAAAAAAAAAAAAAAAAAAAADgMlFZ6wAAAAAAAAAAAAAAAAAAAAAAAAAAXEbKZKSnPz0Dkzl38UTOLS6k2tOTSndPJsb7s268L2W1loefOJDn9h9LUVRSlKvZ13g+7bmDec2rG+mqtjI0lsx0Jft7k+fnO1np68mFla58plXm0x87mxcq1ZxodjK1MJfeWiOthbNpt8t0VpoZrDdy9kJPKu2+JNUklTSnzua666/L//RDP5htE2P5Bz/0wym7iyz0N3PfrdcmnVbOTM1lqaxm19aNefC5B/PIn+/LQL2WzTduzN7b92bbdbtS66qvdcMAAAAAAAAAAAAAAAAAAAAAAAAAXCZqax0AAAAAAAAAAAAAAAAAAAAAAAAAgMvL+LqRPLLvYq7aVcny2VOpDfamVi1zfmo+c4tL6apUsnf7RMrGcmr17rQbK+k+XMn+65ILn57N8J5KitWlvGH7G7LvyOdyYGYlX55aSFlJ+qpFDu6fSaenyCONMvdWl1MtW9mztSubJpJzF4tMziZzC81MDC8nZZkURb7p+344C1MXc80N1+X//r9+MfPLy/mHv/5j2T22JxfnFvPS4S+k0Uo2bZ3IkQsXMnVoX67a2p99L9Tztp4rc8V9V2Rl8lC6+oq1rhcAAAAAAAAAAAAAAAAAAAAAAACAy0RtrQMAAAAAAAAAAAAAAAAAAAAAAAAAcPno7enNB97zndmx4UCOHj+VLduvzEv7H0qt0pW+gfl0r+/N+rGNWaytZmVXO4/PP5neSiN/9/V/O41KO48ffSB3vvWb8/Cjn8u7N39L3tq9M7/0lY+nf/3G9I1NZ3y0lZlLzTS7qmm2WlkcGs1dV/Sl1lOkt9JItSfpqVYzNlRLu+jPs4/8WqaaSZHelNXVVCrLKTdWM1QtsmdwQ161YzydxmKuva6aTqU3ff0TKYpKzs1XMzTcm2uu25YdO9sZqB7JZPWns9I+utYVAwAAAAAAAAAAAAAAAAAAAAAAAHCZqK11AAAAAAAAAAAAAAAAAAAAAAAAAAAuH+1OmfFtd+V9b7wiT0+dy+ZNW/P0wYcyv7qQoZHRlI3hDAxszsP7j+SpxX0ZuftMNk5U8y/ufCkjt+7I93z8tfmf7/2F/NKpf5g3bH93ht70PfntFz6Vxcnz2X3z+oxeUWR5eSUvHpvPDetuzKbpG9O7OpN2mXR3JTvqK1k3PpKVlVa6+wdSX/n1/MlHevL0U5MZnxjJ1a+qpKz1ZHy4TM/gviz117K4sJKx0aVM7O1Pf/dEtq2/Isf/9EI2rt+SrW+/PfWxF3Ju/sHsXZ1PpbOy1hUDAAAAAAAAAAAAAAAAAAAAAAAAcJmorHUAAAAAAAAAAAAAAAAAAAAAAAAAAC4f68dG88STD6fVVeTKnXvTWe1kdbWdpJLsOpJq73y+9OBnM1c5lOkD3RmY35VqrZZ6pZaZF5/Pd7/urlzc/2B+5Cd+JpWJZuo9ReaHVzJ8dW9ma6s5dWI6C4vr0letZeP4d2XDhlelXG2lUrbTarWy0mimt9LJhQsXs7y8kn/wkxfTmhvKzit7U+k+lqx2srx8PGcm92W+q5PnDuzPD/zgB/L6+1+bTSO7cuLLM3n6iQczOH8mU+cP5CsPPJCD+57MySNncuHopRRlda0rBgAAAAAAAAAAAAAAAAAAAAAAAOAyUVvrAAAAAAAAAAAAAAAAAAAAAAAAAABcRir1fOFzn88XvvBIdm8ZzWKSokze957vylfKn033ppfSP7wtG19f5tM/M5djn96S3RtOZWFsOvPnLqZ6bjh9wwvpnJ5MV2UgzemFTJ1fTbVvOeNL35nV9peyccersmPzcpYaZ9Js92TH2HimF+czN7+Qnp6efOGhfalUO5nYvCX7j7dyz5tuzdPPfS617tEU9R1J78kcPn0h27aN5+brr01Pz1BSr2b+kfOpXlhOuXU4Z6pnstJYyvknT2SuOZaZpdmMF71prpRr3TAAAAAAAAAAAAAAAAAAAAAAAAAAl4nKWgcAAAAAAAAAAAAAAAAAAAAAAAAA4PLRXl3N2dNnsmv7lnzyM19Mc/JSxnsGs37dxrx+1978wFt+Nze9s5Fr1+3JQF9PNo3Xc/3IGzNzbi4Te29O5dqdWfeWN6d5upFGOZOVM3OpV/dm+/Z/nYmtd6TWe216eh5PWRRpLvxaytbTOTU1lbLspH9oJOmUKWqdbN68KemUGegfzBPPvJAvfeG5LC01sv/sZzL30jXpa+zN7m3j2TQxnp7aYJaWpzJY9GahsZLTkys5vb7MwZPLmS07OfDkZA4cTR44einzzdZaVwwAAAAAAAAAAAAAAAAAAAAAAADAZaK21gEAAAAAAAAAAAAAAAAAAAAAAAAAuHzMzs3lhz/4gfQMbUyrvZzPfP7B/E9/+9uyeePmbF/3/jQ703n9zn+aw+f/Iu9+03XZtPf23HX96/KX/9e/yJ6j/zg/+5s/n5+9MJBnZj+ZHRsG8tpv+rHceMv/kiuve3MuTv56JtZtyfJ0J4cPns3GsVraPSsZHJpIrVpPpdaVhbn5bN6yORs3bcjCciP17q58+YufSb1eS7O1msbqpVw89khGR/Ykx5Yy3Xc4F0cezdNPPZE9c5szOT+XfV89m77pTnaN1jN473iu39CVF7IjS/vO5tmXDq11xQAAAAAAAAAAAAAAAAAAAAAAAABcJiprHQAAAAAAAAAAAAAAAAAAAAAAAACAy8fgwEA2bdmSSxeOpLe3J+3VVgZGN+TzX/5crtnx3alVe3Lohd/K3pGl3PeeG3Lb629Mb60nT04+mn/2K+/NSE8nfbuvyoljB3LnO380M8emUynGc/LMC5k8/XgunvlQ5hfOpFU00tXbn+XFlZSrrSwtLaZatrJzz95s3LQxvb19GRoezdGjh9PT05ve7p5s6d6WiyeLLBSLOXzxuTw7cy5n9i/kzMmnUllelz988UBOZDFved1tKfv7c2RiNZ0N42lvuzvrNmzL/NbhDAz2r3XFAAAAAAAAAAAAAAAAAAAAAAAAAFwmamsdAAAAAAAAAAAAAAAAAAAAAAAAAIDLR727N0ud8azfsS4Pfejnc+XmifzhH/xhrrv7TTn/lS9lpFJPTo6kOl5NozqV+dbBjBXd2bztynTfltx51RuzUj2eazdty7EXHsmzTz+YbevelGL5YhYnD2Zxusjw0LZcM1pNa2E1g30bsrgykK6uegb7BlJ0DWe12kl7sZKhvsHsGa+lr3sxvQOj2T3Wzotne9LqlOmqJ6M7359D881c/GwlLzXns/UNN2b6Yjt7b70r88uPZmFpKtVGJbNzY0mnk73rb8qD1ZfWumIAAAAAAAAAAAAAAAAAAAAAAAAALhO1tQ4AAAAAAAAAAAAAAAAAAAAAAAAAwOWjp284N9z5Ldn/7OO5dXkmy2MbsrTYyS3jW/Pcg3+Ut771quw/3Z3uG3anvbQzI0VPdp54MLdte3VqO2spspjJhb/IyI0jOTfzxYxvbeW5P/7Z3HbTrlx6bD5vfP3bM31pOl2NZhqpZdvWq/L5zz2W1spqbq7P5Or3/ZNkejDNmdlsqr0qO4aW8rpb6pmYmMpjL13IbZuLHDmzmtnFInMj/zKtgU7m13cyVKtkPkWqw508cL7Ia3YmRaWW1eZKaqtdSVGk0lVNvfL/Zec/o2277/rQ+zvXWnvt3k7Zp/eictSPmi3bkrvcjY3BBAKXkOvAQyCk3ABJbnIvTxiQG0IgBEJMCCUYjDEY49iy5SrZsmT1fqTTez+791Xm84JDHl1iTEhs7Yzsz2eMOeacv/kv3/mb7+cnlrrFAAAAAAAAAAAAAAAAAAAAAAAAACwTlaUOAAAAAAAAAAAAAAAAAAAAAAAAAMDy0ViYy+kDT2Wwq5Lh6mIeODGbE7W1+U+/+Uvpfus1mezZkzu/bU0mqh25tvlcitmZjF0sUymKFGmlKIpUah0p0k61Vku9pydb1m/I3GLy2tfensEVK7Jx7arMjE2lOXEx7UqZt7/urrzujluz7/DRTI5eTLp6MrRha6qr67n5VdtytrU2fdVW9m6v5KqRMjduruTmrZVcO3VvmhMXMnfyxSycejFZnEmlWk2tVk2ZStrtMtWOrrTaZdrtMvNzM0mKpW4xAAAAAAAAAAAAAAAAAAAAAAAAAMtEZakDAAAAAAAAAAAAAAAAAAAAAAAAALB8tBrzGb14IhMnnk1j/TVZsWln9t66N+cqfTl/djKV/nMZe76V2seeSdfp2RybPptjHc2UZSvtFGmXlbSbzRRFJa0ySVHLwtxkhvqGs2Z4KL21Ss6fO5/hNSMZnZ7PzOxcrrx2T2YXk6ve8u6MT4+n1ltPdWVXqoNdObz/ZKYvnM78RCvN6UY2DSfXbqzk9p3JTc3PpP/YZ1M5+PksPvuJTD37pVRqlbSLpNVq5fDBfWm32ymTtMuk2WilKPzmDwAAAAAAAAAAAAAAAAAAAAAAAICXR22pAwAAAAAAAAAAAAAAAAAAAAAAAACwfFSqtWzccVXarTL1ajOjTz6XL9336Xzbzbty6Nzx3DN9Pm+ubs4nnvlqBletSrmtku09a3P04oG0W83UarVUKtW0Wo20moupd3VnrtFId7WZA08+mWpXPQszs3nm0Kns3DaSUydPZXzz2VR6KulftSuN2WYa1WZWDQ+ko13PyMBCDh2vZmJdke27q5k+XWbzFUmt1coftd6f1s61WXX7hpSNhTQrPWm1yhRJ2u1kbm4u7bJMWZZptRqpdnSlbLeXusUAAAAAAAAAAAAAAAAAAAAAAAAALBO1pQ4AAAAAAAAAAAAAAAAAAAAAAAAAwPLR2d2Trds3p2y309Xxytx95a25+hVHMtTblS+f+Y0cODmT7940kuqKStbe0p9jlUZGTz+e+fmudHd1ZHZuIbVqUi2KdHXWszA7nR/8/vfkqccfy+TYmWzeuTvd3fPZVtmWWqWV4b6+PHZoX1548WD23v6aVPo6Uu+rp+hIanMdWbGyzOxYK2dHKzn4xVYu1dblrubZTI2WOfemG1Ord6dMkbJST6VVplKUabeToijS3dP3py9VtlOpVFIURcqUS9tgAAAAAAAAAAAAAAAAAAAAAAAAAJaN2lIHAAAAAAAAAAAAAAAAAAAAAAAAAGD5qFYq6eqqp91qZdsVV6cokp17rs383Fx+5+d/IZu2rc2/PvV8PvCmazL/8OHsWLE193WMpzW3MmXZTk9Xd4oiqXZUs7DYyIsHzmQ+E1k12JmL05WsWmhmpjif0bEy1125Kzt2bMiZ/aNZt3U4zbKVjo5qOiq1dM50pmu0nZ2birQnytT7ytTH23n46Gxu31PP2Mm5LFa7UimTVqudsixTFH/2FmWKFFm7Zn3arUZSFKlWO9JqNZPiG709AAAAAAAAAAAAAAAAAAAAAAAAAHzz1JY6AAAAAAAAAAAAAAAAAAAAAAAAAADLR6Mxm+NjD2dicjaTY600q810dHRmsLc363vHM9RcSL1/MF84fCprz4xl6uiF3PCdG/LkC9XUegYzszCbk6cupqejnlrfSFb29OS+QxdTqQ9m/6mT2bhtOIuN7swNjuaPPn9/vmfl2tQ6ymxfN5xWYzxlszND++dSVBdysWhmor0+GW7l/NRszo2XGa4u5KEn21lZH0pm7k2zXSbtSpplO0VRSfv0o2k0mll91bG029WcPj+cWqUzlVo7tUyms2NuqVsMAAAAAAAAAAAAAAAAAAAAAAAAwDJRW+oAAAAAAAAAAAAAAAAAAAAAAAAAACwf9VqRF9q/nflqPa3uav74C1/M+fHF7N19Q374zmRx6ngG167Mbz15MA/OJlNTyduefipzE+/Otptvyr6nnsrzT72YK1b05H1/+zsy/fhnMnDztTl19vms2lzNl598KG991xvTePFcLnTPZt/TT+TNN92QV7zilTn2wjN59NnnU9nSn+23DeX4/tP50sevyGKmc/jA2UxPLeT86Eymxhv52TuvzovnfjKNJH2NrizUK2m1GmmmlUbm8h1vOJvf/9hwPnVvV+7ecSmnJ6u5Zk8t/b0TS91iAAAAAAAAAAAAAAAAAAAAAAAAAJaJylIHAAAAAAAAAAAAAAAAAAAAAAAAAGD5mJwYTWXfXGbnF7JqpC9vf8ctuf7a9Tly+HjK5qX0rduYyTPncvebelNUy6wdKXN6NFmzZUuKopKBFatz++23pL+3L+cf+mSqZSuVajXtdtKulfm297w9Lx48mLnx6UxNlumtdmRk5UCeeezhvPjkY9m+aUX6tm3JyI4t6R8eyPjseObai/nhd/9Arq/Xs6rSkXa7SHWuTKNRTdlsZ6y9kMZiK+2ymUqtkmqtI899qshzrR/J4thont1f5PiFeu57YDZnTleXusUAAAAAAAAAAAAAAAAAAAAAAAAALBOVpQ4AAAAAAAAAAAAAAAAAAAAAAAAAwPJxYWI6f/hLz+Sz//ZkDo4ezvTCWK7ZuCU91YWcPtHO8/PHM12uyYXpjalWkhVDyddeGM7gQF8mx0fz3L6DmZqvpt7Xm7LVSEdnVxoLSa3WmT0370n/6lU5/eLxzC20kvkizSI5uP9gzh47kqGh3jR7atm9Z3uykDz3tSdz9uKl3PWqW/KK77syD1waz8qBen7wdW/IZ0+cSJpdqVQ6UqmUaaWRVrNMu53UO6p57nSRC898JDvWLGa63UytJ7kwWcv8Ym2pWwwAAAAAAAAAAAAAAAAAAAAAAADAMlFZ6gAAAAAAAAAAAAAAAAAAAAAAAAAALB+9Kzqy8u2N7F29kGQio+MX0nV2JiPrhrJmTZnDL87kC/fX8sgTlXR3FLnqqiK9xVhmxyZSqVSydmRF6o3JzJcd6evpTq1a5MKRzenr7c26tZ355Bc+l55qNXOzrQytqCXdlQytHs6r3vjmbLny6qwa6Uul0s74+UsZWbc6w52rU1ycyvFnPpqJ6Ua+euhi/ve3vS7nu2pZNbQjWaymUulOWWmn2lGms6MrSTVfO1DLLRv2Z9eW5A13tnLTjsnMdW5Ju91Y6hYDAAAAAAAAAAAAAAAAAAAAAAAAsExUljoAAAAAAAAAAAAAAAAAAAAAAAAAAC+voiiOFkXxTFEUTxZF8ejl2oqiKD5bFMWBy+fhl4z/yaIoDhZF8WJRFG9+SX3v5XUOFkXxb4qiKP6yvWsdHal0rMhtb7gxmzOQjoXpHKqdSLNaTWdnT7ZONfOKq/dn94ZDGV43mEefTEYvlRnYsCFlWabVKvMnX30ya9atSVEUaTcW064/k7JZzZcf2J9X7/676e3uzKotK7L+2tXprhYZ2bgx81OjGRzuztSZRj75u5/J2Rf3p9Gaz6HRU1lbDmfLvmszVyaVjlq6+vvz5MkLKVvHU+9ck+56Z+q1zhSVIit7yiwuVPLutyxk73WtTM60010rU7TLbFp5INWi/JZ8MwAAAAAAAAAAAAAAAAAAAAAAAAD48ypLHQAAAAAAAAAAAAAAAAAAAAAAAACAJfHasixvKMvy5sv3P5Hk82VZ7kry+cv3KYri6iTvT7Inyd1JfqUoiurlOf8uyQeS7Lp83P2XbdpozOex3z2fsdpidq69KTf33ZnR8wOZmFzIYqWaVsr097aya8NCbrxiIqOjZd791mRudDStdjtPPvFUBopGVm/blVarnXazmcGVtex79FAmz05mYWZ/9r7uhqy/emMmJ2ayODmfr3788zl68EDmZufTVavms3/yyXz2wc8nU6fTqpZZeX59Vi/uSq2vK1eu25LpS0fy2ldemcXFhfR11lKWl1Jpzqe5UM/sxEQWJmYyN5VsWVnmil3JHdeVuWJbmf/9ve309pTf1I8EAAAAAAAAAAAAAAAAAAAAAAAAAH+R2lIHAAAAAAAAAAAAAAAAAAAAAAAAAOB/Cu9Kctfl699K8qUkP365/uGyLBeSHCmK4mCSW4uiOJpkoCzLB5OkKIrfTvLuJPd8o03mp1rZ8dpaRsebefq5M3nxq0cy272Y6cmZPPrEcOrthTx/eDbTE41Uqz0ZWdWZSudsHtt/JDnfnQ1b1ufIgcN57omvZqCcS6VWy6Wprsydm8ptu9+VYmQu5fpdObn/YLpW356BvkqK9lTGOsdz7lQjmZ3J6p2bcqk1mkujPRkcuC61ciDTvUVuue76fNfWa3O2Vea7vvd1eWThSMqiTDG1JWPHplJLkYlqX4Z7uvKqO7dlbrzMjTeV6e4vctP6SspqK319T37zvwwAAAAAAAAAAAAAAAAAAAAAAAAAfB21pQ4AAAAAAAAAAAAAAAAAAAAAAAAAwMuuTHJvURRlkn9fluUHk6wpy/JMkpRleaYoipHLYzckeeglc09erjUuX//5+jfULFs5VpY5+oX7UxRJUVRSFEU6yo68cHIkF0a7cu7c2azubGTF2q0ZWtGXj/7x4ew7/6mUZSudne1sWNWVD9/3idTrlXR2dmXnijsz3xzOhk1rMn/ztekbGs7MmqOp9XRn8fNfzge/eE/aD5cpk6TSTrVW5lX9vVmcr2bXlT+fz/a3s+PGdr5z+q4cPXshT02MZ/Oq3bnuNbszOjGdYv+hbJmtp7a3L/Xh3tSKRgZ23J2BJCN/2rBUKpU05ufT2/+3/se+DAAAAAAAAAAAAAAAAAAAAAAAAAD8N6otdQAAAAAAAAAAAAAAAAAAAAAAAAAAXnZ3lGV5uiiKkSSfLYrihW8wtvg6tfIb1P/rBYriA0k+kCQdvdWkLFImqaaSSirpmd+SajGR66/clKLWndHRidQ7Kpm/dCyrNm9NJdVcem4uzUY7iwuL+aW//SP57n/+L7JQtNPX10hlR1+29vfmoecfyXVXrEhZ6053WaSnVWZ6tJljj88mRZkySa1S5HXrB3Jbx0i6VjSzZV2R06c2Zmb6uRw5cSrnRi9k5LYrsq1rbU41zqd1di45vZD5ykI6TrfSt6Y/nfVVqVSrf/ZuaTVbqVSqKYoiRbXyV/gMAAAAAAAAAAAAAAAAAAAAAAAAAPDfr7bUAQAAAAAAAAAAAAAAAAAAAAAAAAB4eZVlefry+XxRFB9LcmuSc0VRrCvL8kxRFOuSnL88/GSSTS+ZvjHJ6cv1jV+n/vX2+2CSDyZJ78p6WRRlKinSTrL2Yn+mLx5L7aruDK3fnc6+lVl3ZVeq1Voao4eTnpEMrr8qXzqyL6sqZYZXb8uXH30krxhZn+fPXMgTx+ay5daO/PoffySLzcU8/8SjGbnp5gxv35zWseMZGNyQsv2nOWodlbzttpV5wys35dSJhZw81Mjg5pNptofz1OFLuf3W2/KFr92X0w8dyMO729l61aYsrujOwrlWylY7I3dtSmdlMKt71+Ts0fOZPH8hT3/pKzl16nxGuwfyt3/s+9Nuf5M+EgAAAAAAAAAAAAAAAAAAAAAAAAD8JWpLHQAAAAAAAAAAAAAAAAAAAAAAAACAl09RFL1JKmVZTl2+flOSn0ryJ0m+L8nPXj5//PKUP0nyu0VR/HyS9Ul2JXm4LMtWURRTRVHcnuRrSb43yS/9t2ToG+jOyuGRTB4dT/+xC2mu782eK27KrlvekLIsk6JIpk6ksv0tqRRFpicupaPaTk+1zMKlMzlfaeVn/vqb8//5w/tTP3Eqn/3CPVlszKZMZ2YX2znx8KM58eBXkxR539u+PUlS7y7y3veuzStuWZOZiWY+9dBohjs7MnWxM/NzRzLfTPZsuyLPHTyaduN4qo2BdKYv49PTafW0U68VWVGszNqBXUm1mU//Pz+fudGz6d2+MzNHj+Xx4+P5T51lqrXqN+tTAQAAAAAAAAAAAAAAAAAAAAAAAMA3VFvqAAAAAAAAAAAAAAAAAAAAAAAAAAC8rNYk+VhRFMmf/pPud8uy/HRRFI8k+UhRFD+Q5HiS9yVJWZbPFUXxkSTPJ2km+eGyLFuX1/qhJL+ZpDvJPZePb6hM8sY735QdK2/Nz/3aP807r92QF0a2Z9vKNRkYGkpZlinLMunfk3bZTlmWWdWzMT/0mldnvlGmVq9n6szJfOrpI9m9cjjXjKzKbz+6L0mRIu0UZTtpFUmlns6BwSRJtSN51/euyM23rkpnvTeL0638je9ancPPnsi9+x/PzOR49m95ZdavPJ7OapGh4c7cf/+nsvnbfyA9jTLrr1yZt68cycFqf9qNVrqr9Wy5amO6e3emq78ru67ZlDesWJN9B46m3Wx+0z4UAAAAAAAAAAAAAAAAAAAAAAAAAHwjtaUOAAAAAAAAAAAAAAAAAAAAAAAAAMDLpyzLw0mu/zr1S0le/xfM+ekkP/116o8mueavsn+lqOQNV70n4zNz6ezpyNiOLemfLfPJ++/Nu974d9JsNpIUaTbmknYrtVo91Wotq1avT73Szuz0bFZv3piZmflc09efvv6e/PZjz6ZMNUWaqSQpar3pWbUtfb09SZHsfV1f9t65MV31wZSpZ+WGatqp5KqeK/Jbv3BvNm57Z/7zV06kOnsi3f29OT1zNrvWr8n5yQupd3WmPDqW+zoHsnLVfIrFiRQdK7N617aUrWZa1VqqzVZaC3O58drtWZz/1F+lHQAAAAAAAAAAAAAAAAAAAAAAAADw36221AEAAAAAAAAAAAAAAAAAAAAAAAAAWD7WDq3N0NzqdExM5dtuen9WD3elY7Yvc4vdefb5h9PRUU29q8jE6FRSttLVO5RqtZnZoidTM6Pp7Fud+cVGWvVmOosirVo1RatIpV0kqSbVrtRrQynm57LQbqVZjucNb9+darUr9XpP+ro2Znz6VKrd3ekbWZ01w49neGUji9MP54nj57J7y/rMnVtIb3c7kydPZ93A2syu70zqZcrZE0mzI4vljswOrM+Kzs70FdWcmZ1Jo6hkpqsjRcVv/gAAAAAAAAAAAAAAAAAAAAAAAAB4efgDHgAAAAAAAAAAAAAAAAAAAAAAAAAvm77mQFY9szY7unfmuu23JO2k7Ejeubed7/n3tyT1Rr7je27PI189kPPnF7Jx54Y88pWH8vf+1n/I/fd8IrfcviOVzt501uupVorMzc9l7MJCJiZnLu8wl2Tsv+x347VTuWPnNTlx9kA6G/0pJ89krllL0axnoXchv/cvV+Y/fuFX0kxXOgYHMzbzTO5/+kRG1nTlB2dvy1D1Yh6ffS6f+OSXs2bdbO5+TyX9zVvzYz9xIHfsuD7b+4fy1fNHMz41l+6ees6evbQkfQUAAAAAAAAAAAAAAAAAAAAAAABg+aksdQAAAAAAAAAAAAAAAAAAAAAAAAAAlpHOmRSrn0hlXT2VapFKrZLKukpqvUlv91Dm5mZT71iTFUO9ee2rr8jC5FjueOWVaTabuf01r03v0KqsXLkyXd09mZ+fz8T4xZRlO2WZy0f5X45KUWT90JUZHT2S9lx/JucW8tAXH06lmE/RnkurOZd6/0j+7ntuzo4NA9n32MkMrxjM694+lM27a/nklx9Ivfts/s4t/yBrh6/O+350Tbp61qcYPZbG/ELqa7ckm9elUl1Ms7GQm/rn0tFsLnWHAQAAAAAAAAAAAAAAAAAAAAAAAFgmKksdAAAAAAAAAAAAAAAAAAAAAAAAAIDlo6wUuf+Fz2R+bjLlwWYylBRJ6jPVPPfE0azduD779h/Mmi0b06jOZ9eW4czOzKRot5JU0m63MzY2mv0vPp9P/uFH0m4X/6/1R7bUUqlUsvfG6/Ojf/O7cu2VV2Ruspr+3kqGuwcz2N2feqUvq1Z0pdFcyGfuPZ9G98b8zXe8Pd/7lpvTGp3N/qdncvTFhbxw6NHc1DuSA/f/drZ11fOxfz+Tx78yluEbVqVe60jRnMlV3c/mbdeuzd41vbmtej5DRWsp2goAAAAAAAAAAAAAAAAAAAAAAADAMlRb6gAAAAAAAAAAAAAAAAAAAAAAAAAALB9ltStX3v7WHNh/b1bN3ZR1i9uTi0lmkszO5LpbtqVslRkfvZCuopKnnz+Q7q56FhYXMzU1nV//xV/I+NhoLl0azfDQQB547JGUZZkkKSrJO999UzrPVfLG9/5oWoszOXTigTSGi/S0O1LWWqmXlaxbuTHz1WYG+xr51FefSv9VT2XryjW5+fqd2bBxRW7b1Z0Pf/pYuratz/0PHMonHphLc/tT2bV2bfbcvJBWbTZv/t5VKRoH8nR1bx75ysfzpqGFHL+QTPVWlrS/AAAAAAAAAAAAAAAAAAAAAAAAACwftaUOAAAAAAAAAAAAAAAAAAAAAAAAAMDycfHieDbtvimH55/LP/vNn8ivrv2dVFbVUx5pZnjjmkxdKJPqdPp6y6wY7szcbCNls50Ulfz6r//7HD58LCMD/enq6szM3FzK5kKKopJ6rSOvuPnG3DJ8Z6YqT+Xk4edzYP+L6ewfzcaN63N+6nC2rV2berOevp6BHD79YNYO786l6tn88Z+MZmL8+SzOJW++rSfbt9fz19/cm1Mb3p4/+qnPZP/UpVzT/0/y2vfMpOuK/5R9X2ykt6vM/OxiytlP547rejM/tTWDk09ncaq51C0GAAAAAAAAAAAAAAAAAAAAAAAAYJmoLXUAAAAAAAAAAAAAAAAAAAAAAAAAAJaPRrOZ/fsPZfLieF71ij1pTy6kMlNNu7fMju2bc+TYsdy8d2se/dyDebyzmt7+emZn5rO4sJjhvt68/tU35cknn8s1V23J2KWLabY6cvsNb0hfrZJdK4dyamwsRX1bnn/ssUyNXsrw1mZWzjfS09fOfPNc9r7v7WmXYxnu2ZrzY/tz8uJ8Oibns2Vrb95+ayXV4e60U2bNQJmf+vE9GcrH8113bU69963pLDfmS//xQxkf6czCVxfyhsps6gMTOXOmSGdxPsf62pmaL5e6xQAAAAAAAAAAAAAAAAAAAAAAAAAsE7WlDgAAAAAAAAAAAAAAAAAAAAAAAADA8jE3P5vv/8EfyHvf+t6UY8fy1fJzqfcNp92ZdA0WWbN6Uzqrw1k5ckWuumFLBnsGMj55Kfvu+0i29C9kfOJirr9iIF2Dk1m/qiuVSk/eeHt3uvq25tmHX0i12pFU6hm7dCYD6+aysn9XKlNluupFerMx5w+cSbt2LrX6ppRzXbnpqr0pW9W84Z21fPlzY/m2ncPp7GhlqtnIt7+rkQc/38pC+nL27J9k+PhV2bn6+qx99UiOTlSzpvJkOurDabQX0io6s7WV9PRcWuoWAwAAAAAAAAAAAAAAAAAAAAAAALBMFGVZLnUGAAAAAAAAAAAAAAAAAAAAAAAAAJaJjs5qObKzOzddW81Tz5cpK5W88tr+DG+r56aB70lRlOnu6c6xF1/MypE1GRgazOJCI6+cfjYdtWrmm4uZWTeR4aurGV45kKLoyANf3pz+/r5MT82nvzPpGxjK4vxsjhw6lEOXOnL7bTekaC2kqHVmdnY2nfV6Ort6MzUzmzvv2pvp2ZkcOHAwtaKerRsH89y+A+nqGcj3/B8/mx947U9m3cCa1HtX5IP3/l/ZufHGXLXr+vyN29ek0t1Oa34m+44cT9/K1Vm3ZUfu/t/+Vp5+4cViqfsMAAAAAAAAAAAAAAAAAAAAAAAAwP/6aksdAAAAAAAAAAAAAAAAAAAAAAAAAIDlo1pLhgar+T/+aTUf/A89WZzvyo/8zbEMrJ3IFz44k0pRZvzsmYyPTmX6zPmkLDM218zb3709rVYj1cVK0jefjo5W6l3VVKv1jE7N5tHnT+SjD+zPz7x/T2YujGbzFTtyxa4tGZs6nrmxUynqfanW2qnVOlLr6Eq73UqRdjr76/nqV7+aaspUeoeyatOG1A8ezOrB/uzecXUulM9k3WI7PRs25O99z09lfrad4a6OVFdU05yfSWX9SB558L4UJ07ke2+/M8VSNxgAAAAAAAAAAAAAAAAAAAAAAACAZaOy1AEAAAAAAAAAAAAAAAAAAAAAAAAAWD7Wravm//tTnSkqyZvumM+O4UvpqcymPNvIwtxMLp04kYuHj+fM+FwOXJzO/onFjFe6cmh6MofKVu45eDYHTzYyP9dOu5UkRf71R7+a8anp9HYmF8+dyeT0aM4e3ZeyNZkVIwPp6x3K3Oi5zF88mv37nsvC3FTm5maTVjsHnnsxcwvtrBjuy42vuirV3o501msZHKjn9JFz2br56rS6e7J6aEW2ruxPMXk8cyefzNC116d389YcGz2RUyfP5/VvflOaUzOp1etL3WIAAAAAAAAAAAAAAAAAAAAAAAAAlonaUgcAAAAAAAAAAAAAAAAAAAAAAAAAYPnorDSzMVOpJ+npqedd37mY5rmk1kq6ikbmZ2dTtlvZsHZ9zrx4Pr0br0lz9Gh+6sNP58iZ6VycmE9HtZK9Vw/nl376rjy173yuWtWTjQPVvPOqoXzpibO5+Zp65uam0z+4JRPTCxleWc2xi/MZ6Kxk7WBXzh16IgMr12e2WWTVZD3D/d3Zcd2mlI3JpNLMwuxUOiuNdNW7U1kcyciGKzM2cTFTJ8dS792YwU0daWc+1c5KPv6pT2fV8FBe2H8ijUp/WuVSdxgAAAAAAAAAAAAAAAAAAAAAAACA5aKy1AEAAAAAAAAAAAAAAAAAAAAAAAAAWD6KMmkeSXKyyJbNzbQnkqIs0rxYpLd/IJWynVW9ndnSnsyVmzdmJFPZ3Nudv/u/7c1iu8j49EI2jPTmMw+dye985FB+9J8+kKH+rhw/N5bJRpnB1Stzy61X5fqbrkpR1DI/t5Cnnng8iwuLmVmsZP+F+XSsviJHT4/lxKEXs3HNQAYHu9MxfyGzT9yT8w99Np/43XvypT+4N73dQ1m7Yksa0wvpLLozX7TS3dufxUZ3qj3Dqa/dnMP7DmZ6ej59fQMpKrU0mq2lbjEAAAAAAAAAAAAAAAAAAAAAAAAAy0RlqQMAAAAAAAAAAAAAAAAAAAAAAAAAsHyUreTi4WpmL1RTmSnTmitS6a+kNVZk+65d6akntWol43MLabSaqTYXUtQ68vyx2Xzu934o73/rlTlzbjrb1w/kP37k2fRWimzbtDq7t27Mna+4Me//ttfm6acOZ2Z6Os/uO5mDJyfzzOGLOXzsTMYmx1JtLObU8dOpd/VlLoOZm5/KmlU9mTp7Opf27cvEwmBW9NTzxPOHsmn1lpzYfzjjc+dzYeJg5hbPZ2b6UKZnjieppKh05J//i3+VRqPMFz/36YydvZDG3OxStxgAAAAAAAAAAAAAAAAAAAAAAACAZaK21AEAAAAAAAAAAAAAAAAAAAAAAAAAWD4mJut58dS6zIwU2bpzPpcWBnLhyHTqRSWLRU82vuHujB47lHWrN2dhvp3Oel+KZjW71j6RA/su5e9//9uye+ThrFm7KX/4h1/KyMhItndekfXDfemeq6c90c7K0yvza4+dSbvekaHhrqxd05vJidlcHFvIcNdMivpcZhaHM7OYnF+YS9/8RMZPnU67NZjh/qE8f3Eq463xjPTckhNnHswLBy5l5/W7Mthb5uJELZ19Azly7rn0l11pD9Xy7u/7jlyamsvFMwdSdHUsdYsBAAAAAAAAAAAAAAAAAAAAAAAAWCZqSx0AAAAAAAAAAAAAAAAAAAAAAAAAgOWj1bEiq9/Sk5EVA+mq7cvFi2vzwoHXZM8tB/JHH/71LLZO5YqV07lly/+VY2fOpFzozUB3PZPFNdm5fk9e2LcvV+25Kht335AvPzmR3TuGs+d3XpOOH6xk9sxCcvBkbvrU9+Tt/2xvipFKPnrsP+SpE19Jf62aheZCRqdaaZeNZPJ0aqvX5FMP/EFWrVyT9QM35ZnKM1lx4Jn03Hkyfb1z+Z3/+9+nqBSpVssUTyWVSlKpFimK5NSOo9m9dXtyMWlU5tK3diCnV55Po7aw1C0GAAAAAAAAAAAAAAAAAAAAAAAAYJmoLHUAAAAAAAAAAAAAAAAAAAAAAAAAAJaPomxm64apjPQ/lLmxmWwffiKvufXh7NzwfMYmx9JcnM2J4zN54cUnc+LkwZy7dChHT9+XVcOrcur8o5mevZiVm3bnmRfuzytu2ZVGayKnzn8s//o3/kkeanwszTdMZ/z2xzP72yey8Mmx1KrVVMukq7sjPd2d6e7sTLXRTN/a9enq7Mzpif15cebelLXe9AzVczb3pjowm+GOPSmLdsq0csPNt6WolCnzp/dlmjn8mcn8/i98PotnBnLy0bPpLHuybmJ96kXnUrcYAAAAAAAAAAAAAAAAAAAAAAAAgGWistQBAAAAAAAAAAAAAAAAAAAAAAAAAFg+KpVG+vtGU2125Jd/sSM/+/ODOXdiOnMzMykr0+nu3JXd1783raLI0NpktPG1zDUvZHCoO7On5zO7MJM/+NA/yfipE+kp+rLQHsiRvt9L7+xzOXj/h3L6/CP5wi0HcvHUxzKz71zKs81MTk1l9MxEutu9OTXeyvmJuXT19qTeVU93bzv9XSvz0MOP5+mvnk/XzK40zm3Lgft7s37D1lSr1fzcT/9C7nrN69PX1/df3qNvTSWHnzuYD/76f8wn77k/5w6cyfylWubm5pawuwAAAAAAAAAAAAAAAAAAAAAAAAAsJ7WlDgAAAAAAAAAAAAAAAAAAAAAAAADA8tFoFrnn09ty/Y5KitYLWVho5Q/+88q8rVLNzj29uevKn8qhM5/MF+/7dJr1S+mt9GWxuiIPfOajGeipZlVvT15x4/a8ePBsxi/05T/e8/H88i1FBvZNZONAV/YfPJZHj85lb8/BbNq/Kue2ns2xsRPZ1D2Q6fHxjLfLbOtup6u7K81WO2X/YsaevjI9vX3pae3JZz/0aLbu2JJtW7bl29/3ozl77kj+5Lc/lLvf+t7c/db35h/94x9KpZKsvnVF9g5tzYHfP5jFgc6cz7nUV/Rnob2w1C0GAAAAAAAAAAAAAAAAAAAAAAAAYJmoLXUAAAAAAAAAAAAAAAAAAAAAAAAAAJaPIkXa87258saHs/fZO/L2jfdnrnUga3d2ZWLxnXni/qO56o5dmZz4ULo6OjLXu5j5C4/mDT/yK+npHczT9/5+avXNadanc+DU8TSaC1n3tu5svK2SR+6Zz9z+RzLfXJNibTPnL30+k6NFNq7fkqF6b2bHTubm7ZsyfXEs7dm59Az0pzWzMmtGrszk2GRWDqzKLbfflf7+ZHpuMZs3bcyK3o6c7hvM1p1X5+Dxs6lUkko1efxLD+fE8bNpr5zNXW+7NWvWrcjk3EQ6611L3WIAAAAAAAAAAAAAAAAAAAAAAAAAlonaUgcAAAAAAAAAAAAAAAAAAAAAAAAAYPloJhk9d30++bFVOTexNde8+XgWZtt59IvXpNVZTaqz6a2PZHp6MelppzODuTgzk41br85iu50j47257Y4b0nv2YBbmz6ZSraars8g17x/J8I5LOXewlbcMnc/Upxdy/rnzGVzx5sxWxzO4YVW6uhez2Gxn2zV7cumFF9K1cmUuPtaVV71jOKtvf1We2bcv+/Y/nd6uw6msGUtZ/lAaWciWbbvSWmzk+quvTt/AcGamR5N2cs3enVk9Mpw1GzanY0V/htJKq1xc6hYDAAAAAAAAAAAAAAAAAAAAAAAAsEzUljoAAAAAAAAAAAAAAAAAAAAAAAAAAMtH0WpnenoyzzzTmVRGc+/Xvj0Th/al0RzOe99yfYbu2p25S4287hXvztTChSwuLGTX9j05e+5Eis7OXHfzK5NaNVe+Yn2OTZzIdcUtOXH+ePLMXLr6BzM7OJeFqVoOHKqno7cv02Uz6apnodpMz+at6UmR4VVrkm3zKcvkyi3b0ze4Mfc98KU8/dyTWbujlbHyUjLTl1q7lc7KcGYuTeY3P/RrWb9xS9YOrsxMvS9veMc12dA1ktrQ6oyOLmbu0oU0JhfTmFlY6hYDAAAAAAAAAAAAAAAAAAAAAAAAsEwUZVkudQYAAAAAAAAAAAAAAAAAAAAAAAAAXkZFUQwl+Q9JrklSJvkbSV5M8vtJtiY5muQ7yrIcuzz+J5P8QJJWkh8ty/Izl+t7k/xmku4kn0ryd8q/5Cd3a0dWl6975W2ZmZnJriuvzo233Jzf+41fz/V79+b//pmfS1GpJGWZVruVJPmz1X7/w7+TMq1Ui2oaaaRINY3WYtrtVj7xuf+UVdu7871vPpmnnxjPq26p5V/8y4FcOtGRDdt2ZX6qmTe84z3p7anmvk98In/7//zH+fe/8Mvpqs7nLd/1XalUirRa7SRlPv4nH8uXvvCpXHnN9fnAG9+S7q7udA0OZXx6PimbuXjxfJrtIu/9wNWpVi+m2vFteez5U9l71ZUpyzK3X39FHn/+aPHN+lYAAAAAAAAAAAAAAAAAAAAAAAAA8BepLXUAAAAAAAAAAAAAAAAAAAAAAAAAAF52v5jk02VZfntRFPUkPUn+UZLPl2X5s0VR/ESSn0jy40VRXJ3k/Un2JFmf5HNFUewuy7KV5N8l+UCSh5J8KsndSe75RhvXarW88c1vyeTMTFYNDmTl8GC+4zvfn407d6fa0fGng8oyzfMnUl+3NSmKpCxTrXWlVqumSJFKq5l2s5l6Z3eKopaRFcO57aozueWKY7lmsEh9sMzP/fxi/trfWJV1G9allu5cPHEwq67ek61XXpNDB05k06Yd2XbFFalWq5eTtTMxMZEnn3wio+PzOXJwf85ccVXarUYuzc1nzciaNMoiC81W9lxzfeZO7Um7s5VabyXtVlKt1JLJ/SmK8pv7pQAAAAAAAAAAAAAAAAAAAAAAAADgL1BZ6gAAAAAAAAAAAAAAAAAAAAAAAAAAvHyKohhI8pokv54kZVkulmU5nuRdSX7r8rDfSvLuy9fvSvLhsiwXyrI8kuRgkluLoliXZKAsywfLsiyT/PZL5vyFyjL54mc/ns2bN+bcyaczOnEw6zatz/Tk6TSnxv90QJLDv/bPM/b4/Wk3FnP22Ufz73711/LwI49ncnIyHR21nDl9Ih21eipFmQuTE1nbfz6tmWRhqkg1SbWykE3D63Pk+OE89NWv5Ctfvj9nR8fzta98MQ9+5g9z9PEHc3jfEynLpNFoJEmGhoZz6y23ZdOmDWk2WikqZY4cP5VnXjiQ//SJz+Xc/EIefPy5FJXOzEydTGOmmdmpmcxNz+Xc+bGMXZhJWe36H/9IAAAAAAAAAAAAAAAAAAAAAAAAAPDfoLbUAQAAAAAAAAAAAAAAAAAAAAAAAAB4WW1PciHJbxRFcX2Sx5L8nSRryrI8kyRlWZ4pimLk8vgNSR56yfyTl2uNy9d/vv4NNRoL2bK9Kx2VMtfc+sa02+00W2UuXjyQ0UPPZe7pr6U+0JtzTzyU5+/7bFrbr8/7PvjxXBqbyif+8z259zOfyV9771szsmFjarVaikpHjr5wLk8dW5Vbrh1NfWU7EwtFvvTUSE5Nn82e7Tfm0PPHUq3V8qnf/a10D6/M8y8eyxvf/Lr80Wceza2ve2U6O7uysDCXjnpX3v3u92Zxfiozc4tZqHZn844t+dyBC+ms1fPH99yfdqOZxvSZTM6uy4WTT+SKG1+fSrWSWrWWrL4q7Wrf//AHAgAAAAAAAAAAAAAAAAAAAAAAAID/FrWlDgAAAAAAAAAAAAAAAAAAAAAAAADAy6qW5KYkP1KW5deKovjFJD/xDcYXX6dWfoP6f71AUXwgyQeSZGRkdd7w5h9M2WqlLKp5+Gtfzrbt27Nh/d5MZyCf+OMvpzV9NLv2XJ+J0fFUVm1OiiKnTxxMtVrLmjWrsmbdhvQNDGd+fiH1ejVr1o/kU38ymr7uVSknZjK72J+HXxhJ0beYsujIFVddk9GJyZw8eig3rF6TkZ3b8tbv/J7c+4WHU+/szOLiQjo66mksLqQoKrnu2huzfdeVeeGBB/PisYtZWFjM3Ox8kmTdQFcaCwv5/MNfy9ve/o5Uax3pqNfTP9CTarWaauXrtQUAAAAAAAAAAAAAAAAAAAAAAAAAvvlqSx0AAAAAAAAAAAAAAAAAAAAAAAAAgJfVySQny7L82uX7jyb5iSTniqJYV5blmaIo1iU5/5Lxm14yf2OS05frG79O/b9SluUHk3wwSW664Yby2utvy9OPfTXnju3Lzbe9Or/x67+Qns7h/PKv/mp6KqO57R//ywwN9KZ39fqs3LApUxfP5VV33J7FhcXcfOvNabST8fGJdNXrabdqWbzUSKXsyf1P9OfwY5dS7SoyuGY69c7ezM0sZK5R5tV3vimTt0xm6sKZ3PLqN+Zzf/zhfN8P/mhmZ6bS3d2boiiSJIuLi9myY3eSInuvvy6/+tF701ldTLVaS0+9I9/77e/M2Ph47r7xdWldOJfJ+fk0FhfSUaumUilyeRkAAAAAAAAAAAAAAAAAAAAAAAAA+JarLXUAAAAAAAAAAAAAAAAAAAAAAAAAAF4+ZVmeLYriRFEUV5Rl+WKS1yd5/vLxfUl+9vL545en/EmS3y2K4ueTrE+yK8nDZVm2iqKYKori9iRfS/K9SX7pL9t/enYm93353pw9ezqrVq9OR7s7RaXMi0cey4UL5/KWH/9Hqa7emPHxmcxOz2Tu+LnUujrz9ne+PY3FRqanZ9Not1MpinRfOp3Znv6sWb06/YNJ/0g1q25dk4NHT2Zlz0AW59opina2b9uSSpoZHl6V1UMD2bljUz5z4IXUp7+U7W9/W1JU0m4109vTm0ZjMdVqNZVqNdNTk6lkLmWKXL17dzatXplVI2vTSCX7H/xyir6u1Ht7c6mjJ08U7Vx9/fUpy/Kb/s0AAAAAAAAAAAAAAAAAAAAAAAAA4OupLXUAAAAAAAAAAAAAAAAAAAAAAAAAAF52P5LkQ0VR1JMcTvL9SSpJPlIUxQ8kOZ7kfUlSluVzRVF8JMnzSZpJfrgsy9bldX4oyW8m6U5yz+XjGzp29mR+9F/8k9y29xV54dQzeVf/e3Ikl9Lun8/v/tLfTWerzFirO19+6JnsuPrGDK96XVbcdGs+/p9+LR3Dq7O4OJ/Ualkskt+/8HB+vD2SjXtfmx/7gSszOd+XR54YT1ftoaxanTQaCxkZ2JzXvvptqTQmc+jE2axasTLV1um8cu9gNmx5ddae+2wG7vjutGbP5MT+F3Ly2ady7dVb0r/7pvz9//ClrFi9Ir3d9ey945bc/eZ3paOjJ6dOnc7Vr31rqpUitXo9RbUjlUqRSpmk/KZ+JwAAAAAAAAAAAAAAAAAAAAAAAAD4C9WWOgAAAAAAAAAAAAAAAAAAAAAAAAAAL6+yLJ9McvPXefT6v2D8Tyf56a9TfzTJNX+VvdutZhbmF3L+2PO5avU16V87nO6L/Tl9cjQXz41naq4jKzb0ZmHdXHrWVnPq2YM53jqcTWeOZLLaSrPoSrO2OqOj5/L0VCP7qs28YtuNOXyqlSMnZ9I/3JWOM5PZsnlHjp4+mnNnL+W5Jx/KdTfenF27dqVSq2V+bi7Th8fTsaMjjQMT2f+lH8/K11+bQ4+8kK995Yl057VpPPNMFhaLTE7OZtuWTfn4H//nfPGLX8xrXnNnbr/jjTl0+Eh2btuaWq2WSq0jlUrlT1+w+Kt0AwAAAAAAAAAAAAAAAAAAAAAAAAD++9WWOgAAAAAAAAAAAAAAAAAAAAAAAAAAy0fZSq6rDeTJ/Wdye/87c+DSf05lNpmZbWflytV56ouPppHOrB8YyO5td+S+T38wFw+ez9/LbDYvHs18pcxPTVQyOzmZfzvblbdevZhmYyEPPL4/rbki6TiTW7btzNkLoxkZHMnYXCXPPbMv3fWubN66ISvW7Uy1Wkv/wIpMjp5J7dc+k/bsVI5V5rL+5lvT/OLjee7pF7Pt6t15y5vuzK6d21Ipymzcsjtnz5zLH//xZ/LhD/9hfvFn/p9UiqRst1K22ymLIinLpW4vAAAAAAAAAAAAAAAAAAAAAAAAAMtIbakDAAAAAAAAAAAAAAAAAAAAAAAAALCMlEU6Bvqyprs7Q6sHcvpSKxu23JjX3fVdOfPgH6S7bzCPP348b3jnuzO8+mjWXbEim4ZXp3nvfRlsLKSzXua67sl8bm42jYHhfOCuxXxo8lxa9RMpBjsyceJc9ndM5eL4bK7fdXu66mW2XDWcsxfGsuPK3Tl36lA66t1Zt2l7Orv70zvezJmF2Uz/5sP56meezqG5+YzPzuXoyTNZe/eVaeZ8bn9Vb7qrd6SaoVy6eCkXLk1mYvRkyvLK7PvSPdl126vSNbQm7VYzzYW5pe4wAAAAAAAAAAAAAAAAAAAAAAAAAMtEbakDAAAAAAAAAAAAAAAAAAAAAAAAALB8rB7sye5NA9kxdWv2N47m7u/+iRSLjVx6+FJmFzqzWKvnzNS5nJxcmZFjB3LrK6/LXM9shh5/IB0DlWx9w40ZfjLZfqmV7bt35GOX6ulfXc81N1ybhYVGRnetyPlLF1MbGkozrQwNrciq1Ruzdl2ZWmd3irmZVGr1bNq6I0defC71Siv1WjXD7Wp6z8ymp9rMeK0/i+VEHv74x9LVezQzZX827vxa+s7clqGt12XjxtV55sv3pD07l9Mnj6ZYtTETY49nYuxSFhcbS91iAAAAAAAAAAAAAAAAAAAAAAAAAJaJ2lIHAAAAAAAAAAAAAAAAAAAAAAAAAGD5GF9o5JNPHc533/SO7BsfS9/Q+nzl8w/m8Sc+lr52R8amq9m0+9Y8fN8v5Oyzw7nrb+7KpYuN3FmrpT7XztiBc1k5OpHXX3N91g/158lPH8uNP7wuX3rgSPqHarl2z46sGhjKibOj6SrmkrLI2MUzuWLPNalV6+nuX5XRC+fSPzCQZruV2atWp3KimpHUMz4/nrMT81m78cY0V5zIxjVr8vGnn8niV9bl4OEnc+11Z9OYncr+A+vy2ENfy/1fui/tZjO//Qd/lJn5RjrrtVy8cG6pWwwAAAAAAAAAAAAAAAAAAAAAAADAMlFb6gAAAAAAAAAAAAAAAAAAAAAAAAAALB9F2cwdV9+QZ2e/lB1XbM/n7v1wVl+s5OSlZ/LGu27NSHtHRl84m3KhK9cN78n6FZuydcea/NPf/Fq+o6udyiMX87ZretJRO5zDx1o52OjMmtOncuDAuWzctCKV1rl0dFQzvKqSSkfSnGhkeuF87nvgbF5351ty9uK5VDu6c/rYqVyYOZ+9P/wdqY/PpP3lF/P4Q/dl5/Yr0lmr5ODkYl735jL1ztvy8QeeTG//UNYMXpEvfu7JDHdeyOnGTBqthZy+NJat3SvSKJtJV5GFdnOpWwwAAAAAAAAAAAAAAAAAAAAAAADAMlFb6gAAAAAAAAAAAAAAAAAAAAAAAAAALB9rV7Xyrvc9mPnFdkbHHku7XU1rRSu3H+3OTbtvy/z8fE4WvXn1K1+Vq6+8JYPDQ5mfn85NO67IoVo9jcZCDs/1pJhLWuVi1m9o5eK5ZvZsvynFQjM984O55corU9S6MzWffPbAfbnn2B/m2nJznnxuMus6LuSNr/o/s2p4fT720M9n6IZb0jFyVQbfe03uvPPOfPxX/2W2v+r1efqx+eyYmsv0xOlcNVRPz2gzn/+tB9JZa+W617TymyNr0mrOpt2oZ+6J+XTua+fCxqk0a62lbjEAAAAAAAAAAAAAAAAAAAAAAAAAy0RlqQMAAAAAAAAAAAAAAAAAAAAAAAAAsHwURdJsz6ZSaaSrcyIDgxM5eHAs87MdqVY6UqlUU5bJ4ux8WovNzE/PZ2p8MsNrVme4uzO3vvmdWbdlfeq9nemod2bnFVdmanQ69UpXZs6eyz33Ppgj93woYxcvZmJ8JkP1kexc9Yrc2L0qZ594NDdtfEtuWNGb/t6Decfu92RgaEVmnno4p7/8uYw3Z/Pk6Yk88Pij2VAv8sLzpzI3OZnNm3fm/KmLWTPQzEhvK6cPn0pzoDeV4RUphlbl0mt6Mzszm+79SVm2l7rFAAAAAAAAAAAAAAAAAAAAAAAAACwTtaUOAAAAAAAAAAAAAAAAAAAAAAAAAMByUmZhsUhHvZp6VzPNsp3RyXYOnTuXskjKFGmWyYkzJ3Pb7ZUMDlWyf//hDK3bntbURK7ac1W2bduaF599OpPHDubCmaNppyuTF6bzju2H0zvblcHDz2TnlqP58MR3ZNPwVfnnQ/8kD5f/ILcN78rBM4/kyY9+MW/cc2vWbromPStWZMVrXpvJ88fyj3/x5/Ka19+WG295a4bXrMq9n/3X6R3uzrEXnsuWbcOZL+Zz6x3XZ+LSkVy96saUx4/kxcFWKlnMzNXd6XhyMmmVS91gAAAAAAAAAAAAAAAAAAAAAAAAAJaJ2lIHAAAAAAAAAAAAAAAAAAAAAAAAAGD5KMsilUolKYt0dnWnMdvK4GB33v7dc2mXSbvdTrtMzk9eytBAO+2FM2lkMdv23JhrbtqboRXDOfXCo6lXO1JbsynD9b40MpUrNjyX+bNjWX1yKhOD7WweGc26xoGcO9fOvoEv5lf/+KuZnJjJhQuXsn64P/ftu5Cf+/6rs3HrrsyPXcrP/NtfyZtetTUf/f2v5BXv+VtZs2lDVj/WnQuXRvPk/vlcubGeK3d0ZWa2mouXWrl27RV58Pc+nqFvvzpFx6qc++u1VJ94LNXmUncYAAAAAAAAAAAAAAAAAAAAAAAAgOWittQBAAAAAAAAAAAAAAAAAAAAAAAAAFg+2q2kVm0naWaxkSwuNPOqV9cy3Lsy584m3V2dqRTtDPb3ptKcSpFGrrn+lqzbcVWKdjvnz53M1GwzN77x7emoVTM7di7/6oM/lb/2gadTeaoj+44ne2+oZSJlXtv3hfzrC9NptwbTP9mV2XIhbxq6PUVrPIfnLuTg42ey4bUT+fAf/EFe8arX5vBDv5gzcz356Ic+lN3XXJuF0xez0Ginu17NbFFPvaeWA4cPZ3aylb9+9R058b3vyMXKZM5lPJXqQJrbu9N+bn6pWwwAAAAAAAAAAAAAAAAAAAAAAADAMlFb6gAAAAAAAAAAAAAAAAAAAAAAAAAALB+VapkUtZSpplbvSHdfK53dPdm4ckdmprpy464duWbr6qwc6E1zcTbVFNm1+8o8cehcqrVaVq9enaGrV2VubjbnTh5PrWxkoTWVxYNFus43ctdgMlgv88iHyrS6k9n1tYyOn8rqHWvT80JXNgxel8cufSXXtu/KxMV6Tl48nbvf89cycfJIHvns9mxffyKXHn0oj544lo1do5kZbWRmtpGbN6zPyvWtbOxIZudbef2GzfnqnrvyyIXncn7imXRX+jL3Y3tSfOCBpW4xAAAAAAAAAAAAAAAAAAAAAAAAAMtEbakDAAAAAAAAAAAAAAAAAAAAAAAAALB8FO1qytmuVGqVNBrNVNvJQPryxLn9uf26bRnormZ42860F6fSaA+lvTiVidFzKeqdqVXKTI+fz7lTJ3Lq4It59On9ueaK7bl+3Q05US5k/VVT6TvTSt8bu7O13s58s57OSz2ZX38uw8c3ZP37rsozjz+cQ5PHsqXzqvzOyX+bX//Zsdx95Tty4Kv358o7X5+u9WvziY9/PNfN9mT9XTtz/OTZ3LimN+mcTc+q7Tm070ju/ra3Z3ZsKrtqK3OusiIXsyIdHSvyxNzpLFSWusMAAAAAAAAAAAAAAAAAAAAAAAAALBdFWZZLnQEAAAAAAAAAAAAAAAAAAAAAAACAZWLP+nr5G99XZnEqmZtKpqeS4/NbcrJ3Szq6ywytGknv0Ip01TsyuGJ1Ri9dTO/AijxWdKZnfiLlwnxmpqbSKovMdPbn0kLyz97+ukxPj+fo0ReS2Zns2XtHpiams2HDljy6/7FM913M7/+rT+ef3PyvMtU9nn938h+mVtTTXCjzxP0HUnQklWqZjs6OVLoqWZxvpbNeyY/9w7+fZrOSVKvprNfSW68lZTMz8wsZOro+Wzden3a7TEd3PZVKke/48Tdm/GwroxMTxVL3GQAAAAAAAAAAAAAAAAAAAAAAAID/9dWWOgAAAAAAAAAAAAAAAAAAAAAAAAAAy0eRViplO635pD1bZOZ80nnxcPrf+coceuqF7D82lqOnL6YoijRTzU037sj2bdvzJ+tuTNfxE1lMNTk9mrKzO4vrR9JqJ4eeeCxda9Zk9ZptmZ8Yzec/f19u3HtbFlrJ3KWL2TmxPz2NC/nwhX+Rke2rks5Welf2ZGp0NkMj9aRIrn31+lRSZs2WoczPzqfdqCappLPaSn1oKPPzs6l1d6TZqqbaLPPiqU9muL4h3b09mZ+ZyeJMO11FNWtWrFnqFgMAAAAAAAAAAAAAAAAAAAAAAACwTNSWOgAAAAAAAAAAAAAAAAAAAAAAAAAAy0hRJilSGyhTLiSnR5MVq5POjnZmmtVU6tWURS07dm/Ozj17smF1V1at2pSFySKdhw9maueeVItK0tObVrWSMmU+98X7cv1Vu/KKt74zLzz5SJ596NGcOTuau+58dRYvjeXUhYN539UD+eLZ4zlXO5eRNbvTO9iTmfFj+c73XplnPns+O3auTd+qWtrNpNGsp9lspVqtZv9zR7Ni/VxWrxzI6MXRjKweTquzM2dPNfJE+aUM1tfk337013Ld6uuyvXdbnh29sNQdBgAAAAAAAAAAAAAAAAAAAAAAAGCZqCx1AAAAAAAAAAAAAAAAAAAAAAAAAACWjyJFKtUyqSaVrjLbtiabticnPv77uTQ9lxWrV+UDH/jO/Og/+LEMDa3JqpEdufk1b07RbmXs6ptSO3s6xdxcMjmRdlmk89ALOXj0ZM6cOJlapZay2pFNW7blyu07sjg9kcGBvjRnGzl4sSsdrTKtozOZfOhY1s5XUkwXef5jp/K2q3emSFIvutNOM0VRplatZXJyIs898ULu+aMvZ2xsJu1qZ8an3Wn9/QAAD2lJREFU59NYnM53vPHv5xXXvyUdZXdWDXXk+Oi+nDg+nvHJS0vdYgAAAAAAAAAAAAAAAAAAAAAAAACWidpSBwAAAAAAAAAAAAAAAAAAAAAAAABg+Sgq1XR1V9NuN9LsKzK0PTlwpJJKZz3/7J/9/fT09mdgxVAunDmbO++4NQMrVqaro0itnbQHVqT/1P2Z6RtI+9SpFJt3p7Fuc95zyxW59aYbc/y553LXd30gb+rqTr2rO2W7lS987FdSbt6Sq9dWsrM6mztuGMzXnr6U6/esyqVDC7lvbH+qZw5n7503ZqE5laLsSsqpNBrtdPX15U3ve2M+/fufzsxCI/1FmYVGme56R/p6BtJqNTLUuya7e27KgfKRtCdmUxYLS91iAAAAAAAAAAAAAAAAAAAAAAAAAJaJylIHAAAAAAAAAAAAAAAAAAAAAAAAAGD5qPasyNpb/1aGt+/N6bF6zs0UufdoZ95yx1xGVg2nlkYqZZF1Gzdn644d6ai1Mjk6mmqlno6OnvTVasmm7SmuvCa1opJqz0Bu2ntbrrjx9tz1be/PfKOZzu7uFJVKnv7iPenpKPPqm3qzeqSdlSO78viBSjoHr80zD27I3V1/LZPtjrQ2VXPm4vHMzs5k/9PHMjc3m8bCTKpdPSmbi3n3d9+dTRvXpLOrJ1PT05mcamRhZj6LC4sp0siN1+zN1t6rMtK7JkVqS91iAAAAAAAAAAAAAAAAAAAAAAAAAJYJf8ADAAAAAAAAAAAAAAAAAAAAAAAA4GXTqnRnof/GVNatyK6b+/LoEwfygfdOZ+W61ZmZncns3FyKrum0G7OpVdtpNRu5NDadteWlNCvNFHfekrWnTqS1am06ajOppczA6r7MzZ9LpT2fxsJYpkYvpqu7J31rO/Pcg+M5cLSV/pXr8vl7n03PUCPbbuhL99BcDh95Mm94/+4MrSvTWGhnanY2XT3VTI4upFIk06OjKZtlZlNNe2YqtVpHuir1tJvtNCvzSTVp9Day47rdWbV2fWbnJnPkd35mqVsMAAAAAAAAAAAAAAAAAAAAAAAAwDJRlGW51BkAAAAAAAAAAAAAAAAAAAAAAAAAWCZGVo+Uf/27vz9jp49ldnE2733/d+e3f+PX8p73//UcOfSxVBbKdAxMZ3aqksXWTLqHKzl3oCdvee0jKTrKFN1lOmtlmtNJT0cl5UIl919an9u2jue1V0ymUitStssUrSRlkY9+8ZV55uCGFEXSbpepVIqURVKtVtNutlOpJX/6V74yZZkUxf8/a1HUUimK/Nlv+/7s/31FkdSKjiTJwuJC6vXOPxuQD/7WR3L67PmXrAIAAAAAAAAAAAAAAAAAAAAAAAAA3xq1pQ4AAAAAAAAAAAAAAAAAAAAAAAAAwPJRqdbywIMPpDF+KTfuvT1Hj57N+aOnMj1fy+L8pUxPdmfjylZmZ2fT0dOdfU/PpFhIVnc20upoptpRpKteS1F0pTXXSK3WTFlOp9mcTEdlKkklhw5fmcG+VlYPHUilbKZaq13e+yVByqRSrSZlUlwuFZfrLx3T/n8VLpfLpJHG5TUrabYaL5nyX48HAAAAAAAAAAAAAAAAAAAAAAAAgG+F2lIHAAAAAAAAAAAAAAAAAAAAAAAAAGD5aLXbmZudym2vfm16u/pz4sTJrCoXc+n00Zw5u5hyoZWysSFzc4dTmx3Mwth4rtg2nHq7kmpqqbXaKeaS5/eN5Kn9Z/P2m5upFWXmFiuZnCjy+NHvyHNfPZX24FW5Yuv1SXt0qV8ZAAAAAAAAAAAAAAAAAAAAAAAAAL4lKksdAAAAAAAAAAAAAAAAAAAAAAAAAICXT1EUVxRF8eRLjsmiKH6sKIoVRVF8tiiKA5fPwy+Z85NFURwsiuLFoije/JL63qIonrn87N8URVH85fsnN950RxoL7Zw6djizs1M53ihSKZKF+Y5Uugdy/tzFTI8WOXVhKiMrV+TaLZvTU2mnNZ20pqtpTiYnJuZy9cqpTE80U02RyfFaqh1l1gz2pt23KlOTE7n3vjILi7VvVSsBAAAAAAAAAAAAAAAAAAAAAAAAYElVljoAAAAAAAAAAAAAAAAAAAAAAAAAAC+fsixfLMvyhrIsb0iyN8lsko8l+Ykkny/LcleSz1++T1EUVyd5f5I9Se5O8itFUVQvL/fvknwgya7Lx91/2f61Wkcee/yRHHzmkazduiNbt2/PG9/7XZlvFikW5rNu/YacOzue6YVmDp8/kVXDHfm1j38sYycbqc010h5fTHWxnQ2Vs9myNlmzKuksk7mOMufGqnny4bHMT5WpVRupzO7PmTO1b2r/AAAAAAAAAAAAAAAAAAAAAAAAAOB/FpWlDgAAAAAAAAAAAAAAAAAAAAAAAADAknl9kkNlWR5L8q4kv3W5/ltJ3n35+l1JPlyW5UJZlkeSHExya1EU65IMlGX5YFmWZZLffsmcb6DIzNTFXPvK16RWLdJR78nMdDt7brghpy+N5YGvPJndOzZlZmEqrXYj9z7yTNZcsTNFynR1F+nuKtJZbef67e10dRaZm69koG8h9aLMH//O1tz7sUfymc88nK998dFcPHk6Zy5Wv5n9AgAAAAAAAAAAAAAAAAAAAAAAAID/aVSWOgAAAAAAAAAAAAAAAAAAAAAAAAAAS+b9SX7v8vWasizPJMnl88jl+oYkJ14y5+Tl2obL13++/g21Got5wxvflsHh1enq68tjX/xSHvzCR1OpFtm+eXVW9jXy6NNHU1QW8453b8u3vf2taTZnU3R05sLFjkzO1TPb6szETFcWKl3p7C9y+8aFzL4wkOdfqKbs6MqKns7s3lLP1EJfWn67BwAAAAAAAAAAAAAAAAAAAAAAAMD/ooqyLJc6AwAAAAAAAAAAAAAAAAAAAAAAAAAvs6Io6klOJ9lTluW5oijGy7IcesnzsbIsh4ui+OUkD5Zl+TuX67+e5FNJjif5mbIs33C5/uok/7Asy3d8nb0+kOQDl2+vSfLst/DVvpFVSS5+i/fYUpbl6m/xHgAAAAAAAAAAAAAAAAAAAAAAAACQ2lIHAAAAAAAAAAAAAAAAAAAAAAAAAGBJvCXJ42VZnrt8f64oinVlWZ4pimJdkvOX6yeTbHrJvI1JTl+ub/w69f9KWZYfTPLBJCmK4tGyLG/+5r3Gf7ul3BsAAAAAAAAAAAAAAAAAAAAAAAAAvtkqSx0AAAAAAAAAAAAAAAAAAAAAAAAAgCXxXUl+7yX3f5Lk+y5ff1+Sj7+k/v6iKDqLotiWZFeSh8uyPJNkqiiK24uiKJJ870vmAAAAAAAAAAAAAAAAAAAAAAAAAADfYrWlDgAAAAAAAAAAAAAAAAAAAAAAAADAy6soip4kb0zyt15S/tkkHymK4geSHE/yviQpy/K5oig+kuT5JM0kP1yWZevynB9K8ptJupPcc/kAAAAAAAAAAAAAAAAAAAAAAAAAAF4GRVmWS50BAAAAAAAAAAAAAAAAAAAAAAAAgGWiKIoPlGX5weW2NwAAAAAAAAAAAAAAAAAAAAAAAAB8sxVlWS51BgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP4KKksdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgL+aylIHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4K+mstQBAAAAAAAAAAAAAAAAAAAAAAAAAFgeiqK4uyiKF4uiOFgUxU98E9b7j0VRnC+K4tmX1FYURfHZoigOXD4Pv+TZT17e+8WiKN78kvreoiieufzs3xRFUfyPZgMAAAAAAAAAAAAAAAAAAAAAAACAb7XKUgcAAAAAAAAAAAAAAAAAAAAAAAAA4H99RVFUk/xykrckuTrJdxVFcfX/4LK/meTuP1f7iSSfL8tyV5LPX77P5b3en2TP5Tm/cjlTkvy7JB9Isuvy8efXBAAAAAAAAAAAAAAAAAAAAAAAAID/6VSWOgAAAAAAAAAAAAAAAAAAAAAAAAAAy8KtSQ6WZXm4LMvFJB9O8q7/kQXLsrw/yeifK78ryW9dvv6tJO9+Sf3DZVkulGV5JMnBJLcWRbEuyUBZlg+WZVkm+e2XzAEAAAAAAAAAAAAAAAAAAAAAAACA/2lVljoAAAAAAAAAAAAAAAAAAAAAAAAAAMvChiQnXnJ/8nLtm21NWZZnkuTyeeQv2X/D5etvdS4AAAAAAAAAAAAAAAAAAAAAAAAA+KaqLHUAAAAAAAAAAAAAAAAAAAAAAAAAAJaF4uvUyv8J9l/qXAAAAAAAAAAAAAAAAAAAAAAAAADw36Wy1AEAAAAAAAAAAAAAAAAAAAAAAAAAWBZOJtn0kvuNSU5/C/Y5VxTFuiS5fD7/l+x/8vL1tzoXAAAAAAAAAAAAAAAAwP+v3TlGzSqIAjD63V9R7N1AiuzB0k0IqUxhJboHW1chdkI604hb0DouQAQXYBsZm79I+1B5Qc+BgWFg7v0AAAAAAADgjzrsHQAAAAAAAAAAAAAAAAAAAAAAAADAf+FzdTozJzNzrzqrLv/Cnsvq/Hg/r97feD+bmfszc1KdVp/WWt+rHzPzaGamenrjDwAAAAAAAAAAAAAAAAAAAAAAAADcWnf3DgAAAAAAAAAAAAAAAAAAAAAAAADg37fWup6Zl9XH6k71Zq119TszZ+Zd9bh6ODPfqlfV6+piZp5VX6snx/1XM3NRfamuqxdrrZ/HUc+rt9WD6sPxAAAAAAAAAAAAAAAAAAAAAAAAAMCtNmutvRsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADY4LB3AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANsc9g4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgm8PeAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGxz2DsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAbQ57BwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALDNYe8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtjnsHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMA2vwAg6zK1LkoiQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = tv.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = torch.Tensor([0]), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18  (pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_resnet = tv.models.resnet18(pretrained=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(model_resnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 50.013. Train acc: 0.000. Train Loss: 1508.043\n",
      "epoch 1, loss 6.1805, train acc 0.000, test acc 0.542, time 60.7 sec\n",
      "Step. time since epoch: 32.515. Train acc: 0.496. Train Loss: 763.980\n",
      "epoch 2, loss 3.1311, train acc 0.496, test acc 0.458, time 42.9 sec\n",
      "Step. time since epoch: 22.632. Train acc: 0.504. Train Loss: 31084312.000\n",
      "epoch 3, loss 127394.7213, train acc 0.504, test acc 0.458, time 31.2 sec\n",
      "Step. time since epoch: 23.203. Train acc: 0.504. Train Loss: nan\n",
      "epoch 4, loss nan, train acc 0.504, test acc 0.458, time 33.2 sec\n",
      "Step. time since epoch: 24.033. Train acc: 0.504. Train Loss: nan\n",
      "epoch 5, loss nan, train acc 0.504, test acc 0.458, time 33.9 sec\n"
     ]
    }
   ],
   "source": [
    "train(model_resnet, dataloaders['train'], dataloaders['val'], optimizer_ft, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg16 (pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = tv.models.vgg16(pretrained=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(model_vgg.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1318.677. Train acc: 0.000. Train Loss: 1687.099\n",
      "epoch 1, loss 6.9143, train acc 0.000, test acc 0.542, time 1544.1 sec\n",
      "Step. time since epoch: 1177.947. Train acc: 0.496. Train Loss: 642.666\n",
      "epoch 2, loss 2.6339, train acc 0.496, test acc 0.458, time 1352.1 sec\n",
      "Step. time since epoch: 691.465. Train acc: 0.504. Train Loss: 17309127147520.000\n",
      "epoch 3, loss 70939045686.5574, train acc 0.504, test acc 0.458, time 773.1 sec\n",
      "Step. time since epoch: 348.035. Train acc: 0.504. Train Loss: nan\n",
      "epoch 4, loss nan, train acc 0.504, test acc 0.458, time 406.8 sec\n",
      "Step. time since epoch: 184.335. Train acc: 0.504. Train Loss: nan\n",
      "epoch 5, loss nan, train acc 0.504, test acc 0.458, time 245.2 sec\n"
     ]
    }
   ],
   "source": [
    "train(model_vgg, dataloaders['train'], dataloaders['val'], optimizer_ft, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ddefe5f5b444ae8c043959a4351d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=46830571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_resnet = tv.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=10, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.fc = nn.Linear(in_features=512, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model_resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 8.843. Train acc: 0.525. Train Loss: 4086.816\n",
      "epoch 1, loss 16.7492, train acc 0.525, test acc 0.928, time 16.0 sec\n",
      "Step. time since epoch: 8.504. Train acc: 0.906. Train Loss: 363.249\n",
      "epoch 2, loss 1.4887, train acc 0.906, test acc 0.614, time 15.5 sec\n",
      "Step. time since epoch: 8.362. Train acc: 0.615. Train Loss: 4202.022\n",
      "epoch 3, loss 17.2214, train acc 0.615, test acc 0.778, time 15.5 sec\n",
      "Step. time since epoch: 8.575. Train acc: 0.754. Train Loss: 1949.940\n",
      "epoch 4, loss 7.9916, train acc 0.754, test acc 0.941, time 15.7 sec\n",
      "Step. time since epoch: 8.449. Train acc: 0.918. Train Loss: 412.587\n",
      "epoch 5, loss 1.6909, train acc 0.918, test acc 0.739, time 15.6 sec\n"
     ]
    }
   ],
   "source": [
    "train(model_resnet, dataloaders['train'], dataloaders['val'], optimizer_ft, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449f0e4d869e4f4ca7d747524c35adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_vgg = tv.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.classifier[6] = nn.Linear(in_features=4096, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model_vgg.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 356.633. Train acc: 0.061. Train Loss: 590.129\n",
      "epoch 1, loss 2.4186, train acc 0.061, test acc 0.974, time 421.1 sec\n",
      "Step. time since epoch: 240.230. Train acc: 0.922. Train Loss: 131.976\n",
      "epoch 2, loss 0.5409, train acc 0.922, test acc 0.961, time 272.1 sec\n",
      "Step. time since epoch: 267.652. Train acc: 0.939. Train Loss: 132.846\n",
      "epoch 3, loss 0.5444, train acc 0.939, test acc 0.954, time 299.5 sec\n",
      "Step. time since epoch: 290.932. Train acc: 0.930. Train Loss: 150.778\n",
      "epoch 4, loss 0.6179, train acc 0.930, test acc 0.967, time 320.5 sec\n",
      "Step. time since epoch: 246.113. Train acc: 0.951. Train Loss: 188.381\n",
      "epoch 5, loss 0.7721, train acc 0.951, test acc 0.967, time 283.3 sec\n"
     ]
    }
   ],
   "source": [
    "train(model_vgg, dataloaders['train'], dataloaders['val'], optimizer_ft, 5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet18(pretrained=True) + augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: albumentations in c:\\users\\user\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: qudida>=0.0.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from albumentations) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in c:\\users\\user\\anaconda3\\lib\\site-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from albumentations) (0.17.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from albumentations) (1.22.3)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python-headless>=4.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2020.10.1)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U albumentations\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# ! conda install -c conda-forge imgaug\n",
    "! conda install -c conda-forge albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from typing_extensions import ParamSpec, Concatenate\n",
    "#from typing_extensions import Concatenate\n",
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms_aug = {\n",
    "    'train': tv.transforms.Compose([\n",
    "        tv.transforms.RandomResizedCrop(224),\n",
    "        tv.transforms.RandomHorizontalFlip(), \n",
    "        tv.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        tv.transforms.RandomRotation(degrees=90),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': tv.transforms.Compose([\n",
    "        tv.transforms.Resize(256),\n",
    "        tv.transforms.CenterCrop(224),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets_aug = {x: tv.datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms_aug[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders_aug = {x: torch.utils.data.DataLoader(image_datasets_aug[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes_aug = {x: len(image_datasets_aug[x]) for x in ['train', 'val']}\n",
    "class_names_aug = image_datasets_aug['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_resnet = tv.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.fc = nn.Linear(in_features=512, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model_resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 2.972. Train acc: 0.250. Train Loss: 7.467\n",
      "Step. time since epoch: 3.144. Train acc: 1.000. Train Loss: 0.200\n",
      "Step. time since epoch: 3.317. Train acc: 0.500. Train Loss: 2.736\n",
      "Step. time since epoch: 3.455. Train acc: 0.500. Train Loss: 4.104\n",
      "Step. time since epoch: 3.576. Train acc: 1.000. Train Loss: 0.010\n",
      "Step. time since epoch: 3.704. Train acc: 0.500. Train Loss: 4.168\n",
      "Step. time since epoch: 3.842. Train acc: 0.500. Train Loss: 5.398\n",
      "Step. time since epoch: 3.950. Train acc: 0.750. Train Loss: 1.636\n",
      "Step. time since epoch: 4.068. Train acc: 0.250. Train Loss: 17.826\n",
      "Step. time since epoch: 4.212. Train acc: 0.250. Train Loss: 18.067\n",
      "Step. time since epoch: 4.334. Train acc: 0.500. Train Loss: 4.480\n",
      "Step. time since epoch: 4.454. Train acc: 0.750. Train Loss: 8.321\n",
      "Step. time since epoch: 4.565. Train acc: 0.500. Train Loss: 6.495\n",
      "Step. time since epoch: 4.683. Train acc: 0.750. Train Loss: 2.729\n",
      "Step. time since epoch: 4.800. Train acc: 0.500. Train Loss: 6.256\n",
      "Step. time since epoch: 4.918. Train acc: 0.000. Train Loss: 28.849\n",
      "Step. time since epoch: 5.041. Train acc: 0.750. Train Loss: 1.684\n",
      "Step. time since epoch: 5.151. Train acc: 0.750. Train Loss: 4.737\n",
      "Step. time since epoch: 5.262. Train acc: 1.000. Train Loss: 0.140\n",
      "Step. time since epoch: 5.373. Train acc: 0.750. Train Loss: 0.752\n",
      "Step. time since epoch: 5.492. Train acc: 0.750. Train Loss: 3.214\n",
      "Step. time since epoch: 5.617. Train acc: 1.000. Train Loss: 0.144\n",
      "Step. time since epoch: 5.730. Train acc: 0.750. Train Loss: 2.723\n",
      "Step. time since epoch: 5.845. Train acc: 0.750. Train Loss: 2.578\n",
      "Step. time since epoch: 5.958. Train acc: 0.750. Train Loss: 3.733\n",
      "Step. time since epoch: 6.078. Train acc: 1.000. Train Loss: 0.097\n",
      "Step. time since epoch: 6.203. Train acc: 0.750. Train Loss: 0.893\n",
      "Step. time since epoch: 6.316. Train acc: 1.000. Train Loss: 0.336\n",
      "Step. time since epoch: 6.456. Train acc: 0.750. Train Loss: 4.456\n",
      "Step. time since epoch: 6.570. Train acc: 1.000. Train Loss: 0.032\n",
      "Step. time since epoch: 6.696. Train acc: 1.000. Train Loss: 0.032\n",
      "Step. time since epoch: 6.808. Train acc: 1.000. Train Loss: 0.407\n",
      "Step. time since epoch: 6.926. Train acc: 0.750. Train Loss: 2.369\n",
      "Step. time since epoch: 7.038. Train acc: 1.000. Train Loss: 0.588\n",
      "Step. time since epoch: 7.158. Train acc: 1.000. Train Loss: 0.170\n",
      "Step. time since epoch: 7.278. Train acc: 0.750. Train Loss: 1.022\n",
      "Step. time since epoch: 7.393. Train acc: 0.500. Train Loss: 10.370\n",
      "Step. time since epoch: 7.503. Train acc: 0.500. Train Loss: 5.983\n",
      "Step. time since epoch: 7.611. Train acc: 0.750. Train Loss: 2.228\n",
      "Step. time since epoch: 7.721. Train acc: 0.750. Train Loss: 1.463\n",
      "Step. time since epoch: 7.840. Train acc: 0.500. Train Loss: 6.187\n",
      "Step. time since epoch: 7.959. Train acc: 0.500. Train Loss: 4.500\n",
      "Step. time since epoch: 8.073. Train acc: 0.750. Train Loss: 6.108\n",
      "Step. time since epoch: 8.191. Train acc: 1.000. Train Loss: 0.054\n",
      "Step. time since epoch: 8.299. Train acc: 0.250. Train Loss: 5.771\n",
      "Step. time since epoch: 8.417. Train acc: 0.750. Train Loss: 1.672\n",
      "Step. time since epoch: 8.533. Train acc: 0.750. Train Loss: 2.011\n",
      "Step. time since epoch: 8.649. Train acc: 0.750. Train Loss: 1.662\n",
      "Step. time since epoch: 8.770. Train acc: 0.500. Train Loss: 4.504\n",
      "Step. time since epoch: 8.881. Train acc: 1.000. Train Loss: 0.154\n",
      "Step. time since epoch: 8.995. Train acc: 1.000. Train Loss: 0.758\n",
      "Step. time since epoch: 9.109. Train acc: 0.750. Train Loss: 2.540\n",
      "Step. time since epoch: 9.244. Train acc: 0.500. Train Loss: 10.090\n",
      "Step. time since epoch: 9.349. Train acc: 1.000. Train Loss: 0.176\n",
      "Step. time since epoch: 9.443. Train acc: 1.000. Train Loss: 0.535\n",
      "Step. time since epoch: 9.549. Train acc: 0.750. Train Loss: 10.452\n",
      "Step. time since epoch: 9.650. Train acc: 0.750. Train Loss: 1.212\n",
      "Step. time since epoch: 9.751. Train acc: 0.750. Train Loss: 4.706\n",
      "Step. time since epoch: 9.848. Train acc: 0.500. Train Loss: 7.030\n",
      "Step. time since epoch: 9.957. Train acc: 1.000. Train Loss: 0.482\n",
      "Step. time since epoch: 10.064. Train acc: 0.500. Train Loss: 3.923\n",
      "epoch 1, loss 0.9976, train acc 0.713, test acc 0.889, time 18.1 sec\n",
      "Step. time since epoch: 2.459. Train acc: 0.750. Train Loss: 3.739\n",
      "Step. time since epoch: 2.559. Train acc: 1.000. Train Loss: 0.147\n",
      "Step. time since epoch: 2.663. Train acc: 0.750. Train Loss: 1.757\n",
      "Step. time since epoch: 2.772. Train acc: 1.000. Train Loss: 0.053\n",
      "Step. time since epoch: 2.886. Train acc: 0.750. Train Loss: 1.145\n",
      "Step. time since epoch: 2.993. Train acc: 0.750. Train Loss: 5.943\n",
      "Step. time since epoch: 3.110. Train acc: 1.000. Train Loss: 0.007\n",
      "Step. time since epoch: 3.233. Train acc: 0.750. Train Loss: 1.145\n",
      "Step. time since epoch: 3.356. Train acc: 0.750. Train Loss: 2.460\n",
      "Step. time since epoch: 3.463. Train acc: 0.750. Train Loss: 4.544\n",
      "Step. time since epoch: 3.572. Train acc: 1.000. Train Loss: 0.548\n",
      "Step. time since epoch: 3.674. Train acc: 1.000. Train Loss: 0.548\n",
      "Step. time since epoch: 3.784. Train acc: 0.750. Train Loss: 4.413\n",
      "Step. time since epoch: 3.888. Train acc: 0.750. Train Loss: 2.754\n",
      "Step. time since epoch: 3.996. Train acc: 0.500. Train Loss: 3.266\n",
      "Step. time since epoch: 4.110. Train acc: 0.500. Train Loss: 5.924\n",
      "Step. time since epoch: 4.222. Train acc: 1.000. Train Loss: 0.085\n",
      "Step. time since epoch: 4.331. Train acc: 1.000. Train Loss: 0.051\n",
      "Step. time since epoch: 4.444. Train acc: 1.000. Train Loss: 0.177\n",
      "Step. time since epoch: 4.551. Train acc: 0.750. Train Loss: 6.420\n",
      "Step. time since epoch: 4.665. Train acc: 0.000. Train Loss: 20.097\n",
      "Step. time since epoch: 4.780. Train acc: 0.250. Train Loss: 34.435\n",
      "Step. time since epoch: 4.900. Train acc: 1.000. Train Loss: 0.078\n",
      "Step. time since epoch: 5.015. Train acc: 1.000. Train Loss: 0.835\n",
      "Step. time since epoch: 5.129. Train acc: 1.000. Train Loss: 0.343\n",
      "Step. time since epoch: 5.245. Train acc: 1.000. Train Loss: 0.059\n",
      "Step. time since epoch: 5.363. Train acc: 1.000. Train Loss: 0.579\n",
      "Step. time since epoch: 5.484. Train acc: 0.750. Train Loss: 1.084\n",
      "Step. time since epoch: 5.612. Train acc: 0.750. Train Loss: 8.998\n",
      "Step. time since epoch: 5.735. Train acc: 0.250. Train Loss: 21.582\n",
      "Step. time since epoch: 5.855. Train acc: 1.000. Train Loss: 0.193\n",
      "Step. time since epoch: 5.964. Train acc: 1.000. Train Loss: 0.399\n",
      "Step. time since epoch: 6.078. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 6.197. Train acc: 1.000. Train Loss: 0.283\n",
      "Step. time since epoch: 6.317. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 6.435. Train acc: 1.000. Train Loss: 0.029\n",
      "Step. time since epoch: 6.541. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 6.655. Train acc: 1.000. Train Loss: 0.043\n",
      "Step. time since epoch: 6.769. Train acc: 0.750. Train Loss: 0.741\n",
      "Step. time since epoch: 6.879. Train acc: 0.750. Train Loss: 3.440\n",
      "Step. time since epoch: 6.994. Train acc: 0.750. Train Loss: 2.724\n",
      "Step. time since epoch: 7.108. Train acc: 1.000. Train Loss: 0.530\n",
      "Step. time since epoch: 7.239. Train acc: 0.750. Train Loss: 1.304\n",
      "Step. time since epoch: 7.362. Train acc: 0.750. Train Loss: 1.215\n",
      "Step. time since epoch: 7.484. Train acc: 1.000. Train Loss: 0.035\n",
      "Step. time since epoch: 7.597. Train acc: 0.750. Train Loss: 5.074\n",
      "Step. time since epoch: 7.718. Train acc: 1.000. Train Loss: 0.179\n",
      "Step. time since epoch: 7.842. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 7.965. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 8.104. Train acc: 1.000. Train Loss: 0.004\n",
      "Step. time since epoch: 8.238. Train acc: 1.000. Train Loss: 0.132\n",
      "Step. time since epoch: 8.354. Train acc: 1.000. Train Loss: 0.130\n",
      "Step. time since epoch: 8.457. Train acc: 1.000. Train Loss: 0.092\n",
      "Step. time since epoch: 8.573. Train acc: 1.000. Train Loss: 0.009\n",
      "Step. time since epoch: 8.684. Train acc: 0.250. Train Loss: 12.183\n",
      "Step. time since epoch: 8.807. Train acc: 1.000. Train Loss: 0.592\n",
      "Step. time since epoch: 8.922. Train acc: 0.750. Train Loss: 0.815\n",
      "Step. time since epoch: 9.024. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 9.133. Train acc: 1.000. Train Loss: 0.102\n",
      "Step. time since epoch: 9.242. Train acc: 0.750. Train Loss: 0.859\n",
      "Step. time since epoch: 9.358. Train acc: 0.750. Train Loss: 6.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.7007, train acc 0.844, test acc 0.915, time 18.6 sec\n",
      "Step. time since epoch: 2.739. Train acc: 1.000. Train Loss: 0.425\n",
      "Step. time since epoch: 3.266. Train acc: 1.000. Train Loss: 0.135\n",
      "Step. time since epoch: 3.526. Train acc: 0.750. Train Loss: 11.081\n",
      "Step. time since epoch: 3.689. Train acc: 1.000. Train Loss: 0.007\n",
      "Step. time since epoch: 3.812. Train acc: 1.000. Train Loss: 0.169\n",
      "Step. time since epoch: 3.936. Train acc: 0.750. Train Loss: 3.297\n",
      "Step. time since epoch: 4.059. Train acc: 0.750. Train Loss: 0.991\n",
      "Step. time since epoch: 4.182. Train acc: 0.750. Train Loss: 1.724\n",
      "Step. time since epoch: 4.304. Train acc: 0.750. Train Loss: 1.748\n",
      "Step. time since epoch: 4.436. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 4.562. Train acc: 0.750. Train Loss: 5.238\n",
      "Step. time since epoch: 4.684. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 4.808. Train acc: 0.750. Train Loss: 1.242\n",
      "Step. time since epoch: 4.914. Train acc: 0.750. Train Loss: 0.952\n",
      "Step. time since epoch: 5.025. Train acc: 1.000. Train Loss: 0.077\n",
      "Step. time since epoch: 5.134. Train acc: 1.000. Train Loss: 0.009\n",
      "Step. time since epoch: 5.375. Train acc: 1.000. Train Loss: 0.509\n",
      "Step. time since epoch: 5.493. Train acc: 0.750. Train Loss: 4.994\n",
      "Step. time since epoch: 5.625. Train acc: 1.000. Train Loss: 0.097\n",
      "Step. time since epoch: 5.755. Train acc: 0.500. Train Loss: 7.652\n",
      "Step. time since epoch: 5.886. Train acc: 0.750. Train Loss: 5.899\n",
      "Step. time since epoch: 6.002. Train acc: 1.000. Train Loss: 0.653\n",
      "Step. time since epoch: 6.111. Train acc: 0.750. Train Loss: 6.138\n",
      "Step. time since epoch: 6.224. Train acc: 1.000. Train Loss: 0.025\n",
      "Step. time since epoch: 6.343. Train acc: 0.750. Train Loss: 1.949\n",
      "Step. time since epoch: 6.461. Train acc: 0.500. Train Loss: 13.194\n",
      "Step. time since epoch: 6.573. Train acc: 1.000. Train Loss: 0.059\n",
      "Step. time since epoch: 6.692. Train acc: 1.000. Train Loss: 0.053\n",
      "Step. time since epoch: 6.809. Train acc: 0.750. Train Loss: 2.824\n",
      "Step. time since epoch: 6.922. Train acc: 0.750. Train Loss: 1.043\n",
      "Step. time since epoch: 7.033. Train acc: 1.000. Train Loss: 0.004\n",
      "Step. time since epoch: 7.157. Train acc: 0.750. Train Loss: 1.520\n",
      "Step. time since epoch: 7.278. Train acc: 0.750. Train Loss: 0.984\n",
      "Step. time since epoch: 7.392. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 7.498. Train acc: 0.750. Train Loss: 5.063\n",
      "Step. time since epoch: 7.604. Train acc: 0.750. Train Loss: 2.491\n",
      "Step. time since epoch: 7.715. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 7.831. Train acc: 1.000. Train Loss: 0.562\n",
      "Step. time since epoch: 7.934. Train acc: 0.750. Train Loss: 1.512\n",
      "Step. time since epoch: 8.035. Train acc: 0.750. Train Loss: 2.024\n",
      "Step. time since epoch: 8.144. Train acc: 1.000. Train Loss: 0.022\n",
      "Step. time since epoch: 8.261. Train acc: 1.000. Train Loss: 0.206\n",
      "Step. time since epoch: 8.369. Train acc: 0.750. Train Loss: 8.025\n",
      "Step. time since epoch: 8.473. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 8.581. Train acc: 1.000. Train Loss: 0.090\n",
      "Step. time since epoch: 8.686. Train acc: 1.000. Train Loss: 0.299\n",
      "Step. time since epoch: 8.794. Train acc: 1.000. Train Loss: 0.066\n",
      "Step. time since epoch: 8.898. Train acc: 1.000. Train Loss: 0.517\n",
      "Step. time since epoch: 9.006. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 9.117. Train acc: 1.000. Train Loss: 0.418\n",
      "Step. time since epoch: 9.243. Train acc: 0.750. Train Loss: 8.157\n",
      "Step. time since epoch: 9.361. Train acc: 0.500. Train Loss: 5.691\n",
      "Step. time since epoch: 9.502. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 9.633. Train acc: 1.000. Train Loss: 0.009\n",
      "Step. time since epoch: 9.764. Train acc: 0.750. Train Loss: 6.121\n",
      "Step. time since epoch: 9.885. Train acc: 1.000. Train Loss: 0.010\n",
      "Step. time since epoch: 10.006. Train acc: 1.000. Train Loss: 0.131\n",
      "Step. time since epoch: 10.110. Train acc: 0.750. Train Loss: 4.676\n",
      "Step. time since epoch: 10.248. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 10.346. Train acc: 0.750. Train Loss: 8.530\n",
      "Step. time since epoch: 10.443. Train acc: 1.000. Train Loss: 0.107\n",
      "epoch 3, loss 0.5305, train acc 0.873, test acc 0.928, time 17.2 sec\n",
      "Step. time since epoch: 2.934. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 3.228. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 3.373. Train acc: 0.750. Train Loss: 7.148\n",
      "Step. time since epoch: 3.481. Train acc: 0.750. Train Loss: 1.028\n",
      "Step. time since epoch: 3.586. Train acc: 1.000. Train Loss: 0.273\n",
      "Step. time since epoch: 3.692. Train acc: 0.750. Train Loss: 4.995\n",
      "Step. time since epoch: 3.810. Train acc: 1.000. Train Loss: 0.004\n",
      "Step. time since epoch: 3.912. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 4.022. Train acc: 0.750. Train Loss: 5.539\n",
      "Step. time since epoch: 4.131. Train acc: 0.750. Train Loss: 2.248\n",
      "Step. time since epoch: 4.238. Train acc: 0.500. Train Loss: 9.055\n",
      "Step. time since epoch: 4.360. Train acc: 1.000. Train Loss: 0.238\n",
      "Step. time since epoch: 4.468. Train acc: 0.750. Train Loss: 1.456\n",
      "Step. time since epoch: 4.574. Train acc: 1.000. Train Loss: 0.235\n",
      "Step. time since epoch: 4.678. Train acc: 0.750. Train Loss: 2.540\n",
      "Step. time since epoch: 4.790. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 4.905. Train acc: 0.750. Train Loss: 1.540\n",
      "Step. time since epoch: 5.018. Train acc: 1.000. Train Loss: 0.439\n",
      "Step. time since epoch: 5.139. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 5.256. Train acc: 0.500. Train Loss: 3.864\n",
      "Step. time since epoch: 5.403. Train acc: 0.750. Train Loss: 0.999\n",
      "Step. time since epoch: 5.525. Train acc: 1.000. Train Loss: 0.317\n",
      "Step. time since epoch: 5.654. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 5.773. Train acc: 1.000. Train Loss: 0.050\n",
      "Step. time since epoch: 5.904. Train acc: 0.750. Train Loss: 2.336\n",
      "Step. time since epoch: 6.014. Train acc: 0.500. Train Loss: 6.583\n",
      "Step. time since epoch: 6.135. Train acc: 0.750. Train Loss: 3.545\n",
      "Step. time since epoch: 6.244. Train acc: 1.000. Train Loss: 0.440\n",
      "Step. time since epoch: 6.349. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 6.461. Train acc: 1.000. Train Loss: 0.116\n",
      "Step. time since epoch: 6.567. Train acc: 0.750. Train Loss: 5.754\n",
      "Step. time since epoch: 6.672. Train acc: 0.750. Train Loss: 1.129\n",
      "Step. time since epoch: 6.777. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 6.884. Train acc: 1.000. Train Loss: 0.057\n",
      "Step. time since epoch: 6.986. Train acc: 0.750. Train Loss: 3.548\n",
      "Step. time since epoch: 7.089. Train acc: 0.750. Train Loss: 2.586\n",
      "Step. time since epoch: 7.199. Train acc: 0.750. Train Loss: 2.947\n",
      "Step. time since epoch: 7.316. Train acc: 1.000. Train Loss: 0.131\n",
      "Step. time since epoch: 7.421. Train acc: 1.000. Train Loss: 0.054\n",
      "Step. time since epoch: 7.526. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 7.632. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 7.737. Train acc: 1.000. Train Loss: 0.184\n",
      "Step. time since epoch: 7.840. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 7.950. Train acc: 0.750. Train Loss: 7.232\n",
      "Step. time since epoch: 8.062. Train acc: 0.500. Train Loss: 5.923\n",
      "Step. time since epoch: 8.167. Train acc: 0.750. Train Loss: 5.014\n",
      "Step. time since epoch: 8.270. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 8.384. Train acc: 0.500. Train Loss: 7.796\n",
      "Step. time since epoch: 8.490. Train acc: 1.000. Train Loss: 0.474\n",
      "Step. time since epoch: 8.600. Train acc: 0.750. Train Loss: 3.661\n",
      "Step. time since epoch: 8.704. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 8.810. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 8.915. Train acc: 1.000. Train Loss: 0.097\n",
      "Step. time since epoch: 9.007. Train acc: 0.500. Train Loss: 3.818\n",
      "Step. time since epoch: 9.105. Train acc: 0.750. Train Loss: 4.828\n",
      "Step. time since epoch: 9.200. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 9.292. Train acc: 0.750. Train Loss: 9.958\n",
      "Step. time since epoch: 9.387. Train acc: 0.750. Train Loss: 1.774\n",
      "Step. time since epoch: 9.490. Train acc: 1.000. Train Loss: 0.037\n",
      "Step. time since epoch: 9.595. Train acc: 0.750. Train Loss: 5.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 9.716. Train acc: 0.750. Train Loss: 3.840\n",
      "epoch 4, loss 0.5365, train acc 0.852, test acc 0.915, time 17.2 sec\n",
      "Step. time since epoch: 2.565. Train acc: 1.000. Train Loss: 0.012\n",
      "Step. time since epoch: 2.711. Train acc: 0.750. Train Loss: 0.922\n",
      "Step. time since epoch: 2.889. Train acc: 0.750. Train Loss: 1.324\n",
      "Step. time since epoch: 3.061. Train acc: 1.000. Train Loss: 0.007\n",
      "Step. time since epoch: 3.213. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 3.376. Train acc: 0.750. Train Loss: 5.589\n",
      "Step. time since epoch: 3.494. Train acc: 0.750. Train Loss: 10.445\n",
      "Step. time since epoch: 3.604. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 3.715. Train acc: 0.750. Train Loss: 1.027\n",
      "Step. time since epoch: 3.825. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 3.938. Train acc: 1.000. Train Loss: 0.022\n",
      "Step. time since epoch: 4.045. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 4.151. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 4.261. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 4.368. Train acc: 0.500. Train Loss: 12.380\n",
      "Step. time since epoch: 4.481. Train acc: 1.000. Train Loss: 0.097\n",
      "Step. time since epoch: 4.583. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 4.686. Train acc: 1.000. Train Loss: 0.033\n",
      "Step. time since epoch: 4.789. Train acc: 0.750. Train Loss: 0.754\n",
      "Step. time since epoch: 4.899. Train acc: 0.500. Train Loss: 4.093\n",
      "Step. time since epoch: 5.011. Train acc: 1.000. Train Loss: 0.022\n",
      "Step. time since epoch: 5.116. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 5.236. Train acc: 0.750. Train Loss: 1.506\n",
      "Step. time since epoch: 5.339. Train acc: 0.750. Train Loss: 1.043\n",
      "Step. time since epoch: 5.446. Train acc: 0.750. Train Loss: 2.715\n",
      "Step. time since epoch: 5.553. Train acc: 1.000. Train Loss: 0.234\n",
      "Step. time since epoch: 5.658. Train acc: 0.750. Train Loss: 3.340\n",
      "Step. time since epoch: 5.776. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 5.899. Train acc: 0.500. Train Loss: 10.306\n",
      "Step. time since epoch: 6.023. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 6.127. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 6.235. Train acc: 1.000. Train Loss: 0.018\n",
      "Step. time since epoch: 6.355. Train acc: 0.750. Train Loss: 6.214\n",
      "Step. time since epoch: 6.461. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 6.572. Train acc: 0.750. Train Loss: 3.098\n",
      "Step. time since epoch: 6.669. Train acc: 0.750. Train Loss: 2.675\n",
      "Step. time since epoch: 6.779. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 6.889. Train acc: 0.750. Train Loss: 1.094\n",
      "Step. time since epoch: 6.995. Train acc: 1.000. Train Loss: 0.095\n",
      "Step. time since epoch: 7.107. Train acc: 1.000. Train Loss: 0.652\n",
      "Step. time since epoch: 7.209. Train acc: 0.750. Train Loss: 0.975\n",
      "Step. time since epoch: 7.315. Train acc: 1.000. Train Loss: 0.469\n",
      "Step. time since epoch: 7.424. Train acc: 1.000. Train Loss: 0.170\n",
      "Step. time since epoch: 7.537. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 7.638. Train acc: 1.000. Train Loss: 0.526\n",
      "Step. time since epoch: 7.743. Train acc: 0.750. Train Loss: 1.133\n",
      "Step. time since epoch: 7.847. Train acc: 1.000. Train Loss: 0.066\n",
      "Step. time since epoch: 7.953. Train acc: 1.000. Train Loss: 0.012\n",
      "Step. time since epoch: 8.068. Train acc: 0.750. Train Loss: 2.916\n",
      "Step. time since epoch: 8.180. Train acc: 1.000. Train Loss: 0.130\n",
      "Step. time since epoch: 8.291. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 8.402. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 8.514. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 8.614. Train acc: 1.000. Train Loss: 0.070\n",
      "Step. time since epoch: 8.706. Train acc: 0.750. Train Loss: 2.394\n",
      "Step. time since epoch: 8.802. Train acc: 0.500. Train Loss: 4.411\n",
      "Step. time since epoch: 8.901. Train acc: 1.000. Train Loss: 0.254\n",
      "Step. time since epoch: 8.995. Train acc: 0.750. Train Loss: 0.737\n",
      "Step. time since epoch: 9.121. Train acc: 1.000. Train Loss: 0.094\n",
      "Step. time since epoch: 9.229. Train acc: 0.750. Train Loss: 1.892\n",
      "Step. time since epoch: 9.320. Train acc: 1.000. Train Loss: 0.015\n",
      "epoch 5, loss 0.3525, train acc 0.885, test acc 0.928, time 16.5 sec\n"
     ]
    }
   ],
   "source": [
    "train(model_resnet, dataloaders_aug['train'], dataloaders_aug['val'], optimizer_ft, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg16(pretrained=True) + augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_vgg = tv.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.classifier[6] = nn.Linear(in_features=4096, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model_vgg.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 3.518. Train acc: 0.000. Train Loss: 10.413\n",
      "Step. time since epoch: 4.135. Train acc: 0.250. Train Loss: 8.209\n",
      "Step. time since epoch: 4.713. Train acc: 0.000. Train Loss: 10.529\n",
      "Step. time since epoch: 5.243. Train acc: 1.000. Train Loss: 1.224\n",
      "Step. time since epoch: 5.788. Train acc: 0.000. Train Loss: 21.529\n",
      "Step. time since epoch: 6.325. Train acc: 1.000. Train Loss: 0.319\n",
      "Step. time since epoch: 6.867. Train acc: 0.500. Train Loss: 14.016\n",
      "Step. time since epoch: 7.387. Train acc: 0.750. Train Loss: 1.657\n",
      "Step. time since epoch: 7.908. Train acc: 0.500. Train Loss: 2.508\n",
      "Step. time since epoch: 8.450. Train acc: 0.750. Train Loss: 3.554\n",
      "Step. time since epoch: 8.968. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 9.541. Train acc: 1.000. Train Loss: 0.047\n",
      "Step. time since epoch: 10.122. Train acc: 0.750. Train Loss: 2.163\n",
      "Step. time since epoch: 10.680. Train acc: 0.750. Train Loss: 10.512\n",
      "Step. time since epoch: 11.263. Train acc: 1.000. Train Loss: 0.718\n",
      "Step. time since epoch: 11.803. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 12.358. Train acc: 0.750. Train Loss: 9.376\n",
      "Step. time since epoch: 12.973. Train acc: 0.750. Train Loss: 0.914\n",
      "Step. time since epoch: 13.497. Train acc: 0.750. Train Loss: 1.912\n",
      "Step. time since epoch: 14.040. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 14.551. Train acc: 0.750. Train Loss: 0.930\n",
      "Step. time since epoch: 15.078. Train acc: 0.750. Train Loss: 0.877\n",
      "Step. time since epoch: 15.610. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 16.138. Train acc: 0.750. Train Loss: 16.869\n",
      "Step. time since epoch: 16.725. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 17.255. Train acc: 1.000. Train Loss: 0.263\n",
      "Step. time since epoch: 17.783. Train acc: 0.750. Train Loss: 6.260\n",
      "Step. time since epoch: 18.322. Train acc: 1.000. Train Loss: 0.076\n",
      "Step. time since epoch: 18.847. Train acc: 1.000. Train Loss: 0.012\n",
      "Step. time since epoch: 19.384. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 19.917. Train acc: 0.750. Train Loss: 2.128\n",
      "Step. time since epoch: 20.447. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 20.966. Train acc: 0.750. Train Loss: 2.530\n",
      "Step. time since epoch: 21.508. Train acc: 0.500. Train Loss: 24.903\n",
      "Step. time since epoch: 22.035. Train acc: 0.750. Train Loss: 25.622\n",
      "Step. time since epoch: 22.620. Train acc: 0.750. Train Loss: 5.614\n",
      "Step. time since epoch: 23.125. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 23.659. Train acc: 0.750. Train Loss: 17.154\n",
      "Step. time since epoch: 24.188. Train acc: 1.000. Train Loss: 0.225\n",
      "Step. time since epoch: 24.722. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 25.262. Train acc: 1.000. Train Loss: 0.059\n",
      "Step. time since epoch: 25.784. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 26.316. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 26.847. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 27.377. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 27.905. Train acc: 0.250. Train Loss: 20.654\n",
      "Step. time since epoch: 28.456. Train acc: 0.750. Train Loss: 21.749\n",
      "Step. time since epoch: 28.981. Train acc: 0.500. Train Loss: 18.231\n",
      "Step. time since epoch: 29.508. Train acc: 0.750. Train Loss: 1.000\n",
      "Step. time since epoch: 30.029. Train acc: 0.500. Train Loss: 37.942\n",
      "Step. time since epoch: 30.557. Train acc: 0.500. Train Loss: 20.293\n",
      "Step. time since epoch: 31.078. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 31.609. Train acc: 0.750. Train Loss: 17.357\n",
      "Step. time since epoch: 32.129. Train acc: 0.500. Train Loss: 30.393\n",
      "Step. time since epoch: 32.650. Train acc: 1.000. Train Loss: 0.201\n",
      "Step. time since epoch: 33.176. Train acc: 1.000. Train Loss: 0.015\n",
      "Step. time since epoch: 33.694. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 34.221. Train acc: 0.500. Train Loss: 22.144\n",
      "Step. time since epoch: 34.746. Train acc: 0.750. Train Loss: 2.265\n",
      "Step. time since epoch: 35.275. Train acc: 0.500. Train Loss: 14.768\n",
      "Step. time since epoch: 35.799. Train acc: 0.750. Train Loss: 2.229\n",
      "epoch 1, loss 1.6901, train acc 0.766, test acc 0.928, time 59.7 sec\n",
      "Step. time since epoch: 3.045. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 3.573. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 4.095. Train acc: 0.750. Train Loss: 6.525\n",
      "Step. time since epoch: 4.649. Train acc: 1.000. Train Loss: 0.005\n",
      "Step. time since epoch: 5.199. Train acc: 0.750. Train Loss: 1.209\n",
      "Step. time since epoch: 5.765. Train acc: 0.750. Train Loss: 8.880\n",
      "Step. time since epoch: 6.304. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 6.835. Train acc: 0.750. Train Loss: 9.745\n",
      "Step. time since epoch: 7.370. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 7.931. Train acc: 0.750. Train Loss: 3.652\n",
      "Step. time since epoch: 8.449. Train acc: 0.750. Train Loss: 1.653\n",
      "Step. time since epoch: 8.979. Train acc: 0.750. Train Loss: 4.579\n",
      "Step. time since epoch: 9.501. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 10.103. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 10.629. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 11.159. Train acc: 0.750. Train Loss: 1.525\n",
      "Step. time since epoch: 11.686. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 12.210. Train acc: 0.750. Train Loss: 1.099\n",
      "Step. time since epoch: 12.748. Train acc: 1.000. Train Loss: 0.027\n",
      "Step. time since epoch: 13.306. Train acc: 0.750. Train Loss: 3.062\n",
      "Step. time since epoch: 13.846. Train acc: 0.750. Train Loss: 2.915\n",
      "Step. time since epoch: 14.373. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 14.909. Train acc: 0.750. Train Loss: 6.458\n",
      "Step. time since epoch: 15.431. Train acc: 0.750. Train Loss: 11.253\n",
      "Step. time since epoch: 15.955. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 16.481. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 17.057. Train acc: 0.500. Train Loss: 10.921\n",
      "Step. time since epoch: 17.588. Train acc: 0.500. Train Loss: 2.376\n",
      "Step. time since epoch: 18.110. Train acc: 1.000. Train Loss: 0.043\n",
      "Step. time since epoch: 18.633. Train acc: 0.750. Train Loss: 9.096\n",
      "Step. time since epoch: 19.160. Train acc: 0.750. Train Loss: 5.304\n",
      "Step. time since epoch: 19.681. Train acc: 1.000. Train Loss: 0.108\n",
      "Step. time since epoch: 20.216. Train acc: 0.750. Train Loss: 8.094\n",
      "Step. time since epoch: 20.744. Train acc: 0.750. Train Loss: 5.906\n",
      "Step. time since epoch: 21.270. Train acc: 0.750. Train Loss: 9.935\n",
      "Step. time since epoch: 21.808. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 22.342. Train acc: 0.750. Train Loss: 12.768\n",
      "Step. time since epoch: 22.856. Train acc: 1.000. Train Loss: 0.011\n",
      "Step. time since epoch: 23.378. Train acc: 0.750. Train Loss: 6.537\n",
      "Step. time since epoch: 23.903. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 24.465. Train acc: 0.750. Train Loss: 11.402\n",
      "Step. time since epoch: 25.029. Train acc: 0.500. Train Loss: 12.916\n",
      "Step. time since epoch: 25.554. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 26.089. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 26.628. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 27.163. Train acc: 0.750. Train Loss: 4.325\n",
      "Step. time since epoch: 27.687. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 28.210. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 28.733. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 29.264. Train acc: 0.750. Train Loss: 5.572\n",
      "Step. time since epoch: 29.797. Train acc: 0.500. Train Loss: 8.820\n",
      "Step. time since epoch: 30.320. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 30.845. Train acc: 0.750. Train Loss: 2.705\n",
      "Step. time since epoch: 31.366. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 31.892. Train acc: 0.500. Train Loss: 12.423\n",
      "Step. time since epoch: 32.435. Train acc: 1.000. Train Loss: 0.178\n",
      "Step. time since epoch: 32.943. Train acc: 0.500. Train Loss: 11.101\n",
      "Step. time since epoch: 33.482. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 33.985. Train acc: 1.000. Train Loss: 0.744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 34.504. Train acc: 1.000. Train Loss: 0.136\n",
      "Step. time since epoch: 35.030. Train acc: 1.000. Train Loss: 0.000\n",
      "epoch 2, loss 0.8362, train acc 0.852, test acc 0.915, time 58.3 sec\n",
      "Step. time since epoch: 3.180. Train acc: 0.750. Train Loss: 3.233\n",
      "Step. time since epoch: 3.724. Train acc: 0.750. Train Loss: 1.267\n",
      "Step. time since epoch: 4.245. Train acc: 1.000. Train Loss: 0.281\n",
      "Step. time since epoch: 4.795. Train acc: 0.750. Train Loss: 1.700\n",
      "Step. time since epoch: 5.312. Train acc: 1.000. Train Loss: 0.047\n",
      "Step. time since epoch: 5.842. Train acc: 0.750. Train Loss: 0.980\n",
      "Step. time since epoch: 6.368. Train acc: 0.750. Train Loss: 24.001\n",
      "Step. time since epoch: 6.916. Train acc: 1.000. Train Loss: 0.010\n",
      "Step. time since epoch: 7.441. Train acc: 0.750. Train Loss: 3.361\n",
      "Step. time since epoch: 7.989. Train acc: 1.000. Train Loss: 0.010\n",
      "Step. time since epoch: 8.506. Train acc: 0.750. Train Loss: 2.694\n",
      "Step. time since epoch: 9.044. Train acc: 1.000. Train Loss: 0.597\n",
      "Step. time since epoch: 9.584. Train acc: 0.500. Train Loss: 12.288\n",
      "Step. time since epoch: 10.107. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 10.627. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 11.157. Train acc: 0.750. Train Loss: 0.889\n",
      "Step. time since epoch: 11.758. Train acc: 1.000. Train Loss: 0.018\n",
      "Step. time since epoch: 12.305. Train acc: 1.000. Train Loss: 0.032\n",
      "Step. time since epoch: 12.817. Train acc: 0.750. Train Loss: 1.379\n",
      "Step. time since epoch: 13.349. Train acc: 1.000. Train Loss: 0.088\n",
      "Step. time since epoch: 13.872. Train acc: 0.750. Train Loss: 21.723\n",
      "Step. time since epoch: 14.403. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 14.926. Train acc: 0.500. Train Loss: 8.978\n",
      "Step. time since epoch: 15.445. Train acc: 0.750. Train Loss: 4.131\n",
      "Step. time since epoch: 15.978. Train acc: 0.750. Train Loss: 16.495\n",
      "Step. time since epoch: 16.497. Train acc: 0.500. Train Loss: 19.771\n",
      "Step. time since epoch: 17.030. Train acc: 0.500. Train Loss: 10.280\n",
      "Step. time since epoch: 17.594. Train acc: 0.500. Train Loss: 10.706\n",
      "Step. time since epoch: 18.140. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 18.670. Train acc: 0.500. Train Loss: 15.697\n",
      "Step. time since epoch: 19.235. Train acc: 0.500. Train Loss: 39.755\n",
      "Step. time since epoch: 19.758. Train acc: 0.750. Train Loss: 8.887\n",
      "Step. time since epoch: 20.326. Train acc: 0.750. Train Loss: 9.207\n",
      "Step. time since epoch: 20.860. Train acc: 1.000. Train Loss: 0.076\n",
      "Step. time since epoch: 21.382. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 21.918. Train acc: 0.750. Train Loss: 1.361\n",
      "Step. time since epoch: 22.443. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 22.963. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 23.497. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 24.022. Train acc: 0.750. Train Loss: 3.642\n",
      "Step. time since epoch: 24.547. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 25.071. Train acc: 1.000. Train Loss: 0.021\n",
      "Step. time since epoch: 25.619. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 26.160. Train acc: 0.750. Train Loss: 7.178\n",
      "Step. time since epoch: 26.678. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 27.206. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 27.759. Train acc: 0.750. Train Loss: 3.481\n",
      "Step. time since epoch: 28.301. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 28.845. Train acc: 0.750. Train Loss: 2.493\n",
      "Step. time since epoch: 29.369. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 29.908. Train acc: 0.750. Train Loss: 8.323\n",
      "Step. time since epoch: 30.441. Train acc: 1.000. Train Loss: 0.332\n",
      "Step. time since epoch: 30.989. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 31.515. Train acc: 0.750. Train Loss: 21.501\n",
      "Step. time since epoch: 32.034. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 32.558. Train acc: 1.000. Train Loss: 0.802\n",
      "Step. time since epoch: 33.079. Train acc: 0.750. Train Loss: 3.493\n",
      "Step. time since epoch: 33.608. Train acc: 0.750. Train Loss: 0.812\n",
      "Step. time since epoch: 34.126. Train acc: 1.000. Train Loss: 0.018\n",
      "Step. time since epoch: 34.654. Train acc: 0.750. Train Loss: 5.873\n",
      "Step. time since epoch: 35.175. Train acc: 1.000. Train Loss: 0.000\n",
      "epoch 3, loss 1.1390, train acc 0.844, test acc 0.948, time 58.7 sec\n",
      "Step. time since epoch: 2.781. Train acc: 0.750. Train Loss: 7.134\n",
      "Step. time since epoch: 3.302. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 3.855. Train acc: 1.000. Train Loss: 0.510\n",
      "Step. time since epoch: 4.376. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 4.904. Train acc: 1.000. Train Loss: 0.001\n",
      "Step. time since epoch: 5.420. Train acc: 0.750. Train Loss: 8.942\n",
      "Step. time since epoch: 5.952. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 6.475. Train acc: 1.000. Train Loss: 0.007\n",
      "Step. time since epoch: 7.014. Train acc: 0.750. Train Loss: 18.200\n",
      "Step. time since epoch: 7.543. Train acc: 0.750. Train Loss: 22.042\n",
      "Step. time since epoch: 8.112. Train acc: 1.000. Train Loss: 0.680\n",
      "Step. time since epoch: 8.633. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 9.177. Train acc: 0.750. Train Loss: 4.700\n",
      "Step. time since epoch: 9.701. Train acc: 1.000. Train Loss: 0.121\n",
      "Step. time since epoch: 10.249. Train acc: 0.750. Train Loss: 2.489\n",
      "Step. time since epoch: 10.770. Train acc: 1.000. Train Loss: 0.011\n",
      "Step. time since epoch: 11.299. Train acc: 0.750. Train Loss: 1.880\n",
      "Step. time since epoch: 11.829. Train acc: 0.750. Train Loss: 2.572\n",
      "Step. time since epoch: 12.352. Train acc: 0.500. Train Loss: 8.161\n",
      "Step. time since epoch: 12.916. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 13.446. Train acc: 0.750. Train Loss: 5.998\n",
      "Step. time since epoch: 13.984. Train acc: 1.000. Train Loss: 0.372\n",
      "Step. time since epoch: 14.523. Train acc: 0.750. Train Loss: 5.988\n",
      "Step. time since epoch: 15.041. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 15.585. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 16.116. Train acc: 0.750. Train Loss: 13.392\n",
      "Step. time since epoch: 16.641. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 17.173. Train acc: 0.500. Train Loss: 6.398\n",
      "Step. time since epoch: 17.700. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 18.232. Train acc: 0.750. Train Loss: 15.219\n",
      "Step. time since epoch: 18.773. Train acc: 0.750. Train Loss: 11.570\n",
      "Step. time since epoch: 19.299. Train acc: 0.750. Train Loss: 5.325\n",
      "Step. time since epoch: 19.826. Train acc: 0.750. Train Loss: 6.084\n",
      "Step. time since epoch: 20.412. Train acc: 0.750. Train Loss: 8.623\n",
      "Step. time since epoch: 20.938. Train acc: 1.000. Train Loss: 0.009\n",
      "Step. time since epoch: 21.471. Train acc: 1.000. Train Loss: 0.392\n",
      "Step. time since epoch: 21.996. Train acc: 0.750. Train Loss: 8.384\n",
      "Step. time since epoch: 22.534. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 23.065. Train acc: 0.750. Train Loss: 2.757\n",
      "Step. time since epoch: 23.601. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 24.126. Train acc: 0.750. Train Loss: 1.471\n",
      "Step. time since epoch: 24.648. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 25.177. Train acc: 0.750. Train Loss: 0.756\n",
      "Step. time since epoch: 25.701. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 26.232. Train acc: 0.750. Train Loss: 9.089\n",
      "Step. time since epoch: 26.762. Train acc: 0.500. Train Loss: 9.604\n",
      "Step. time since epoch: 27.301. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 27.828. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 28.367. Train acc: 0.500. Train Loss: 21.849\n",
      "Step. time since epoch: 28.879. Train acc: 1.000. Train Loss: 0.019\n",
      "Step. time since epoch: 29.401. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 29.922. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 30.444. Train acc: 0.750. Train Loss: 7.299\n",
      "Step. time since epoch: 30.972. Train acc: 1.000. Train Loss: 0.014\n",
      "Step. time since epoch: 31.495. Train acc: 0.750. Train Loss: 2.839\n",
      "Step. time since epoch: 32.015. Train acc: 1.000. Train Loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 32.543. Train acc: 1.000. Train Loss: 0.006\n",
      "Step. time since epoch: 33.081. Train acc: 0.750. Train Loss: 4.359\n",
      "Step. time since epoch: 33.587. Train acc: 1.000. Train Loss: 0.002\n",
      "Step. time since epoch: 34.105. Train acc: 1.000. Train Loss: 0.207\n",
      "Step. time since epoch: 34.640. Train acc: 1.000. Train Loss: 0.367\n",
      "epoch 4, loss 0.9256, train acc 0.869, test acc 0.961, time 58.1 sec\n",
      "Step. time since epoch: 3.345. Train acc: 0.750. Train Loss: 4.319\n",
      "Step. time since epoch: 3.923. Train acc: 1.000. Train Loss: 0.012\n",
      "Step. time since epoch: 4.446. Train acc: 0.500. Train Loss: 24.112\n",
      "Step. time since epoch: 4.986. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 5.513. Train acc: 0.750. Train Loss: 1.161\n",
      "Step. time since epoch: 6.044. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 6.567. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 7.118. Train acc: 0.750. Train Loss: 6.453\n",
      "Step. time since epoch: 7.652. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 8.186. Train acc: 0.750. Train Loss: 11.849\n",
      "Step. time since epoch: 8.734. Train acc: 1.000. Train Loss: 0.017\n",
      "Step. time since epoch: 9.262. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 9.790. Train acc: 1.000. Train Loss: 0.047\n",
      "Step. time since epoch: 10.314. Train acc: 0.500. Train Loss: 7.912\n",
      "Step. time since epoch: 10.839. Train acc: 0.750. Train Loss: 0.891\n",
      "Step. time since epoch: 11.380. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 11.913. Train acc: 1.000. Train Loss: 0.249\n",
      "Step. time since epoch: 12.459. Train acc: 0.750. Train Loss: 2.608\n",
      "Step. time since epoch: 12.984. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 13.519. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 14.051. Train acc: 0.750. Train Loss: 5.149\n",
      "Step. time since epoch: 14.580. Train acc: 0.750. Train Loss: 0.868\n",
      "Step. time since epoch: 15.170. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 15.706. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 16.226. Train acc: 0.750. Train Loss: 3.050\n",
      "Step. time since epoch: 16.755. Train acc: 0.500. Train Loss: 20.624\n",
      "Step. time since epoch: 17.276. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 17.808. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 18.404. Train acc: 1.000. Train Loss: 0.409\n",
      "Step. time since epoch: 19.030. Train acc: 1.000. Train Loss: 0.076\n",
      "Step. time since epoch: 19.736. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 20.308. Train acc: 1.000. Train Loss: 0.294\n",
      "Step. time since epoch: 20.857. Train acc: 1.000. Train Loss: 0.016\n",
      "Step. time since epoch: 21.385. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 21.926. Train acc: 0.750. Train Loss: 0.751\n",
      "Step. time since epoch: 22.506. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 23.043. Train acc: 0.750. Train Loss: 2.678\n",
      "Step. time since epoch: 23.556. Train acc: 0.750. Train Loss: 1.198\n",
      "Step. time since epoch: 24.098. Train acc: 1.000. Train Loss: 0.085\n",
      "Step. time since epoch: 24.619. Train acc: 0.750. Train Loss: 6.466\n",
      "Step. time since epoch: 25.161. Train acc: 0.750. Train Loss: 2.544\n",
      "Step. time since epoch: 25.679. Train acc: 1.000. Train Loss: 0.003\n",
      "Step. time since epoch: 26.207. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 26.740. Train acc: 1.000. Train Loss: 0.048\n",
      "Step. time since epoch: 27.263. Train acc: 0.500. Train Loss: 6.773\n",
      "Step. time since epoch: 27.786. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 28.318. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 28.841. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 29.371. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 29.901. Train acc: 0.750. Train Loss: 15.205\n",
      "Step. time since epoch: 30.442. Train acc: 1.000. Train Loss: 0.040\n",
      "Step. time since epoch: 30.956. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 31.491. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 32.001. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 32.520. Train acc: 0.500. Train Loss: 31.893\n",
      "Step. time since epoch: 33.048. Train acc: 0.750. Train Loss: 19.168\n",
      "Step. time since epoch: 33.568. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 34.100. Train acc: 0.500. Train Loss: 14.388\n",
      "Step. time since epoch: 34.608. Train acc: 0.500. Train Loss: 16.230\n",
      "Step. time since epoch: 35.149. Train acc: 1.000. Train Loss: 0.000\n",
      "Step. time since epoch: 35.668. Train acc: 1.000. Train Loss: 0.002\n",
      "epoch 5, loss 0.8508, train acc 0.877, test acc 0.941, time 58.6 sec\n"
     ]
    }
   ],
   "source": [
    "train(model_vgg, dataloaders_aug['train'], dataloaders_aug['val'], optimizer_ft, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшим результатом оказалась сеть vgg16 pretrained = true без аугментации. Странно, так как лучшие результаты я ожидал от моделей с аугментацией. Хотя, vgg16 с аугментацией на 2 месте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning ResNet 18 Fashion Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = tv.transforms.Compose([\n",
    "    tv.transforms.Grayscale(3),\n",
    "    tv.transforms.RandomResizedCrop(224),\n",
    "    tv.transforms.CenterCrop(224),\n",
    "    tv.transforms.RandomHorizontalFlip(),\n",
    "    tv.transforms.RandomRotation(degrees=90),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=data_transforms, download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=data_transforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = tv.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.fc = nn.Linear(in_features=512, out_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model_resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 6.081. Train acc: 0.000. Train Loss: 1759.590\n",
      "Step. time since epoch: 12.252. Train acc: 0.152. Train Loss: 650.954\n",
      "Step. time since epoch: 18.368. Train acc: 0.191. Train Loss: 1286.135\n",
      "Step. time since epoch: 24.830. Train acc: 0.246. Train Loss: 2403.913\n",
      "Step. time since epoch: 31.388. Train acc: 0.105. Train Loss: 3981.875\n",
      "Step. time since epoch: 37.686. Train acc: 0.125. Train Loss: 6677.721\n",
      "Step. time since epoch: 43.850. Train acc: 0.227. Train Loss: 8216.759\n",
      "Step. time since epoch: 50.057. Train acc: 0.207. Train Loss: 12563.689\n",
      "Step. time since epoch: 56.568. Train acc: 0.121. Train Loss: 15565.336\n",
      "Step. time since epoch: 63.040. Train acc: 0.102. Train Loss: 24137.412\n",
      "Step. time since epoch: 69.814. Train acc: 0.090. Train Loss: 31958.248\n",
      "Step. time since epoch: 76.641. Train acc: 0.145. Train Loss: 26225.557\n",
      "Step. time since epoch: 83.292. Train acc: 0.164. Train Loss: 30318.227\n",
      "Step. time since epoch: 89.935. Train acc: 0.078. Train Loss: 32701.172\n",
      "Step. time since epoch: 96.593. Train acc: 0.109. Train Loss: 38057.750\n",
      "Step. time since epoch: 103.142. Train acc: 0.074. Train Loss: 24791.893\n",
      "Step. time since epoch: 109.671. Train acc: 0.117. Train Loss: 18638.750\n",
      "Step. time since epoch: 116.425. Train acc: 0.121. Train Loss: 24341.012\n",
      "Step. time since epoch: 123.033. Train acc: 0.098. Train Loss: 21103.629\n",
      "Step. time since epoch: 129.571. Train acc: 0.195. Train Loss: 18167.230\n",
      "Step. time since epoch: 136.081. Train acc: 0.168. Train Loss: 24592.221\n",
      "Step. time since epoch: 142.394. Train acc: 0.160. Train Loss: 30010.891\n",
      "Step. time since epoch: 148.929. Train acc: 0.176. Train Loss: 32593.740\n",
      "Step. time since epoch: 155.399. Train acc: 0.234. Train Loss: 16319.496\n",
      "Step. time since epoch: 164.068. Train acc: 0.309. Train Loss: 19816.797\n",
      "Step. time since epoch: 170.861. Train acc: 0.336. Train Loss: 17345.006\n",
      "Step. time since epoch: 177.771. Train acc: 0.305. Train Loss: 20369.812\n",
      "Step. time since epoch: 184.327. Train acc: 0.250. Train Loss: 26226.234\n",
      "Step. time since epoch: 190.687. Train acc: 0.297. Train Loss: 22633.678\n",
      "Step. time since epoch: 197.962. Train acc: 0.227. Train Loss: 19130.490\n",
      "Step. time since epoch: 204.367. Train acc: 0.309. Train Loss: 17581.580\n",
      "Step. time since epoch: 210.801. Train acc: 0.227. Train Loss: 10714.760\n",
      "Step. time since epoch: 217.125. Train acc: 0.223. Train Loss: 14168.656\n",
      "Step. time since epoch: 224.657. Train acc: 0.328. Train Loss: 10944.984\n",
      "Step. time since epoch: 231.444. Train acc: 0.215. Train Loss: 11181.344\n",
      "Step. time since epoch: 238.022. Train acc: 0.312. Train Loss: 7627.899\n",
      "Step. time since epoch: 244.530. Train acc: 0.305. Train Loss: 8056.798\n",
      "Step. time since epoch: 251.286. Train acc: 0.258. Train Loss: 10399.115\n",
      "Step. time since epoch: 257.972. Train acc: 0.340. Train Loss: 6648.398\n",
      "Step. time since epoch: 264.663. Train acc: 0.379. Train Loss: 6449.519\n",
      "Step. time since epoch: 271.250. Train acc: 0.312. Train Loss: 7906.356\n",
      "Step. time since epoch: 277.937. Train acc: 0.363. Train Loss: 7015.200\n",
      "Step. time since epoch: 284.599. Train acc: 0.402. Train Loss: 5468.109\n",
      "Step. time since epoch: 291.988. Train acc: 0.340. Train Loss: 6006.027\n",
      "Step. time since epoch: 298.724. Train acc: 0.359. Train Loss: 6461.816\n",
      "Step. time since epoch: 305.613. Train acc: 0.367. Train Loss: 4791.761\n",
      "Step. time since epoch: 312.250. Train acc: 0.328. Train Loss: 5534.733\n",
      "Step. time since epoch: 318.933. Train acc: 0.320. Train Loss: 5539.933\n",
      "Step. time since epoch: 325.639. Train acc: 0.441. Train Loss: 4425.264\n",
      "Step. time since epoch: 332.141. Train acc: 0.441. Train Loss: 4837.458\n",
      "Step. time since epoch: 338.650. Train acc: 0.473. Train Loss: 3348.151\n",
      "Step. time since epoch: 345.368. Train acc: 0.434. Train Loss: 3569.918\n",
      "Step. time since epoch: 352.143. Train acc: 0.457. Train Loss: 3338.189\n",
      "Step. time since epoch: 359.013. Train acc: 0.430. Train Loss: 3851.398\n",
      "Step. time since epoch: 365.819. Train acc: 0.449. Train Loss: 3119.206\n",
      "Step. time since epoch: 372.845. Train acc: 0.461. Train Loss: 2883.583\n",
      "Step. time since epoch: 379.655. Train acc: 0.469. Train Loss: 2983.079\n",
      "Step. time since epoch: 386.543. Train acc: 0.492. Train Loss: 2877.510\n",
      "Step. time since epoch: 393.253. Train acc: 0.434. Train Loss: 2713.701\n",
      "Step. time since epoch: 399.783. Train acc: 0.488. Train Loss: 2730.305\n",
      "Step. time since epoch: 407.316. Train acc: 0.426. Train Loss: 3428.368\n",
      "Step. time since epoch: 414.987. Train acc: 0.461. Train Loss: 3152.436\n",
      "Step. time since epoch: 421.877. Train acc: 0.469. Train Loss: 2893.306\n",
      "Step. time since epoch: 428.613. Train acc: 0.469. Train Loss: 2992.377\n",
      "Step. time since epoch: 435.287. Train acc: 0.539. Train Loss: 2166.140\n",
      "Step. time since epoch: 441.869. Train acc: 0.410. Train Loss: 3478.065\n",
      "Step. time since epoch: 449.107. Train acc: 0.480. Train Loss: 2342.639\n",
      "Step. time since epoch: 455.489. Train acc: 0.520. Train Loss: 2462.633\n",
      "Step. time since epoch: 463.153. Train acc: 0.383. Train Loss: 3821.336\n",
      "Step. time since epoch: 470.270. Train acc: 0.492. Train Loss: 2995.213\n",
      "Step. time since epoch: 477.115. Train acc: 0.418. Train Loss: 2662.658\n",
      "Step. time since epoch: 484.033. Train acc: 0.328. Train Loss: 4148.168\n",
      "Step. time since epoch: 490.971. Train acc: 0.441. Train Loss: 3205.480\n",
      "Step. time since epoch: 497.885. Train acc: 0.449. Train Loss: 3668.004\n",
      "Step. time since epoch: 504.772. Train acc: 0.441. Train Loss: 4764.823\n",
      "Step. time since epoch: 511.966. Train acc: 0.449. Train Loss: 3694.874\n",
      "Step. time since epoch: 518.817. Train acc: 0.492. Train Loss: 2975.018\n",
      "Step. time since epoch: 525.723. Train acc: 0.461. Train Loss: 2936.391\n",
      "Step. time since epoch: 532.704. Train acc: 0.344. Train Loss: 4679.151\n",
      "Step. time since epoch: 539.378. Train acc: 0.371. Train Loss: 3518.076\n",
      "Step. time since epoch: 545.723. Train acc: 0.441. Train Loss: 2611.745\n",
      "Step. time since epoch: 552.084. Train acc: 0.488. Train Loss: 2912.546\n",
      "Step. time since epoch: 558.592. Train acc: 0.434. Train Loss: 2945.365\n",
      "Step. time since epoch: 565.400. Train acc: 0.508. Train Loss: 2801.562\n",
      "Step. time since epoch: 572.068. Train acc: 0.473. Train Loss: 2189.828\n",
      "Step. time since epoch: 578.727. Train acc: 0.445. Train Loss: 3657.032\n",
      "Step. time since epoch: 585.418. Train acc: 0.410. Train Loss: 3982.671\n",
      "Step. time since epoch: 592.150. Train acc: 0.492. Train Loss: 2908.044\n",
      "Step. time since epoch: 598.748. Train acc: 0.422. Train Loss: 4067.525\n",
      "Step. time since epoch: 605.465. Train acc: 0.492. Train Loss: 2610.680\n",
      "Step. time since epoch: 612.162. Train acc: 0.430. Train Loss: 3487.601\n",
      "Step. time since epoch: 618.800. Train acc: 0.461. Train Loss: 2636.199\n",
      "Step. time since epoch: 626.602. Train acc: 0.375. Train Loss: 3492.720\n",
      "Step. time since epoch: 633.493. Train acc: 0.387. Train Loss: 3934.512\n",
      "Step. time since epoch: 640.433. Train acc: 0.488. Train Loss: 3681.261\n",
      "Step. time since epoch: 647.203. Train acc: 0.445. Train Loss: 4480.943\n",
      "Step. time since epoch: 654.186. Train acc: 0.426. Train Loss: 3979.725\n",
      "Step. time since epoch: 660.704. Train acc: 0.387. Train Loss: 4022.054\n",
      "Step. time since epoch: 667.420. Train acc: 0.469. Train Loss: 2435.083\n",
      "Step. time since epoch: 674.059. Train acc: 0.371. Train Loss: 4190.939\n",
      "Step. time since epoch: 680.737. Train acc: 0.469. Train Loss: 3841.331\n",
      "Step. time since epoch: 687.626. Train acc: 0.469. Train Loss: 3541.414\n",
      "Step. time since epoch: 694.525. Train acc: 0.473. Train Loss: 2965.217\n",
      "Step. time since epoch: 701.621. Train acc: 0.367. Train Loss: 3977.855\n",
      "Step. time since epoch: 709.736. Train acc: 0.383. Train Loss: 4302.475\n",
      "Step. time since epoch: 717.294. Train acc: 0.441. Train Loss: 3249.554\n",
      "Step. time since epoch: 724.182. Train acc: 0.430. Train Loss: 3934.405\n",
      "Step. time since epoch: 731.082. Train acc: 0.434. Train Loss: 4342.378\n",
      "Step. time since epoch: 737.362. Train acc: 0.426. Train Loss: 2902.216\n",
      "Step. time since epoch: 743.576. Train acc: 0.434. Train Loss: 3617.833\n",
      "Step. time since epoch: 749.662. Train acc: 0.418. Train Loss: 3441.211\n",
      "Step. time since epoch: 755.773. Train acc: 0.488. Train Loss: 2788.706\n",
      "Step. time since epoch: 761.870. Train acc: 0.352. Train Loss: 4163.737\n",
      "Step. time since epoch: 768.153. Train acc: 0.469. Train Loss: 3037.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 775.176. Train acc: 0.445. Train Loss: 3050.109\n",
      "Step. time since epoch: 781.468. Train acc: 0.355. Train Loss: 5005.519\n",
      "Step. time since epoch: 787.824. Train acc: 0.473. Train Loss: 2532.627\n",
      "Step. time since epoch: 794.036. Train acc: 0.418. Train Loss: 3306.918\n",
      "Step. time since epoch: 801.375. Train acc: 0.430. Train Loss: 3893.335\n",
      "Step. time since epoch: 809.037. Train acc: 0.379. Train Loss: 4223.780\n",
      "Step. time since epoch: 815.432. Train acc: 0.500. Train Loss: 2470.883\n",
      "Step. time since epoch: 822.022. Train acc: 0.422. Train Loss: 2696.965\n",
      "Step. time since epoch: 828.219. Train acc: 0.480. Train Loss: 2431.667\n",
      "Step. time since epoch: 834.324. Train acc: 0.414. Train Loss: 2442.026\n",
      "Step. time since epoch: 840.844. Train acc: 0.551. Train Loss: 1820.154\n",
      "Step. time since epoch: 847.262. Train acc: 0.484. Train Loss: 2486.828\n",
      "Step. time since epoch: 853.446. Train acc: 0.512. Train Loss: 2077.350\n",
      "Step. time since epoch: 860.239. Train acc: 0.445. Train Loss: 2226.680\n",
      "Step. time since epoch: 866.697. Train acc: 0.414. Train Loss: 2508.108\n",
      "Step. time since epoch: 872.857. Train acc: 0.441. Train Loss: 2221.480\n",
      "Step. time since epoch: 879.106. Train acc: 0.434. Train Loss: 2526.716\n",
      "Step. time since epoch: 885.448. Train acc: 0.422. Train Loss: 2995.983\n",
      "Step. time since epoch: 891.652. Train acc: 0.465. Train Loss: 2203.334\n",
      "Step. time since epoch: 898.246. Train acc: 0.496. Train Loss: 2644.077\n",
      "Step. time since epoch: 906.768. Train acc: 0.426. Train Loss: 3305.459\n",
      "Step. time since epoch: 913.552. Train acc: 0.383. Train Loss: 4439.406\n",
      "Step. time since epoch: 920.084. Train acc: 0.496. Train Loss: 2677.003\n",
      "Step. time since epoch: 926.417. Train acc: 0.473. Train Loss: 2331.648\n",
      "Step. time since epoch: 932.791. Train acc: 0.434. Train Loss: 2709.815\n",
      "Step. time since epoch: 939.008. Train acc: 0.461. Train Loss: 2231.721\n",
      "Step. time since epoch: 945.301. Train acc: 0.477. Train Loss: 1908.622\n",
      "Step. time since epoch: 951.545. Train acc: 0.496. Train Loss: 1842.828\n",
      "Step. time since epoch: 957.700. Train acc: 0.438. Train Loss: 2395.248\n",
      "Step. time since epoch: 964.195. Train acc: 0.531. Train Loss: 1771.919\n",
      "Step. time since epoch: 970.721. Train acc: 0.496. Train Loss: 1946.387\n",
      "Step. time since epoch: 977.192. Train acc: 0.500. Train Loss: 1562.130\n",
      "Step. time since epoch: 983.781. Train acc: 0.500. Train Loss: 1892.285\n",
      "Step. time since epoch: 990.205. Train acc: 0.535. Train Loss: 1625.528\n",
      "Step. time since epoch: 996.764. Train acc: 0.445. Train Loss: 1752.619\n",
      "Step. time since epoch: 1002.993. Train acc: 0.508. Train Loss: 1575.476\n",
      "Step. time since epoch: 1009.129. Train acc: 0.480. Train Loss: 1756.557\n",
      "Step. time since epoch: 1015.253. Train acc: 0.457. Train Loss: 2083.173\n",
      "Step. time since epoch: 1021.687. Train acc: 0.469. Train Loss: 1994.412\n",
      "Step. time since epoch: 1027.796. Train acc: 0.457. Train Loss: 2176.376\n",
      "Step. time since epoch: 1033.924. Train acc: 0.504. Train Loss: 1730.215\n",
      "Step. time since epoch: 1040.047. Train acc: 0.457. Train Loss: 1623.296\n",
      "Step. time since epoch: 1046.183. Train acc: 0.461. Train Loss: 2173.917\n",
      "Step. time since epoch: 1052.308. Train acc: 0.508. Train Loss: 1372.677\n",
      "Step. time since epoch: 1058.422. Train acc: 0.523. Train Loss: 1773.914\n",
      "Step. time since epoch: 1064.473. Train acc: 0.469. Train Loss: 2230.817\n",
      "Step. time since epoch: 1070.555. Train acc: 0.469. Train Loss: 1849.842\n",
      "Step. time since epoch: 1076.682. Train acc: 0.461. Train Loss: 1999.828\n",
      "Step. time since epoch: 1082.803. Train acc: 0.395. Train Loss: 2184.959\n",
      "Step. time since epoch: 1088.908. Train acc: 0.395. Train Loss: 2853.559\n",
      "Step. time since epoch: 1095.147. Train acc: 0.453. Train Loss: 2903.683\n",
      "Step. time since epoch: 1101.250. Train acc: 0.430. Train Loss: 2849.293\n",
      "Step. time since epoch: 1107.329. Train acc: 0.379. Train Loss: 3909.980\n",
      "Step. time since epoch: 1113.466. Train acc: 0.414. Train Loss: 2865.780\n",
      "Step. time since epoch: 1119.563. Train acc: 0.391. Train Loss: 3083.129\n",
      "Step. time since epoch: 1125.746. Train acc: 0.418. Train Loss: 2766.751\n",
      "Step. time since epoch: 1131.817. Train acc: 0.312. Train Loss: 3948.454\n",
      "Step. time since epoch: 1138.103. Train acc: 0.367. Train Loss: 2376.809\n",
      "Step. time since epoch: 1144.206. Train acc: 0.363. Train Loss: 3518.296\n",
      "Step. time since epoch: 1150.360. Train acc: 0.379. Train Loss: 3173.542\n",
      "Step. time since epoch: 1156.499. Train acc: 0.395. Train Loss: 3168.358\n",
      "Step. time since epoch: 1162.576. Train acc: 0.355. Train Loss: 3313.625\n",
      "Step. time since epoch: 1168.698. Train acc: 0.434. Train Loss: 2862.429\n",
      "Step. time since epoch: 1174.843. Train acc: 0.434. Train Loss: 2456.303\n",
      "Step. time since epoch: 1180.962. Train acc: 0.352. Train Loss: 2624.474\n",
      "Step. time since epoch: 1187.072. Train acc: 0.367. Train Loss: 3042.909\n",
      "Step. time since epoch: 1193.184. Train acc: 0.336. Train Loss: 3487.948\n",
      "Step. time since epoch: 1199.304. Train acc: 0.418. Train Loss: 4120.167\n",
      "Step. time since epoch: 1205.458. Train acc: 0.461. Train Loss: 4726.691\n",
      "Step. time since epoch: 1211.581. Train acc: 0.449. Train Loss: 4359.836\n",
      "Step. time since epoch: 1217.718. Train acc: 0.340. Train Loss: 6541.763\n",
      "Step. time since epoch: 1223.795. Train acc: 0.430. Train Loss: 4402.273\n",
      "Step. time since epoch: 1229.918. Train acc: 0.488. Train Loss: 4657.468\n",
      "Step. time since epoch: 1235.986. Train acc: 0.461. Train Loss: 3289.008\n",
      "Step. time since epoch: 1242.127. Train acc: 0.445. Train Loss: 3213.026\n",
      "Step. time since epoch: 1248.234. Train acc: 0.445. Train Loss: 3022.232\n",
      "Step. time since epoch: 1254.338. Train acc: 0.254. Train Loss: 6117.631\n",
      "Step. time since epoch: 1260.428. Train acc: 0.453. Train Loss: 2925.970\n",
      "Step. time since epoch: 1266.759. Train acc: 0.484. Train Loss: 2990.977\n",
      "Step. time since epoch: 1273.108. Train acc: 0.465. Train Loss: 3655.750\n",
      "Step. time since epoch: 1279.290. Train acc: 0.465. Train Loss: 4148.642\n",
      "Step. time since epoch: 1285.663. Train acc: 0.453. Train Loss: 3740.058\n",
      "Step. time since epoch: 1291.782. Train acc: 0.387. Train Loss: 4055.474\n",
      "Step. time since epoch: 1297.919. Train acc: 0.422. Train Loss: 3033.089\n",
      "Step. time since epoch: 1303.966. Train acc: 0.461. Train Loss: 2832.131\n",
      "Step. time since epoch: 1310.063. Train acc: 0.406. Train Loss: 3301.445\n",
      "Step. time since epoch: 1316.156. Train acc: 0.375. Train Loss: 3379.268\n",
      "Step. time since epoch: 1322.298. Train acc: 0.340. Train Loss: 3834.930\n",
      "Step. time since epoch: 1328.377. Train acc: 0.297. Train Loss: 4207.286\n",
      "Step. time since epoch: 1334.566. Train acc: 0.430. Train Loss: 4064.123\n",
      "Step. time since epoch: 1340.645. Train acc: 0.316. Train Loss: 5633.120\n",
      "Step. time since epoch: 1346.741. Train acc: 0.383. Train Loss: 4976.478\n",
      "Step. time since epoch: 1352.815. Train acc: 0.344. Train Loss: 5682.639\n",
      "Step. time since epoch: 1358.890. Train acc: 0.336. Train Loss: 4959.406\n",
      "Step. time since epoch: 1364.960. Train acc: 0.371. Train Loss: 2865.790\n",
      "Step. time since epoch: 1371.054. Train acc: 0.328. Train Loss: 4128.081\n",
      "Step. time since epoch: 1377.171. Train acc: 0.273. Train Loss: 5838.190\n",
      "Step. time since epoch: 1383.456. Train acc: 0.305. Train Loss: 6246.639\n",
      "Step. time since epoch: 1389.592. Train acc: 0.484. Train Loss: 3146.504\n",
      "Step. time since epoch: 1395.776. Train acc: 0.395. Train Loss: 3535.918\n",
      "Step. time since epoch: 1401.921. Train acc: 0.355. Train Loss: 4848.887\n",
      "Step. time since epoch: 1408.123. Train acc: 0.402. Train Loss: 3231.861\n",
      "Step. time since epoch: 1414.216. Train acc: 0.375. Train Loss: 3742.277\n",
      "Step. time since epoch: 1420.368. Train acc: 0.488. Train Loss: 3255.828\n",
      "Step. time since epoch: 1426.443. Train acc: 0.406. Train Loss: 3748.250\n",
      "Step. time since epoch: 1432.541. Train acc: 0.383. Train Loss: 3186.768\n",
      "Step. time since epoch: 1438.904. Train acc: 0.445. Train Loss: 2981.093\n",
      "Step. time since epoch: 1445.248. Train acc: 0.344. Train Loss: 4003.931\n",
      "Step. time since epoch: 1451.501. Train acc: 0.363. Train Loss: 3424.462\n",
      "Step. time since epoch: 1457.711. Train acc: 0.449. Train Loss: 2791.343\n",
      "Step. time since epoch: 1463.786. Train acc: 0.414. Train Loss: 3396.676\n",
      "Step. time since epoch: 1469.963. Train acc: 0.508. Train Loss: 1969.789\n",
      "Step. time since epoch: 1476.053. Train acc: 0.484. Train Loss: 2272.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1482.195. Train acc: 0.410. Train Loss: 3048.952\n",
      "Step. time since epoch: 1488.291. Train acc: 0.441. Train Loss: 2513.985\n",
      "Step. time since epoch: 1494.818. Train acc: 0.461. Train Loss: 2444.844\n",
      "Step. time since epoch: 1501.203. Train acc: 0.512. Train Loss: 1943.358\n",
      "Step. time since epoch: 1507.714. Train acc: 0.473. Train Loss: 2753.850\n",
      "Step. time since epoch: 1513.977. Train acc: 0.496. Train Loss: 2535.819\n",
      "Step. time since epoch: 1521.370. Train acc: 0.539. Train Loss: 1835.623\n",
      "Step. time since epoch: 1523.892. Train acc: 0.500. Train Loss: 776.300\n",
      "epoch 1, loss 21.9851, train acc 0.392, test acc 0.444, time 1758.4 sec\n",
      "Step. time since epoch: 5.938. Train acc: 0.434. Train Loss: 2762.793\n",
      "Step. time since epoch: 11.785. Train acc: 0.434. Train Loss: 2380.114\n",
      "Step. time since epoch: 17.731. Train acc: 0.570. Train Loss: 1898.023\n",
      "Step. time since epoch: 23.676. Train acc: 0.523. Train Loss: 2352.685\n",
      "Step. time since epoch: 29.738. Train acc: 0.457. Train Loss: 2729.150\n",
      "Step. time since epoch: 35.549. Train acc: 0.492. Train Loss: 1990.965\n",
      "Step. time since epoch: 41.565. Train acc: 0.430. Train Loss: 3013.916\n",
      "Step. time since epoch: 47.547. Train acc: 0.379. Train Loss: 3294.162\n",
      "Step. time since epoch: 53.520. Train acc: 0.484. Train Loss: 2978.030\n",
      "Step. time since epoch: 60.362. Train acc: 0.387. Train Loss: 3045.414\n",
      "Step. time since epoch: 67.289. Train acc: 0.395. Train Loss: 2724.431\n",
      "Step. time since epoch: 73.723. Train acc: 0.441. Train Loss: 2496.473\n",
      "Step. time since epoch: 80.184. Train acc: 0.398. Train Loss: 3207.668\n",
      "Step. time since epoch: 86.593. Train acc: 0.406. Train Loss: 3720.794\n",
      "Step. time since epoch: 92.642. Train acc: 0.480. Train Loss: 3334.226\n",
      "Step. time since epoch: 98.505. Train acc: 0.473. Train Loss: 2665.351\n",
      "Step. time since epoch: 104.432. Train acc: 0.477. Train Loss: 3264.081\n",
      "Step. time since epoch: 110.730. Train acc: 0.453. Train Loss: 3812.038\n",
      "Step. time since epoch: 116.598. Train acc: 0.441. Train Loss: 3227.417\n",
      "Step. time since epoch: 122.583. Train acc: 0.430. Train Loss: 2519.407\n",
      "Step. time since epoch: 128.904. Train acc: 0.445. Train Loss: 3342.514\n",
      "Step. time since epoch: 135.162. Train acc: 0.410. Train Loss: 3957.405\n",
      "Step. time since epoch: 141.565. Train acc: 0.484. Train Loss: 2638.820\n",
      "Step. time since epoch: 147.429. Train acc: 0.461. Train Loss: 3316.974\n",
      "Step. time since epoch: 153.549. Train acc: 0.469. Train Loss: 2869.890\n",
      "Step. time since epoch: 159.550. Train acc: 0.449. Train Loss: 3294.978\n",
      "Step. time since epoch: 165.513. Train acc: 0.480. Train Loss: 2658.582\n",
      "Step. time since epoch: 171.610. Train acc: 0.453. Train Loss: 2760.804\n",
      "Step. time since epoch: 177.705. Train acc: 0.465. Train Loss: 2869.954\n",
      "Step. time since epoch: 183.601. Train acc: 0.398. Train Loss: 3427.594\n",
      "Step. time since epoch: 189.681. Train acc: 0.445. Train Loss: 2163.634\n",
      "Step. time since epoch: 195.592. Train acc: 0.508. Train Loss: 2305.307\n",
      "Step. time since epoch: 201.497. Train acc: 0.473. Train Loss: 2230.922\n",
      "Step. time since epoch: 207.644. Train acc: 0.492. Train Loss: 2073.323\n",
      "Step. time since epoch: 213.639. Train acc: 0.430. Train Loss: 2047.991\n",
      "Step. time since epoch: 219.456. Train acc: 0.504. Train Loss: 1922.881\n",
      "Step. time since epoch: 225.417. Train acc: 0.535. Train Loss: 1736.976\n",
      "Step. time since epoch: 231.578. Train acc: 0.496. Train Loss: 1913.342\n",
      "Step. time since epoch: 237.996. Train acc: 0.535. Train Loss: 1496.774\n",
      "Step. time since epoch: 244.239. Train acc: 0.562. Train Loss: 1545.553\n",
      "Step. time since epoch: 250.473. Train acc: 0.551. Train Loss: 1556.139\n",
      "Step. time since epoch: 257.356. Train acc: 0.605. Train Loss: 1282.903\n",
      "Step. time since epoch: 264.027. Train acc: 0.516. Train Loss: 1547.770\n",
      "Step. time since epoch: 270.298. Train acc: 0.562. Train Loss: 1179.216\n",
      "Step. time since epoch: 276.851. Train acc: 0.473. Train Loss: 1782.086\n",
      "Step. time since epoch: 283.138. Train acc: 0.473. Train Loss: 1714.587\n",
      "Step. time since epoch: 289.869. Train acc: 0.531. Train Loss: 1459.990\n",
      "Step. time since epoch: 296.509. Train acc: 0.535. Train Loss: 1346.290\n",
      "Step. time since epoch: 302.820. Train acc: 0.551. Train Loss: 1399.473\n",
      "Step. time since epoch: 309.067. Train acc: 0.516. Train Loss: 1515.861\n",
      "Step. time since epoch: 315.130. Train acc: 0.512. Train Loss: 1181.514\n",
      "Step. time since epoch: 321.782. Train acc: 0.445. Train Loss: 1849.633\n",
      "Step. time since epoch: 328.828. Train acc: 0.477. Train Loss: 1524.047\n",
      "Step. time since epoch: 335.481. Train acc: 0.516. Train Loss: 1628.809\n",
      "Step. time since epoch: 341.687. Train acc: 0.547. Train Loss: 1686.246\n",
      "Step. time since epoch: 347.672. Train acc: 0.504. Train Loss: 1287.092\n",
      "Step. time since epoch: 353.528. Train acc: 0.484. Train Loss: 1538.495\n",
      "Step. time since epoch: 359.612. Train acc: 0.496. Train Loss: 1772.113\n",
      "Step. time since epoch: 365.759. Train acc: 0.508. Train Loss: 1687.985\n",
      "Step. time since epoch: 371.864. Train acc: 0.566. Train Loss: 1705.294\n",
      "Step. time since epoch: 377.973. Train acc: 0.488. Train Loss: 1498.388\n",
      "Step. time since epoch: 383.959. Train acc: 0.504. Train Loss: 1475.315\n",
      "Step. time since epoch: 390.021. Train acc: 0.473. Train Loss: 1510.849\n",
      "Step. time since epoch: 396.079. Train acc: 0.508. Train Loss: 1339.699\n",
      "Step. time since epoch: 401.993. Train acc: 0.508. Train Loss: 1558.993\n",
      "Step. time since epoch: 407.854. Train acc: 0.520. Train Loss: 1173.323\n",
      "Step. time since epoch: 413.743. Train acc: 0.523. Train Loss: 1349.739\n",
      "Step. time since epoch: 419.597. Train acc: 0.492. Train Loss: 1652.461\n",
      "Step. time since epoch: 425.399. Train acc: 0.449. Train Loss: 1690.641\n",
      "Step. time since epoch: 431.203. Train acc: 0.508. Train Loss: 1463.626\n",
      "Step. time since epoch: 437.054. Train acc: 0.438. Train Loss: 1755.324\n",
      "Step. time since epoch: 443.033. Train acc: 0.461. Train Loss: 1682.233\n",
      "Step. time since epoch: 448.958. Train acc: 0.523. Train Loss: 1524.544\n",
      "Step. time since epoch: 454.762. Train acc: 0.367. Train Loss: 2771.566\n",
      "Step. time since epoch: 460.593. Train acc: 0.508. Train Loss: 1612.456\n",
      "Step. time since epoch: 466.449. Train acc: 0.512. Train Loss: 1503.368\n",
      "Step. time since epoch: 472.226. Train acc: 0.387. Train Loss: 2514.336\n",
      "Step. time since epoch: 478.051. Train acc: 0.402. Train Loss: 2501.887\n",
      "Step. time since epoch: 483.842. Train acc: 0.426. Train Loss: 3236.455\n",
      "Step. time since epoch: 489.686. Train acc: 0.445. Train Loss: 3567.906\n",
      "Step. time since epoch: 495.579. Train acc: 0.449. Train Loss: 3514.669\n",
      "Step. time since epoch: 501.438. Train acc: 0.477. Train Loss: 1830.597\n",
      "Step. time since epoch: 507.191. Train acc: 0.383. Train Loss: 3143.199\n",
      "Step. time since epoch: 513.132. Train acc: 0.316. Train Loss: 4239.753\n",
      "Step. time since epoch: 519.085. Train acc: 0.340. Train Loss: 4511.294\n",
      "Step. time since epoch: 524.921. Train acc: 0.344. Train Loss: 3781.711\n",
      "Step. time since epoch: 530.732. Train acc: 0.426. Train Loss: 3982.139\n",
      "Step. time since epoch: 536.736. Train acc: 0.383. Train Loss: 5604.451\n",
      "Step. time since epoch: 542.736. Train acc: 0.328. Train Loss: 6527.274\n",
      "Step. time since epoch: 548.741. Train acc: 0.363. Train Loss: 6056.076\n",
      "Step. time since epoch: 554.583. Train acc: 0.301. Train Loss: 6169.403\n",
      "Step. time since epoch: 560.384. Train acc: 0.352. Train Loss: 5791.522\n",
      "Step. time since epoch: 566.216. Train acc: 0.305. Train Loss: 4735.675\n",
      "Step. time since epoch: 571.988. Train acc: 0.293. Train Loss: 5092.114\n",
      "Step. time since epoch: 578.128. Train acc: 0.270. Train Loss: 5768.576\n",
      "Step. time since epoch: 584.119. Train acc: 0.281. Train Loss: 4546.378\n",
      "Step. time since epoch: 589.909. Train acc: 0.270. Train Loss: 6197.524\n",
      "Step. time since epoch: 596.159. Train acc: 0.344. Train Loss: 6662.452\n",
      "Step. time since epoch: 602.069. Train acc: 0.328. Train Loss: 6095.782\n",
      "Step. time since epoch: 608.377. Train acc: 0.461. Train Loss: 3368.350\n",
      "Step. time since epoch: 614.610. Train acc: 0.418. Train Loss: 3166.136\n",
      "Step. time since epoch: 620.442. Train acc: 0.293. Train Loss: 4689.907\n",
      "Step. time since epoch: 626.272. Train acc: 0.375. Train Loss: 3812.235\n",
      "Step. time since epoch: 632.098. Train acc: 0.367. Train Loss: 3450.625\n",
      "Step. time since epoch: 637.967. Train acc: 0.305. Train Loss: 4439.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 644.082. Train acc: 0.367. Train Loss: 4327.037\n",
      "Step. time since epoch: 650.159. Train acc: 0.398. Train Loss: 4716.821\n",
      "Step. time since epoch: 656.281. Train acc: 0.270. Train Loss: 5772.036\n",
      "Step. time since epoch: 662.250. Train acc: 0.473. Train Loss: 1972.617\n",
      "Step. time since epoch: 668.176. Train acc: 0.434. Train Loss: 3138.255\n",
      "Step. time since epoch: 674.046. Train acc: 0.359. Train Loss: 4500.397\n",
      "Step. time since epoch: 679.938. Train acc: 0.414. Train Loss: 3068.820\n",
      "Step. time since epoch: 686.051. Train acc: 0.406. Train Loss: 2922.548\n",
      "Step. time since epoch: 692.284. Train acc: 0.441. Train Loss: 2824.642\n",
      "Step. time since epoch: 698.151. Train acc: 0.504. Train Loss: 2571.076\n",
      "Step. time since epoch: 704.075. Train acc: 0.391. Train Loss: 2785.881\n",
      "Step. time since epoch: 710.114. Train acc: 0.414. Train Loss: 2974.753\n",
      "Step. time since epoch: 716.039. Train acc: 0.398. Train Loss: 3612.542\n",
      "Step. time since epoch: 722.048. Train acc: 0.430. Train Loss: 3843.880\n",
      "Step. time since epoch: 727.997. Train acc: 0.445. Train Loss: 3653.149\n",
      "Step. time since epoch: 733.899. Train acc: 0.445. Train Loss: 2792.066\n",
      "Step. time since epoch: 739.848. Train acc: 0.434. Train Loss: 2895.720\n",
      "Step. time since epoch: 746.106. Train acc: 0.402. Train Loss: 4071.548\n",
      "Step. time since epoch: 752.135. Train acc: 0.387. Train Loss: 4238.075\n",
      "Step. time since epoch: 757.967. Train acc: 0.492. Train Loss: 3518.402\n",
      "Step. time since epoch: 764.472. Train acc: 0.434. Train Loss: 3713.112\n",
      "Step. time since epoch: 771.437. Train acc: 0.414. Train Loss: 3358.829\n",
      "Step. time since epoch: 777.475. Train acc: 0.449. Train Loss: 3555.007\n",
      "Step. time since epoch: 783.375. Train acc: 0.434. Train Loss: 4794.585\n",
      "Step. time since epoch: 789.881. Train acc: 0.453. Train Loss: 3339.026\n",
      "Step. time since epoch: 796.009. Train acc: 0.445. Train Loss: 3452.636\n",
      "Step. time since epoch: 802.526. Train acc: 0.438. Train Loss: 2787.069\n",
      "Step. time since epoch: 808.841. Train acc: 0.449. Train Loss: 3230.808\n",
      "Step. time since epoch: 814.728. Train acc: 0.457. Train Loss: 3452.484\n",
      "Step. time since epoch: 820.630. Train acc: 0.516. Train Loss: 2820.243\n",
      "Step. time since epoch: 826.487. Train acc: 0.379. Train Loss: 4385.604\n",
      "Step. time since epoch: 832.479. Train acc: 0.496. Train Loss: 2548.697\n",
      "Step. time since epoch: 838.372. Train acc: 0.469. Train Loss: 2723.323\n",
      "Step. time since epoch: 844.200. Train acc: 0.473. Train Loss: 2975.368\n",
      "Step. time since epoch: 850.042. Train acc: 0.473. Train Loss: 3010.415\n",
      "Step. time since epoch: 856.143. Train acc: 0.535. Train Loss: 2584.092\n",
      "Step. time since epoch: 862.245. Train acc: 0.469. Train Loss: 2694.277\n",
      "Step. time since epoch: 868.313. Train acc: 0.441. Train Loss: 2558.886\n",
      "Step. time since epoch: 874.201. Train acc: 0.488. Train Loss: 2138.883\n",
      "Step. time since epoch: 880.464. Train acc: 0.512. Train Loss: 2037.372\n",
      "Step. time since epoch: 886.509. Train acc: 0.574. Train Loss: 1755.616\n",
      "Step. time since epoch: 892.469. Train acc: 0.488. Train Loss: 2536.568\n",
      "Step. time since epoch: 898.565. Train acc: 0.543. Train Loss: 1762.844\n",
      "Step. time since epoch: 904.504. Train acc: 0.488. Train Loss: 1877.076\n",
      "Step. time since epoch: 910.454. Train acc: 0.516. Train Loss: 1788.576\n",
      "Step. time since epoch: 916.512. Train acc: 0.508. Train Loss: 1846.804\n",
      "Step. time since epoch: 922.543. Train acc: 0.535. Train Loss: 1797.158\n",
      "Step. time since epoch: 928.575. Train acc: 0.543. Train Loss: 1732.600\n",
      "Step. time since epoch: 934.494. Train acc: 0.527. Train Loss: 1698.389\n",
      "Step. time since epoch: 940.630. Train acc: 0.480. Train Loss: 1774.943\n",
      "Step. time since epoch: 946.750. Train acc: 0.496. Train Loss: 1864.752\n",
      "Step. time since epoch: 952.623. Train acc: 0.496. Train Loss: 1958.969\n",
      "Step. time since epoch: 958.536. Train acc: 0.520. Train Loss: 1625.492\n",
      "Step. time since epoch: 964.369. Train acc: 0.496. Train Loss: 1635.885\n",
      "Step. time since epoch: 970.396. Train acc: 0.512. Train Loss: 1719.711\n",
      "Step. time since epoch: 976.269. Train acc: 0.512. Train Loss: 1399.302\n",
      "Step. time since epoch: 982.090. Train acc: 0.480. Train Loss: 1899.701\n",
      "Step. time since epoch: 988.104. Train acc: 0.523. Train Loss: 1471.036\n",
      "Step. time since epoch: 994.054. Train acc: 0.465. Train Loss: 1733.981\n",
      "Step. time since epoch: 1000.061. Train acc: 0.488. Train Loss: 1762.462\n",
      "Step. time since epoch: 1005.997. Train acc: 0.508. Train Loss: 2096.765\n",
      "Step. time since epoch: 1012.034. Train acc: 0.512. Train Loss: 1709.072\n",
      "Step. time since epoch: 1019.044. Train acc: 0.441. Train Loss: 1878.037\n",
      "Step. time since epoch: 1025.146. Train acc: 0.434. Train Loss: 2240.034\n",
      "Step. time since epoch: 1031.104. Train acc: 0.500. Train Loss: 1836.948\n",
      "Step. time since epoch: 1036.969. Train acc: 0.543. Train Loss: 1763.216\n",
      "Step. time since epoch: 1042.802. Train acc: 0.488. Train Loss: 2372.446\n",
      "Step. time since epoch: 1048.610. Train acc: 0.508. Train Loss: 1822.940\n",
      "Step. time since epoch: 1054.397. Train acc: 0.551. Train Loss: 1350.258\n",
      "Step. time since epoch: 1060.298. Train acc: 0.465. Train Loss: 1855.914\n",
      "Step. time since epoch: 1066.173. Train acc: 0.508. Train Loss: 1232.782\n",
      "Step. time since epoch: 1072.097. Train acc: 0.488. Train Loss: 1633.339\n",
      "Step. time since epoch: 1079.389. Train acc: 0.488. Train Loss: 1730.670\n",
      "Step. time since epoch: 1087.036. Train acc: 0.508. Train Loss: 1564.034\n",
      "Step. time since epoch: 1093.904. Train acc: 0.469. Train Loss: 1849.282\n",
      "Step. time since epoch: 1101.017. Train acc: 0.508. Train Loss: 1727.176\n",
      "Step. time since epoch: 1107.347. Train acc: 0.539. Train Loss: 1407.890\n",
      "Step. time since epoch: 1114.392. Train acc: 0.496. Train Loss: 1806.587\n",
      "Step. time since epoch: 1120.442. Train acc: 0.445. Train Loss: 1846.249\n",
      "Step. time since epoch: 1126.371. Train acc: 0.457. Train Loss: 1678.105\n",
      "Step. time since epoch: 1132.885. Train acc: 0.430. Train Loss: 2042.913\n",
      "Step. time since epoch: 1139.132. Train acc: 0.453. Train Loss: 1799.564\n",
      "Step. time since epoch: 1145.007. Train acc: 0.500. Train Loss: 1643.024\n",
      "Step. time since epoch: 1150.926. Train acc: 0.500. Train Loss: 2381.862\n",
      "Step. time since epoch: 1156.862. Train acc: 0.473. Train Loss: 2542.798\n",
      "Step. time since epoch: 1162.861. Train acc: 0.500. Train Loss: 2395.795\n",
      "Step. time since epoch: 1168.874. Train acc: 0.527. Train Loss: 1590.675\n",
      "Step. time since epoch: 1175.086. Train acc: 0.477. Train Loss: 2249.059\n",
      "Step. time since epoch: 1182.357. Train acc: 0.434. Train Loss: 2082.815\n",
      "Step. time since epoch: 1188.875. Train acc: 0.492. Train Loss: 2139.570\n",
      "Step. time since epoch: 1195.123. Train acc: 0.371. Train Loss: 2451.420\n",
      "Step. time since epoch: 1201.242. Train acc: 0.414. Train Loss: 2281.821\n",
      "Step. time since epoch: 1207.318. Train acc: 0.406. Train Loss: 3068.356\n",
      "Step. time since epoch: 1213.345. Train acc: 0.465. Train Loss: 3181.540\n",
      "Step. time since epoch: 1219.706. Train acc: 0.457. Train Loss: 2817.298\n",
      "Step. time since epoch: 1225.968. Train acc: 0.430. Train Loss: 2543.550\n",
      "Step. time since epoch: 1232.172. Train acc: 0.371. Train Loss: 3358.048\n",
      "Step. time since epoch: 1238.011. Train acc: 0.473. Train Loss: 2014.097\n",
      "Step. time since epoch: 1244.346. Train acc: 0.562. Train Loss: 1385.573\n",
      "Step. time since epoch: 1250.790. Train acc: 0.410. Train Loss: 2756.879\n",
      "Step. time since epoch: 1256.782. Train acc: 0.453. Train Loss: 2142.947\n",
      "Step. time since epoch: 1262.633. Train acc: 0.402. Train Loss: 3034.144\n",
      "Step. time since epoch: 1268.434. Train acc: 0.438. Train Loss: 2403.772\n",
      "Step. time since epoch: 1274.213. Train acc: 0.480. Train Loss: 2042.342\n",
      "Step. time since epoch: 1280.047. Train acc: 0.469. Train Loss: 2575.943\n",
      "Step. time since epoch: 1285.978. Train acc: 0.438. Train Loss: 2836.033\n",
      "Step. time since epoch: 1292.335. Train acc: 0.422. Train Loss: 2572.818\n",
      "Step. time since epoch: 1298.438. Train acc: 0.418. Train Loss: 3043.351\n",
      "Step. time since epoch: 1304.438. Train acc: 0.406. Train Loss: 2617.322\n",
      "Step. time since epoch: 1311.066. Train acc: 0.363. Train Loss: 3841.140\n",
      "Step. time since epoch: 1317.504. Train acc: 0.523. Train Loss: 2219.019\n",
      "Step. time since epoch: 1323.780. Train acc: 0.457. Train Loss: 2359.106\n",
      "Step. time since epoch: 1329.941. Train acc: 0.504. Train Loss: 2712.859\n",
      "Step. time since epoch: 1335.953. Train acc: 0.461. Train Loss: 2926.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1341.929. Train acc: 0.461. Train Loss: 2387.788\n",
      "Step. time since epoch: 1347.842. Train acc: 0.512. Train Loss: 1876.997\n",
      "Step. time since epoch: 1354.313. Train acc: 0.324. Train Loss: 3406.241\n",
      "Step. time since epoch: 1360.518. Train acc: 0.344. Train Loss: 3165.062\n",
      "Step. time since epoch: 1368.858. Train acc: 0.453. Train Loss: 2647.981\n",
      "Step. time since epoch: 1376.504. Train acc: 0.469. Train Loss: 3239.065\n",
      "Step. time since epoch: 1383.046. Train acc: 0.480. Train Loss: 3276.784\n",
      "Step. time since epoch: 1389.793. Train acc: 0.398. Train Loss: 3557.365\n",
      "Step. time since epoch: 1396.710. Train acc: 0.395. Train Loss: 3947.198\n",
      "Step. time since epoch: 1402.920. Train acc: 0.469. Train Loss: 3079.471\n",
      "Step. time since epoch: 1409.961. Train acc: 0.453. Train Loss: 2302.781\n",
      "Step. time since epoch: 1416.007. Train acc: 0.414. Train Loss: 2585.806\n",
      "Step. time since epoch: 1422.893. Train acc: 0.426. Train Loss: 2700.594\n",
      "Step. time since epoch: 1429.700. Train acc: 0.473. Train Loss: 2578.911\n",
      "Step. time since epoch: 1436.980. Train acc: 0.410. Train Loss: 3116.224\n",
      "Step. time since epoch: 1439.723. Train acc: 0.448. Train Loss: 760.626\n",
      "epoch 2, loss 10.4214, train acc 0.455, test acc 0.475, time 1678.2 sec\n",
      "Step. time since epoch: 5.938. Train acc: 0.441. Train Loss: 2067.179\n",
      "Step. time since epoch: 11.778. Train acc: 0.426. Train Loss: 2462.609\n",
      "Step. time since epoch: 17.587. Train acc: 0.398. Train Loss: 2720.693\n",
      "Step. time since epoch: 23.541. Train acc: 0.492. Train Loss: 1634.207\n",
      "Step. time since epoch: 29.421. Train acc: 0.465. Train Loss: 2359.180\n",
      "Step. time since epoch: 35.378. Train acc: 0.430. Train Loss: 2148.321\n",
      "Step. time since epoch: 41.416. Train acc: 0.449. Train Loss: 2110.971\n",
      "Step. time since epoch: 47.571. Train acc: 0.375. Train Loss: 2496.923\n",
      "Step. time since epoch: 53.478. Train acc: 0.480. Train Loss: 1762.190\n",
      "Step. time since epoch: 59.425. Train acc: 0.508. Train Loss: 2308.920\n",
      "Step. time since epoch: 65.598. Train acc: 0.453. Train Loss: 2385.427\n",
      "Step. time since epoch: 72.505. Train acc: 0.445. Train Loss: 1967.857\n",
      "Step. time since epoch: 78.737. Train acc: 0.484. Train Loss: 1895.771\n",
      "Step. time since epoch: 84.951. Train acc: 0.473. Train Loss: 2322.812\n",
      "Step. time since epoch: 91.314. Train acc: 0.477. Train Loss: 2273.780\n",
      "Step. time since epoch: 97.331. Train acc: 0.488. Train Loss: 1613.649\n",
      "Step. time since epoch: 103.385. Train acc: 0.453. Train Loss: 2098.726\n",
      "Step. time since epoch: 109.596. Train acc: 0.492. Train Loss: 1928.602\n",
      "Step. time since epoch: 116.764. Train acc: 0.480. Train Loss: 2131.363\n",
      "Step. time since epoch: 124.009. Train acc: 0.488. Train Loss: 1968.269\n",
      "Step. time since epoch: 131.150. Train acc: 0.426. Train Loss: 1997.431\n",
      "Step. time since epoch: 138.311. Train acc: 0.465. Train Loss: 2593.066\n",
      "Step. time since epoch: 145.638. Train acc: 0.434. Train Loss: 2119.207\n",
      "Step. time since epoch: 152.647. Train acc: 0.465. Train Loss: 2080.567\n",
      "Step. time since epoch: 159.306. Train acc: 0.453. Train Loss: 2292.348\n",
      "Step. time since epoch: 166.373. Train acc: 0.484. Train Loss: 1732.347\n",
      "Step. time since epoch: 173.630. Train acc: 0.426. Train Loss: 2245.387\n",
      "Step. time since epoch: 180.025. Train acc: 0.480. Train Loss: 2152.621\n",
      "Step. time since epoch: 185.877. Train acc: 0.441. Train Loss: 2117.862\n",
      "Step. time since epoch: 191.705. Train acc: 0.445. Train Loss: 2305.986\n",
      "Step. time since epoch: 197.614. Train acc: 0.398. Train Loss: 2288.877\n",
      "Step. time since epoch: 203.412. Train acc: 0.445. Train Loss: 1883.065\n",
      "Step. time since epoch: 209.313. Train acc: 0.457. Train Loss: 2516.025\n",
      "Step. time since epoch: 215.196. Train acc: 0.480. Train Loss: 1404.827\n",
      "Step. time since epoch: 221.092. Train acc: 0.453. Train Loss: 2039.351\n",
      "Step. time since epoch: 227.122. Train acc: 0.430. Train Loss: 1525.361\n",
      "Step. time since epoch: 232.970. Train acc: 0.496. Train Loss: 1749.033\n",
      "Step. time since epoch: 238.820. Train acc: 0.438. Train Loss: 2122.108\n",
      "Step. time since epoch: 244.855. Train acc: 0.477. Train Loss: 1865.446\n",
      "Step. time since epoch: 251.374. Train acc: 0.484. Train Loss: 1494.061\n",
      "Step. time since epoch: 257.398. Train acc: 0.465. Train Loss: 2208.245\n",
      "Step. time since epoch: 264.057. Train acc: 0.500. Train Loss: 1565.979\n",
      "Step. time since epoch: 271.419. Train acc: 0.453. Train Loss: 1591.322\n",
      "Step. time since epoch: 277.392. Train acc: 0.469. Train Loss: 1626.022\n",
      "Step. time since epoch: 283.495. Train acc: 0.422. Train Loss: 2138.528\n",
      "Step. time since epoch: 290.110. Train acc: 0.473. Train Loss: 1803.826\n",
      "Step. time since epoch: 296.163. Train acc: 0.434. Train Loss: 2214.467\n",
      "Step. time since epoch: 302.087. Train acc: 0.512. Train Loss: 1558.597\n",
      "Step. time since epoch: 308.430. Train acc: 0.453. Train Loss: 2042.582\n",
      "Step. time since epoch: 314.365. Train acc: 0.484. Train Loss: 1404.200\n",
      "Step. time since epoch: 320.462. Train acc: 0.523. Train Loss: 1416.943\n",
      "Step. time since epoch: 326.613. Train acc: 0.496. Train Loss: 1673.197\n",
      "Step. time since epoch: 332.531. Train acc: 0.391. Train Loss: 2190.433\n",
      "Step. time since epoch: 339.193. Train acc: 0.531. Train Loss: 1262.788\n",
      "Step. time since epoch: 346.654. Train acc: 0.457. Train Loss: 1743.891\n",
      "Step. time since epoch: 353.469. Train acc: 0.492. Train Loss: 1665.279\n",
      "Step. time since epoch: 359.654. Train acc: 0.465. Train Loss: 2048.197\n",
      "Step. time since epoch: 365.694. Train acc: 0.477. Train Loss: 2051.912\n",
      "Step. time since epoch: 371.728. Train acc: 0.434. Train Loss: 2521.269\n",
      "Step. time since epoch: 377.769. Train acc: 0.426. Train Loss: 2358.385\n",
      "Step. time since epoch: 384.260. Train acc: 0.410. Train Loss: 2781.292\n",
      "Step. time since epoch: 390.717. Train acc: 0.371. Train Loss: 3104.508\n",
      "Step. time since epoch: 396.641. Train acc: 0.422. Train Loss: 4158.938\n",
      "Step. time since epoch: 403.324. Train acc: 0.406. Train Loss: 4084.327\n",
      "Step. time since epoch: 409.791. Train acc: 0.473. Train Loss: 2663.538\n",
      "Step. time since epoch: 416.124. Train acc: 0.387. Train Loss: 3714.028\n",
      "Step. time since epoch: 422.236. Train acc: 0.457. Train Loss: 2730.146\n",
      "Step. time since epoch: 428.193. Train acc: 0.535. Train Loss: 1582.802\n",
      "Step. time since epoch: 434.143. Train acc: 0.418. Train Loss: 2943.738\n",
      "Step. time since epoch: 440.068. Train acc: 0.422. Train Loss: 2810.888\n",
      "Step. time since epoch: 446.108. Train acc: 0.445. Train Loss: 2372.028\n",
      "Step. time since epoch: 452.104. Train acc: 0.387. Train Loss: 3057.750\n",
      "Step. time since epoch: 457.925. Train acc: 0.363. Train Loss: 3630.201\n",
      "Step. time since epoch: 463.867. Train acc: 0.465. Train Loss: 2664.302\n",
      "Step. time since epoch: 469.993. Train acc: 0.422. Train Loss: 4305.018\n",
      "Step. time since epoch: 475.924. Train acc: 0.426. Train Loss: 4273.583\n",
      "Step. time since epoch: 481.774. Train acc: 0.379. Train Loss: 3532.471\n",
      "Step. time since epoch: 487.625. Train acc: 0.492. Train Loss: 1935.088\n",
      "Step. time since epoch: 493.468. Train acc: 0.355. Train Loss: 3303.721\n",
      "Step. time since epoch: 499.427. Train acc: 0.332. Train Loss: 3867.725\n",
      "Step. time since epoch: 505.319. Train acc: 0.387. Train Loss: 2635.071\n",
      "Step. time since epoch: 511.188. Train acc: 0.414. Train Loss: 3383.318\n",
      "Step. time since epoch: 517.081. Train acc: 0.445. Train Loss: 3358.491\n",
      "Step. time since epoch: 523.790. Train acc: 0.414. Train Loss: 4166.354\n",
      "Step. time since epoch: 530.003. Train acc: 0.426. Train Loss: 3263.853\n",
      "Step. time since epoch: 536.033. Train acc: 0.520. Train Loss: 2099.262\n",
      "Step. time since epoch: 542.138. Train acc: 0.430. Train Loss: 2953.733\n",
      "Step. time since epoch: 548.218. Train acc: 0.410. Train Loss: 3884.602\n",
      "Step. time since epoch: 554.138. Train acc: 0.488. Train Loss: 2764.024\n",
      "Step. time since epoch: 560.205. Train acc: 0.512. Train Loss: 1693.281\n",
      "Step. time since epoch: 566.200. Train acc: 0.410. Train Loss: 3466.824\n",
      "Step. time since epoch: 572.147. Train acc: 0.410. Train Loss: 3498.748\n",
      "Step. time since epoch: 578.160. Train acc: 0.441. Train Loss: 2369.519\n",
      "Step. time since epoch: 584.247. Train acc: 0.410. Train Loss: 3195.819\n",
      "Step. time since epoch: 590.260. Train acc: 0.480. Train Loss: 3121.606\n",
      "Step. time since epoch: 596.094. Train acc: 0.402. Train Loss: 3167.215\n",
      "Step. time since epoch: 602.246. Train acc: 0.340. Train Loss: 5107.908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 608.234. Train acc: 0.512. Train Loss: 3568.695\n",
      "Step. time since epoch: 614.179. Train acc: 0.449. Train Loss: 2933.688\n",
      "Step. time since epoch: 620.027. Train acc: 0.430. Train Loss: 5393.001\n",
      "Step. time since epoch: 626.071. Train acc: 0.434. Train Loss: 4220.686\n",
      "Step. time since epoch: 631.924. Train acc: 0.457. Train Loss: 3976.847\n",
      "Step. time since epoch: 637.744. Train acc: 0.410. Train Loss: 5167.577\n",
      "Step. time since epoch: 643.553. Train acc: 0.496. Train Loss: 3304.234\n",
      "Step. time since epoch: 649.474. Train acc: 0.504. Train Loss: 2150.808\n",
      "Step. time since epoch: 655.375. Train acc: 0.273. Train Loss: 4784.849\n",
      "Step. time since epoch: 661.306. Train acc: 0.402. Train Loss: 2388.026\n",
      "Step. time since epoch: 667.179. Train acc: 0.438. Train Loss: 2862.051\n",
      "Step. time since epoch: 673.410. Train acc: 0.480. Train Loss: 3065.895\n",
      "Step. time since epoch: 679.765. Train acc: 0.406. Train Loss: 3563.918\n",
      "Step. time since epoch: 687.033. Train acc: 0.492. Train Loss: 2385.662\n",
      "Step. time since epoch: 693.163. Train acc: 0.457. Train Loss: 2295.874\n",
      "Step. time since epoch: 699.323. Train acc: 0.492. Train Loss: 2742.357\n",
      "Step. time since epoch: 705.645. Train acc: 0.465. Train Loss: 1763.066\n",
      "Step. time since epoch: 711.807. Train acc: 0.508. Train Loss: 1902.001\n",
      "Step. time since epoch: 717.724. Train acc: 0.391. Train Loss: 3261.623\n",
      "Step. time since epoch: 723.700. Train acc: 0.430. Train Loss: 2325.295\n",
      "Step. time since epoch: 730.138. Train acc: 0.480. Train Loss: 1685.148\n",
      "Step. time since epoch: 736.485. Train acc: 0.543. Train Loss: 1670.344\n",
      "Step. time since epoch: 742.490. Train acc: 0.402. Train Loss: 2401.400\n",
      "Step. time since epoch: 748.331. Train acc: 0.500. Train Loss: 2040.808\n",
      "Step. time since epoch: 754.260. Train acc: 0.527. Train Loss: 1804.732\n",
      "Step. time since epoch: 760.147. Train acc: 0.398. Train Loss: 2248.956\n",
      "Step. time since epoch: 766.024. Train acc: 0.523. Train Loss: 1718.561\n",
      "Step. time since epoch: 771.918. Train acc: 0.484. Train Loss: 1754.294\n",
      "Step. time since epoch: 777.751. Train acc: 0.492. Train Loss: 2194.576\n",
      "Step. time since epoch: 783.584. Train acc: 0.551. Train Loss: 1606.294\n",
      "Step. time since epoch: 789.443. Train acc: 0.496. Train Loss: 1712.801\n",
      "Step. time since epoch: 795.364. Train acc: 0.543. Train Loss: 1482.364\n",
      "Step. time since epoch: 801.280. Train acc: 0.582. Train Loss: 1331.422\n",
      "Step. time since epoch: 807.122. Train acc: 0.516. Train Loss: 1385.812\n",
      "Step. time since epoch: 813.023. Train acc: 0.523. Train Loss: 1547.356\n",
      "Step. time since epoch: 818.888. Train acc: 0.516. Train Loss: 1311.859\n",
      "Step. time since epoch: 824.808. Train acc: 0.438. Train Loss: 1855.404\n",
      "Step. time since epoch: 830.991. Train acc: 0.566. Train Loss: 1199.201\n",
      "Step. time since epoch: 836.794. Train acc: 0.484. Train Loss: 1497.546\n",
      "Step. time since epoch: 842.569. Train acc: 0.539. Train Loss: 1362.345\n",
      "Step. time since epoch: 848.836. Train acc: 0.523. Train Loss: 1416.952\n",
      "Step. time since epoch: 854.746. Train acc: 0.500. Train Loss: 1707.229\n",
      "Step. time since epoch: 860.814. Train acc: 0.477. Train Loss: 1501.400\n",
      "Step. time since epoch: 866.661. Train acc: 0.410. Train Loss: 1583.938\n",
      "Step. time since epoch: 872.529. Train acc: 0.395. Train Loss: 2263.738\n",
      "Step. time since epoch: 878.469. Train acc: 0.410. Train Loss: 2490.597\n",
      "Step. time since epoch: 884.641. Train acc: 0.402. Train Loss: 2359.604\n",
      "Step. time since epoch: 890.871. Train acc: 0.484. Train Loss: 2283.127\n",
      "Step. time since epoch: 896.949. Train acc: 0.484. Train Loss: 2343.477\n",
      "Step. time since epoch: 903.330. Train acc: 0.387. Train Loss: 2974.479\n",
      "Step. time since epoch: 909.608. Train acc: 0.527. Train Loss: 2237.530\n",
      "Step. time since epoch: 915.620. Train acc: 0.391. Train Loss: 2902.156\n",
      "Step. time since epoch: 921.405. Train acc: 0.398. Train Loss: 3821.266\n",
      "Step. time since epoch: 927.355. Train acc: 0.484. Train Loss: 2790.220\n",
      "Step. time since epoch: 933.152. Train acc: 0.465. Train Loss: 2426.004\n",
      "Step. time since epoch: 938.911. Train acc: 0.488. Train Loss: 1839.255\n",
      "Step. time since epoch: 946.314. Train acc: 0.438. Train Loss: 2409.185\n",
      "Step. time since epoch: 952.636. Train acc: 0.492. Train Loss: 2103.327\n",
      "Step. time since epoch: 959.866. Train acc: 0.434. Train Loss: 2426.104\n",
      "Step. time since epoch: 966.363. Train acc: 0.379. Train Loss: 2825.184\n",
      "Step. time since epoch: 973.390. Train acc: 0.496. Train Loss: 1697.207\n",
      "Step. time since epoch: 980.050. Train acc: 0.438. Train Loss: 2321.726\n",
      "Step. time since epoch: 986.023. Train acc: 0.465. Train Loss: 2139.370\n",
      "Step. time since epoch: 992.133. Train acc: 0.523. Train Loss: 2104.099\n",
      "Step. time since epoch: 998.120. Train acc: 0.477. Train Loss: 2488.546\n",
      "Step. time since epoch: 1004.336. Train acc: 0.508. Train Loss: 1756.281\n",
      "Step. time since epoch: 1010.356. Train acc: 0.457. Train Loss: 2290.885\n",
      "Step. time since epoch: 1016.421. Train acc: 0.355. Train Loss: 2831.651\n",
      "Step. time since epoch: 1022.295. Train acc: 0.457. Train Loss: 2057.202\n",
      "Step. time since epoch: 1028.495. Train acc: 0.531. Train Loss: 2298.803\n",
      "Step. time since epoch: 1035.082. Train acc: 0.438. Train Loss: 3197.573\n",
      "Step. time since epoch: 1041.895. Train acc: 0.438. Train Loss: 2164.751\n",
      "Step. time since epoch: 1048.684. Train acc: 0.555. Train Loss: 1486.019\n",
      "Step. time since epoch: 1055.134. Train acc: 0.398. Train Loss: 2734.381\n",
      "Step. time since epoch: 1061.597. Train acc: 0.426. Train Loss: 1995.769\n",
      "Step. time since epoch: 1067.650. Train acc: 0.488. Train Loss: 2074.422\n",
      "Step. time since epoch: 1073.501. Train acc: 0.430. Train Loss: 2727.790\n",
      "Step. time since epoch: 1079.364. Train acc: 0.477. Train Loss: 1716.034\n",
      "Step. time since epoch: 1085.241. Train acc: 0.438. Train Loss: 2254.369\n",
      "Step. time since epoch: 1091.078. Train acc: 0.379. Train Loss: 3153.233\n",
      "Step. time since epoch: 1096.959. Train acc: 0.434. Train Loss: 2690.655\n",
      "Step. time since epoch: 1102.787. Train acc: 0.469. Train Loss: 2207.399\n",
      "Step. time since epoch: 1108.654. Train acc: 0.465. Train Loss: 2356.269\n",
      "Step. time since epoch: 1114.468. Train acc: 0.359. Train Loss: 3166.524\n",
      "Step. time since epoch: 1120.311. Train acc: 0.547. Train Loss: 1423.168\n",
      "Step. time since epoch: 1126.245. Train acc: 0.441. Train Loss: 2604.325\n",
      "Step. time since epoch: 1132.026. Train acc: 0.465. Train Loss: 2017.097\n",
      "Step. time since epoch: 1137.953. Train acc: 0.363. Train Loss: 2649.136\n",
      "Step. time since epoch: 1143.805. Train acc: 0.516. Train Loss: 1373.587\n",
      "Step. time since epoch: 1149.696. Train acc: 0.555. Train Loss: 1604.166\n",
      "Step. time since epoch: 1155.696. Train acc: 0.363. Train Loss: 2798.162\n",
      "Step. time since epoch: 1161.512. Train acc: 0.480. Train Loss: 1354.722\n",
      "Step. time since epoch: 1167.343. Train acc: 0.527. Train Loss: 1606.547\n",
      "Step. time since epoch: 1173.146. Train acc: 0.508. Train Loss: 2067.441\n",
      "Step. time since epoch: 1178.954. Train acc: 0.496. Train Loss: 1638.051\n",
      "Step. time since epoch: 1185.349. Train acc: 0.516. Train Loss: 1596.032\n",
      "Step. time since epoch: 1191.902. Train acc: 0.430. Train Loss: 2128.062\n",
      "Step. time since epoch: 1198.189. Train acc: 0.504. Train Loss: 1653.837\n",
      "Step. time since epoch: 1204.988. Train acc: 0.484. Train Loss: 1851.867\n",
      "Step. time since epoch: 1212.186. Train acc: 0.492. Train Loss: 1619.466\n",
      "Step. time since epoch: 1219.171. Train acc: 0.504. Train Loss: 1671.444\n",
      "Step. time since epoch: 1225.387. Train acc: 0.535. Train Loss: 1371.273\n",
      "Step. time since epoch: 1231.502. Train acc: 0.438. Train Loss: 2075.024\n",
      "Step. time since epoch: 1237.719. Train acc: 0.453. Train Loss: 2091.683\n",
      "Step. time since epoch: 1243.817. Train acc: 0.379. Train Loss: 2047.158\n",
      "Step. time since epoch: 1249.958. Train acc: 0.453. Train Loss: 2321.691\n",
      "Step. time since epoch: 1256.122. Train acc: 0.551. Train Loss: 1341.670\n",
      "Step. time since epoch: 1262.262. Train acc: 0.504. Train Loss: 1779.714\n",
      "Step. time since epoch: 1268.310. Train acc: 0.457. Train Loss: 2137.967\n",
      "Step. time since epoch: 1274.627. Train acc: 0.449. Train Loss: 2447.450\n",
      "Step. time since epoch: 1280.746. Train acc: 0.484. Train Loss: 1638.978\n",
      "Step. time since epoch: 1286.871. Train acc: 0.523. Train Loss: 2230.321\n",
      "Step. time since epoch: 1292.914. Train acc: 0.488. Train Loss: 2173.042\n",
      "Step. time since epoch: 1298.995. Train acc: 0.484. Train Loss: 2051.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1305.154. Train acc: 0.457. Train Loss: 1878.849\n",
      "Step. time since epoch: 1311.364. Train acc: 0.402. Train Loss: 2940.233\n",
      "Step. time since epoch: 1317.453. Train acc: 0.422. Train Loss: 3047.328\n",
      "Step. time since epoch: 1323.559. Train acc: 0.336. Train Loss: 4051.518\n",
      "Step. time since epoch: 1329.713. Train acc: 0.496. Train Loss: 2327.396\n",
      "Step. time since epoch: 1336.281. Train acc: 0.371. Train Loss: 4357.391\n",
      "Step. time since epoch: 1342.429. Train acc: 0.371. Train Loss: 3665.862\n",
      "Step. time since epoch: 1348.479. Train acc: 0.516. Train Loss: 2293.581\n",
      "Step. time since epoch: 1354.521. Train acc: 0.457. Train Loss: 3009.564\n",
      "Step. time since epoch: 1360.612. Train acc: 0.484. Train Loss: 2005.912\n",
      "Step. time since epoch: 1366.649. Train acc: 0.383. Train Loss: 2827.587\n",
      "Step. time since epoch: 1372.716. Train acc: 0.375. Train Loss: 2585.522\n",
      "Step. time since epoch: 1378.779. Train acc: 0.422. Train Loss: 2325.811\n",
      "Step. time since epoch: 1384.846. Train acc: 0.359. Train Loss: 3143.982\n",
      "Step. time since epoch: 1391.606. Train acc: 0.414. Train Loss: 3289.238\n",
      "Step. time since epoch: 1397.800. Train acc: 0.477. Train Loss: 3264.221\n",
      "Step. time since epoch: 1403.875. Train acc: 0.352. Train Loss: 4385.804\n",
      "Step. time since epoch: 1409.964. Train acc: 0.449. Train Loss: 2683.048\n",
      "Step. time since epoch: 1416.015. Train acc: 0.445. Train Loss: 2123.658\n",
      "Step. time since epoch: 1422.340. Train acc: 0.418. Train Loss: 2426.633\n",
      "Step. time since epoch: 1428.451. Train acc: 0.379. Train Loss: 2624.677\n",
      "Step. time since epoch: 1434.523. Train acc: 0.457. Train Loss: 2154.911\n",
      "Step. time since epoch: 1440.978. Train acc: 0.461. Train Loss: 2933.854\n",
      "Step. time since epoch: 1443.364. Train acc: 0.427. Train Loss: 1078.448\n",
      "epoch 3, loss 9.3864, train acc 0.454, test acc 0.452, time 1682.0 sec\n",
      "Step. time since epoch: 6.104. Train acc: 0.469. Train Loss: 2620.184\n",
      "Step. time since epoch: 12.154. Train acc: 0.457. Train Loss: 2569.236\n",
      "Step. time since epoch: 18.207. Train acc: 0.457. Train Loss: 1951.103\n",
      "Step. time since epoch: 24.490. Train acc: 0.469. Train Loss: 2650.651\n",
      "Step. time since epoch: 30.489. Train acc: 0.449. Train Loss: 2306.962\n",
      "Step. time since epoch: 36.636. Train acc: 0.473. Train Loss: 2105.080\n",
      "Step. time since epoch: 42.722. Train acc: 0.492. Train Loss: 1953.972\n",
      "Step. time since epoch: 48.824. Train acc: 0.410. Train Loss: 2454.032\n",
      "Step. time since epoch: 54.907. Train acc: 0.457. Train Loss: 2706.182\n",
      "Step. time since epoch: 61.028. Train acc: 0.461. Train Loss: 3003.003\n",
      "Step. time since epoch: 67.115. Train acc: 0.469. Train Loss: 2529.053\n",
      "Step. time since epoch: 73.301. Train acc: 0.434. Train Loss: 3147.863\n",
      "Step. time since epoch: 79.243. Train acc: 0.434. Train Loss: 2744.482\n",
      "Step. time since epoch: 85.342. Train acc: 0.477. Train Loss: 1637.572\n",
      "Step. time since epoch: 91.412. Train acc: 0.426. Train Loss: 2769.476\n",
      "Step. time since epoch: 97.444. Train acc: 0.473. Train Loss: 2608.596\n",
      "Step. time since epoch: 103.528. Train acc: 0.488. Train Loss: 1909.671\n",
      "Step. time since epoch: 109.626. Train acc: 0.398. Train Loss: 2373.865\n",
      "Step. time since epoch: 115.670. Train acc: 0.512. Train Loss: 1562.754\n",
      "Step. time since epoch: 121.785. Train acc: 0.469. Train Loss: 2137.286\n",
      "Step. time since epoch: 127.836. Train acc: 0.449. Train Loss: 2676.774\n",
      "Step. time since epoch: 133.893. Train acc: 0.434. Train Loss: 3029.315\n",
      "Step. time since epoch: 139.924. Train acc: 0.516. Train Loss: 2434.812\n",
      "Step. time since epoch: 146.061. Train acc: 0.484. Train Loss: 1635.237\n",
      "Step. time since epoch: 152.044. Train acc: 0.430. Train Loss: 1898.621\n",
      "Step. time since epoch: 158.139. Train acc: 0.379. Train Loss: 2753.308\n",
      "Step. time since epoch: 164.193. Train acc: 0.469. Train Loss: 2065.595\n",
      "Step. time since epoch: 170.263. Train acc: 0.426. Train Loss: 2483.656\n",
      "Step. time since epoch: 176.333. Train acc: 0.477. Train Loss: 2211.219\n",
      "Step. time since epoch: 182.453. Train acc: 0.453. Train Loss: 2961.724\n",
      "Step. time since epoch: 188.548. Train acc: 0.441. Train Loss: 3030.726\n",
      "Step. time since epoch: 194.588. Train acc: 0.496. Train Loss: 1900.714\n",
      "Step. time since epoch: 200.624. Train acc: 0.422. Train Loss: 2087.626\n",
      "Step. time since epoch: 206.712. Train acc: 0.336. Train Loss: 3293.323\n",
      "Step. time since epoch: 212.756. Train acc: 0.441. Train Loss: 2606.103\n",
      "Step. time since epoch: 218.938. Train acc: 0.426. Train Loss: 2771.328\n",
      "Step. time since epoch: 225.173. Train acc: 0.484. Train Loss: 2453.392\n",
      "Step. time since epoch: 231.515. Train acc: 0.496. Train Loss: 2019.455\n",
      "Step. time since epoch: 237.557. Train acc: 0.488. Train Loss: 1760.661\n",
      "Step. time since epoch: 243.673. Train acc: 0.473. Train Loss: 2052.335\n",
      "Step. time since epoch: 250.061. Train acc: 0.547. Train Loss: 2038.706\n",
      "Step. time since epoch: 256.297. Train acc: 0.543. Train Loss: 1819.750\n",
      "Step. time since epoch: 262.334. Train acc: 0.516. Train Loss: 1638.514\n",
      "Step. time since epoch: 268.385. Train acc: 0.449. Train Loss: 2137.555\n",
      "Step. time since epoch: 274.385. Train acc: 0.367. Train Loss: 2650.887\n",
      "Step. time since epoch: 280.427. Train acc: 0.477. Train Loss: 2492.332\n",
      "Step. time since epoch: 286.519. Train acc: 0.395. Train Loss: 3395.300\n",
      "Step. time since epoch: 292.614. Train acc: 0.422. Train Loss: 2872.272\n",
      "Step. time since epoch: 298.755. Train acc: 0.414. Train Loss: 2434.464\n",
      "Step. time since epoch: 304.788. Train acc: 0.391. Train Loss: 3490.865\n",
      "Step. time since epoch: 310.862. Train acc: 0.383. Train Loss: 3185.647\n",
      "Step. time since epoch: 316.922. Train acc: 0.375. Train Loss: 3824.188\n",
      "Step. time since epoch: 323.013. Train acc: 0.367. Train Loss: 4219.586\n",
      "Step. time since epoch: 329.058. Train acc: 0.441. Train Loss: 3247.962\n",
      "Step. time since epoch: 335.186. Train acc: 0.355. Train Loss: 4422.529\n",
      "Step. time since epoch: 341.316. Train acc: 0.398. Train Loss: 4089.490\n",
      "Step. time since epoch: 347.402. Train acc: 0.395. Train Loss: 4456.054\n",
      "Step. time since epoch: 353.445. Train acc: 0.402. Train Loss: 3681.391\n",
      "Step. time since epoch: 359.494. Train acc: 0.371. Train Loss: 4733.872\n",
      "Step. time since epoch: 365.602. Train acc: 0.320. Train Loss: 6093.380\n",
      "Step. time since epoch: 371.678. Train acc: 0.445. Train Loss: 3509.701\n",
      "Step. time since epoch: 377.744. Train acc: 0.469. Train Loss: 3031.445\n",
      "Step. time since epoch: 384.145. Train acc: 0.418. Train Loss: 3728.867\n",
      "Step. time since epoch: 390.410. Train acc: 0.398. Train Loss: 4106.970\n",
      "Step. time since epoch: 396.851. Train acc: 0.379. Train Loss: 3956.650\n",
      "Step. time since epoch: 403.405. Train acc: 0.465. Train Loss: 2206.510\n",
      "Step. time since epoch: 409.832. Train acc: 0.441. Train Loss: 2394.917\n",
      "Step. time since epoch: 416.442. Train acc: 0.473. Train Loss: 2952.724\n",
      "Step. time since epoch: 423.000. Train acc: 0.438. Train Loss: 3797.057\n",
      "Step. time since epoch: 429.615. Train acc: 0.449. Train Loss: 2986.561\n",
      "Step. time since epoch: 435.898. Train acc: 0.488. Train Loss: 1881.004\n",
      "Step. time since epoch: 442.349. Train acc: 0.473. Train Loss: 2640.214\n",
      "Step. time since epoch: 448.783. Train acc: 0.496. Train Loss: 2354.610\n",
      "Step. time since epoch: 454.918. Train acc: 0.469. Train Loss: 1970.772\n",
      "Step. time since epoch: 461.077. Train acc: 0.465. Train Loss: 2053.581\n",
      "Step. time since epoch: 467.201. Train acc: 0.434. Train Loss: 2593.768\n",
      "Step. time since epoch: 473.356. Train acc: 0.500. Train Loss: 1642.996\n",
      "Step. time since epoch: 479.478. Train acc: 0.492. Train Loss: 2376.909\n",
      "Step. time since epoch: 485.681. Train acc: 0.527. Train Loss: 2565.260\n",
      "Step. time since epoch: 491.803. Train acc: 0.492. Train Loss: 2140.108\n",
      "Step. time since epoch: 497.926. Train acc: 0.531. Train Loss: 1387.198\n",
      "Step. time since epoch: 503.978. Train acc: 0.555. Train Loss: 1504.463\n",
      "Step. time since epoch: 510.089. Train acc: 0.473. Train Loss: 2030.032\n",
      "Step. time since epoch: 516.255. Train acc: 0.547. Train Loss: 1513.943\n",
      "Step. time since epoch: 522.765. Train acc: 0.496. Train Loss: 1666.458\n",
      "Step. time since epoch: 529.116. Train acc: 0.480. Train Loss: 2066.898\n",
      "Step. time since epoch: 535.258. Train acc: 0.562. Train Loss: 1609.886\n",
      "Step. time since epoch: 541.396. Train acc: 0.453. Train Loss: 1789.464\n",
      "Step. time since epoch: 547.546. Train acc: 0.504. Train Loss: 1643.541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 553.854. Train acc: 0.504. Train Loss: 1577.480\n",
      "Step. time since epoch: 559.960. Train acc: 0.508. Train Loss: 1623.658\n",
      "Step. time since epoch: 566.085. Train acc: 0.520. Train Loss: 1554.085\n",
      "Step. time since epoch: 572.538. Train acc: 0.465. Train Loss: 1604.521\n",
      "Step. time since epoch: 578.839. Train acc: 0.574. Train Loss: 1891.238\n",
      "Step. time since epoch: 585.207. Train acc: 0.539. Train Loss: 1695.064\n",
      "Step. time since epoch: 591.469. Train acc: 0.543. Train Loss: 1360.900\n",
      "Step. time since epoch: 597.564. Train acc: 0.414. Train Loss: 2151.937\n",
      "Step. time since epoch: 603.756. Train acc: 0.578. Train Loss: 1778.991\n",
      "Step. time since epoch: 610.003. Train acc: 0.543. Train Loss: 1614.856\n",
      "Step. time since epoch: 616.217. Train acc: 0.496. Train Loss: 3298.198\n",
      "Step. time since epoch: 622.307. Train acc: 0.531. Train Loss: 2565.429\n",
      "Step. time since epoch: 628.328. Train acc: 0.531. Train Loss: 2810.675\n",
      "Step. time since epoch: 634.553. Train acc: 0.430. Train Loss: 2241.082\n",
      "Step. time since epoch: 640.588. Train acc: 0.430. Train Loss: 2456.086\n",
      "Step. time since epoch: 646.816. Train acc: 0.465. Train Loss: 1759.821\n",
      "Step. time since epoch: 653.094. Train acc: 0.441. Train Loss: 1905.249\n",
      "Step. time since epoch: 659.415. Train acc: 0.441. Train Loss: 2994.311\n",
      "Step. time since epoch: 665.675. Train acc: 0.426. Train Loss: 2649.844\n",
      "Step. time since epoch: 672.016. Train acc: 0.465. Train Loss: 1948.004\n",
      "Step. time since epoch: 678.486. Train acc: 0.492. Train Loss: 1987.094\n",
      "Step. time since epoch: 684.818. Train acc: 0.449. Train Loss: 2328.542\n",
      "Step. time since epoch: 691.074. Train acc: 0.449. Train Loss: 2020.499\n",
      "Step. time since epoch: 697.409. Train acc: 0.523. Train Loss: 1648.654\n",
      "Step. time since epoch: 703.700. Train acc: 0.508. Train Loss: 1842.096\n",
      "Step. time since epoch: 710.291. Train acc: 0.516. Train Loss: 1467.374\n",
      "Step. time since epoch: 716.872. Train acc: 0.449. Train Loss: 1903.533\n",
      "Step. time since epoch: 723.091. Train acc: 0.531. Train Loss: 1801.868\n",
      "Step. time since epoch: 729.534. Train acc: 0.418. Train Loss: 2236.948\n",
      "Step. time since epoch: 735.705. Train acc: 0.441. Train Loss: 2181.059\n",
      "Step. time since epoch: 741.634. Train acc: 0.484. Train Loss: 2132.271\n",
      "Step. time since epoch: 747.462. Train acc: 0.449. Train Loss: 2165.398\n",
      "Step. time since epoch: 753.989. Train acc: 0.406. Train Loss: 2376.939\n",
      "Step. time since epoch: 760.112. Train acc: 0.445. Train Loss: 1870.840\n",
      "Step. time since epoch: 766.189. Train acc: 0.508. Train Loss: 2020.128\n",
      "Step. time since epoch: 772.300. Train acc: 0.457. Train Loss: 2409.048\n",
      "Step. time since epoch: 778.532. Train acc: 0.488. Train Loss: 2123.769\n",
      "Step. time since epoch: 784.778. Train acc: 0.555. Train Loss: 1257.348\n",
      "Step. time since epoch: 790.745. Train acc: 0.418. Train Loss: 2430.249\n",
      "Step. time since epoch: 796.901. Train acc: 0.500. Train Loss: 1667.340\n",
      "Step. time since epoch: 802.918. Train acc: 0.527. Train Loss: 1416.159\n",
      "Step. time since epoch: 808.970. Train acc: 0.449. Train Loss: 2118.514\n",
      "Step. time since epoch: 814.997. Train acc: 0.504. Train Loss: 1403.620\n",
      "Step. time since epoch: 821.126. Train acc: 0.508. Train Loss: 1719.786\n",
      "Step. time since epoch: 827.106. Train acc: 0.504. Train Loss: 1712.670\n",
      "Step. time since epoch: 833.932. Train acc: 0.523. Train Loss: 1353.669\n",
      "Step. time since epoch: 840.907. Train acc: 0.508. Train Loss: 1659.944\n",
      "Step. time since epoch: 846.987. Train acc: 0.562. Train Loss: 1175.774\n",
      "Step. time since epoch: 853.241. Train acc: 0.500. Train Loss: 1399.903\n",
      "Step. time since epoch: 859.216. Train acc: 0.551. Train Loss: 1252.467\n",
      "Step. time since epoch: 867.811. Train acc: 0.496. Train Loss: 1434.345\n",
      "Step. time since epoch: 875.145. Train acc: 0.543. Train Loss: 1379.907\n",
      "Step. time since epoch: 881.438. Train acc: 0.516. Train Loss: 1270.856\n",
      "Step. time since epoch: 887.686. Train acc: 0.434. Train Loss: 2083.252\n",
      "Step. time since epoch: 893.993. Train acc: 0.430. Train Loss: 1815.494\n",
      "Step. time since epoch: 901.408. Train acc: 0.465. Train Loss: 2220.810\n",
      "Step. time since epoch: 907.654. Train acc: 0.461. Train Loss: 2597.705\n",
      "Step. time since epoch: 914.171. Train acc: 0.453. Train Loss: 1692.126\n",
      "Step. time since epoch: 920.491. Train acc: 0.508. Train Loss: 1694.495\n",
      "Step. time since epoch: 926.797. Train acc: 0.426. Train Loss: 2580.667\n",
      "Step. time since epoch: 932.925. Train acc: 0.465. Train Loss: 1871.541\n",
      "Step. time since epoch: 939.189. Train acc: 0.449. Train Loss: 2107.644\n",
      "Step. time since epoch: 945.336. Train acc: 0.398. Train Loss: 2496.321\n",
      "Step. time since epoch: 951.904. Train acc: 0.469. Train Loss: 1785.420\n",
      "Step. time since epoch: 958.102. Train acc: 0.512. Train Loss: 1660.083\n",
      "Step. time since epoch: 964.225. Train acc: 0.434. Train Loss: 2565.021\n",
      "Step. time since epoch: 970.408. Train acc: 0.438. Train Loss: 1738.958\n",
      "Step. time since epoch: 976.609. Train acc: 0.539. Train Loss: 1643.816\n",
      "Step. time since epoch: 982.861. Train acc: 0.414. Train Loss: 2152.122\n",
      "Step. time since epoch: 988.993. Train acc: 0.512. Train Loss: 1172.104\n",
      "Step. time since epoch: 995.122. Train acc: 0.516. Train Loss: 1526.269\n",
      "Step. time since epoch: 1001.340. Train acc: 0.512. Train Loss: 1512.924\n",
      "Step. time since epoch: 1007.745. Train acc: 0.465. Train Loss: 1555.604\n",
      "Step. time since epoch: 1014.600. Train acc: 0.500. Train Loss: 1666.499\n",
      "Step. time since epoch: 1021.227. Train acc: 0.492. Train Loss: 1347.043\n",
      "Step. time since epoch: 1027.967. Train acc: 0.441. Train Loss: 1898.972\n",
      "Step. time since epoch: 1034.666. Train acc: 0.520. Train Loss: 1312.026\n",
      "Step. time since epoch: 1041.377. Train acc: 0.500. Train Loss: 1540.965\n",
      "Step. time since epoch: 1048.105. Train acc: 0.500. Train Loss: 1462.118\n",
      "Step. time since epoch: 1054.394. Train acc: 0.566. Train Loss: 1156.218\n",
      "Step. time since epoch: 1060.544. Train acc: 0.492. Train Loss: 1624.488\n",
      "Step. time since epoch: 1066.667. Train acc: 0.508. Train Loss: 1281.946\n",
      "Step. time since epoch: 1072.858. Train acc: 0.461. Train Loss: 1868.144\n",
      "Step. time since epoch: 1078.995. Train acc: 0.496. Train Loss: 1626.289\n",
      "Step. time since epoch: 1085.280. Train acc: 0.461. Train Loss: 1900.125\n",
      "Step. time since epoch: 1091.549. Train acc: 0.457. Train Loss: 1783.464\n",
      "Step. time since epoch: 1097.674. Train acc: 0.434. Train Loss: 1987.310\n",
      "Step. time since epoch: 1103.832. Train acc: 0.477. Train Loss: 1871.143\n",
      "Step. time since epoch: 1110.252. Train acc: 0.445. Train Loss: 1632.165\n",
      "Step. time since epoch: 1116.575. Train acc: 0.434. Train Loss: 2083.567\n",
      "Step. time since epoch: 1122.906. Train acc: 0.500. Train Loss: 1520.984\n",
      "Step. time since epoch: 1129.155. Train acc: 0.477. Train Loss: 1715.722\n",
      "Step. time since epoch: 1135.577. Train acc: 0.430. Train Loss: 2407.560\n",
      "Step. time since epoch: 1141.789. Train acc: 0.395. Train Loss: 2784.406\n",
      "Step. time since epoch: 1147.924. Train acc: 0.504. Train Loss: 2020.377\n",
      "Step. time since epoch: 1154.019. Train acc: 0.336. Train Loss: 2970.955\n",
      "Step. time since epoch: 1160.128. Train acc: 0.453. Train Loss: 2841.499\n",
      "Step. time since epoch: 1166.223. Train acc: 0.539. Train Loss: 1365.032\n",
      "Step. time since epoch: 1172.277. Train acc: 0.512. Train Loss: 1809.666\n",
      "Step. time since epoch: 1178.452. Train acc: 0.332. Train Loss: 3316.368\n",
      "Step. time since epoch: 1184.809. Train acc: 0.477. Train Loss: 2062.038\n",
      "Step. time since epoch: 1191.026. Train acc: 0.445. Train Loss: 2379.111\n",
      "Step. time since epoch: 1197.276. Train acc: 0.465. Train Loss: 3188.880\n",
      "Step. time since epoch: 1203.648. Train acc: 0.445. Train Loss: 2587.575\n",
      "Step. time since epoch: 1210.004. Train acc: 0.426. Train Loss: 2209.197\n",
      "Step. time since epoch: 1216.429. Train acc: 0.457. Train Loss: 2192.010\n",
      "Step. time since epoch: 1222.695. Train acc: 0.414. Train Loss: 2141.261\n",
      "Step. time since epoch: 1229.846. Train acc: 0.457. Train Loss: 1733.397\n",
      "Step. time since epoch: 1239.196. Train acc: 0.434. Train Loss: 1998.410\n",
      "Step. time since epoch: 1247.855. Train acc: 0.336. Train Loss: 2705.672\n",
      "Step. time since epoch: 1254.931. Train acc: 0.461. Train Loss: 2728.556\n",
      "Step. time since epoch: 1261.078. Train acc: 0.457. Train Loss: 3107.323\n",
      "Step. time since epoch: 1267.472. Train acc: 0.422. Train Loss: 3067.968\n",
      "Step. time since epoch: 1273.768. Train acc: 0.453. Train Loss: 2493.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1280.235. Train acc: 0.441. Train Loss: 1886.594\n",
      "Step. time since epoch: 1286.571. Train acc: 0.383. Train Loss: 2489.099\n",
      "Step. time since epoch: 1292.875. Train acc: 0.379. Train Loss: 2492.407\n",
      "Step. time since epoch: 1299.113. Train acc: 0.477. Train Loss: 1595.749\n",
      "Step. time since epoch: 1305.407. Train acc: 0.414. Train Loss: 2477.797\n",
      "Step. time since epoch: 1311.741. Train acc: 0.344. Train Loss: 4286.944\n",
      "Step. time since epoch: 1318.304. Train acc: 0.441. Train Loss: 2826.498\n",
      "Step. time since epoch: 1324.459. Train acc: 0.406. Train Loss: 4352.468\n",
      "Step. time since epoch: 1330.930. Train acc: 0.418. Train Loss: 4570.796\n",
      "Step. time since epoch: 1337.494. Train acc: 0.453. Train Loss: 3540.980\n",
      "Step. time since epoch: 1343.799. Train acc: 0.449. Train Loss: 2324.173\n",
      "Step. time since epoch: 1350.213. Train acc: 0.387. Train Loss: 2624.482\n",
      "Step. time since epoch: 1356.870. Train acc: 0.488. Train Loss: 1636.861\n",
      "Step. time since epoch: 1362.817. Train acc: 0.312. Train Loss: 4050.919\n",
      "Step. time since epoch: 1368.914. Train acc: 0.383. Train Loss: 2965.670\n",
      "Step. time since epoch: 1374.828. Train acc: 0.445. Train Loss: 3059.057\n",
      "Step. time since epoch: 1380.672. Train acc: 0.469. Train Loss: 3125.552\n",
      "Step. time since epoch: 1386.619. Train acc: 0.387. Train Loss: 4504.306\n",
      "Step. time since epoch: 1392.466. Train acc: 0.375. Train Loss: 4380.085\n",
      "Step. time since epoch: 1398.295. Train acc: 0.430. Train Loss: 3113.693\n",
      "Step. time since epoch: 1404.151. Train acc: 0.469. Train Loss: 2662.397\n",
      "Step. time since epoch: 1410.031. Train acc: 0.355. Train Loss: 4230.063\n",
      "Step. time since epoch: 1415.828. Train acc: 0.438. Train Loss: 2466.372\n",
      "Step. time since epoch: 1421.796. Train acc: 0.379. Train Loss: 3283.131\n",
      "Step. time since epoch: 1427.632. Train acc: 0.430. Train Loss: 2569.118\n",
      "Step. time since epoch: 1433.493. Train acc: 0.359. Train Loss: 3230.743\n",
      "Step. time since epoch: 1439.376. Train acc: 0.441. Train Loss: 2670.741\n",
      "Step. time since epoch: 1445.242. Train acc: 0.422. Train Loss: 2090.869\n",
      "Step. time since epoch: 1451.056. Train acc: 0.484. Train Loss: 2157.470\n",
      "Step. time since epoch: 1456.871. Train acc: 0.480. Train Loss: 2034.552\n",
      "Step. time since epoch: 1462.759. Train acc: 0.449. Train Loss: 2026.642\n",
      "Step. time since epoch: 1464.994. Train acc: 0.354. Train Loss: 882.831\n",
      "epoch 4, loss 9.1669, train acc 0.459, test acc 0.413, time 1694.0 sec\n",
      "Step. time since epoch: 5.783. Train acc: 0.418. Train Loss: 2476.540\n",
      "Step. time since epoch: 11.555. Train acc: 0.508. Train Loss: 1884.607\n",
      "Step. time since epoch: 17.345. Train acc: 0.547. Train Loss: 1475.564\n",
      "Step. time since epoch: 23.081. Train acc: 0.480. Train Loss: 2095.695\n",
      "Step. time since epoch: 28.946. Train acc: 0.422. Train Loss: 2072.280\n",
      "Step. time since epoch: 34.771. Train acc: 0.484. Train Loss: 1756.365\n",
      "Step. time since epoch: 40.651. Train acc: 0.453. Train Loss: 2294.421\n",
      "Step. time since epoch: 46.473. Train acc: 0.438. Train Loss: 1688.814\n",
      "Step. time since epoch: 52.293. Train acc: 0.445. Train Loss: 2031.159\n",
      "Step. time since epoch: 58.058. Train acc: 0.414. Train Loss: 2330.323\n",
      "Step. time since epoch: 64.433. Train acc: 0.391. Train Loss: 3083.505\n",
      "Step. time since epoch: 70.883. Train acc: 0.480. Train Loss: 2165.014\n",
      "Step. time since epoch: 76.940. Train acc: 0.488. Train Loss: 1945.284\n",
      "Step. time since epoch: 82.825. Train acc: 0.426. Train Loss: 2678.970\n",
      "Step. time since epoch: 88.766. Train acc: 0.402. Train Loss: 3423.541\n",
      "Step. time since epoch: 94.684. Train acc: 0.344. Train Loss: 3634.424\n",
      "Step. time since epoch: 100.661. Train acc: 0.484. Train Loss: 2940.476\n",
      "Step. time since epoch: 106.552. Train acc: 0.457. Train Loss: 3056.182\n",
      "Step. time since epoch: 112.447. Train acc: 0.391. Train Loss: 3339.980\n",
      "Step. time since epoch: 118.290. Train acc: 0.465. Train Loss: 2893.477\n",
      "Step. time since epoch: 124.114. Train acc: 0.402. Train Loss: 3628.349\n",
      "Step. time since epoch: 129.971. Train acc: 0.488. Train Loss: 2320.357\n",
      "Step. time since epoch: 135.955. Train acc: 0.480. Train Loss: 2181.748\n",
      "Step. time since epoch: 141.818. Train acc: 0.465. Train Loss: 2731.237\n",
      "Step. time since epoch: 147.638. Train acc: 0.438. Train Loss: 3340.794\n",
      "Step. time since epoch: 153.524. Train acc: 0.445. Train Loss: 2736.007\n",
      "Step. time since epoch: 159.438. Train acc: 0.535. Train Loss: 1615.781\n",
      "Step. time since epoch: 165.374. Train acc: 0.438. Train Loss: 3817.691\n",
      "Step. time since epoch: 171.208. Train acc: 0.434. Train Loss: 3036.138\n",
      "Step. time since epoch: 177.022. Train acc: 0.484. Train Loss: 2704.546\n",
      "Step. time since epoch: 182.870. Train acc: 0.453. Train Loss: 2287.135\n",
      "Step. time since epoch: 188.978. Train acc: 0.477. Train Loss: 2374.299\n",
      "Step. time since epoch: 194.845. Train acc: 0.398. Train Loss: 3390.362\n",
      "Step. time since epoch: 200.698. Train acc: 0.500. Train Loss: 2126.775\n",
      "Step. time since epoch: 206.544. Train acc: 0.434. Train Loss: 2241.153\n",
      "Step. time since epoch: 212.436. Train acc: 0.434. Train Loss: 3065.005\n",
      "Step. time since epoch: 218.294. Train acc: 0.461. Train Loss: 2712.332\n",
      "Step. time since epoch: 224.182. Train acc: 0.461. Train Loss: 2705.127\n",
      "Step. time since epoch: 230.008. Train acc: 0.410. Train Loss: 2854.033\n",
      "Step. time since epoch: 235.836. Train acc: 0.484. Train Loss: 2421.069\n",
      "Step. time since epoch: 241.683. Train acc: 0.508. Train Loss: 1967.266\n",
      "Step. time since epoch: 247.516. Train acc: 0.441. Train Loss: 2378.810\n",
      "Step. time since epoch: 253.373. Train acc: 0.430. Train Loss: 2307.247\n",
      "Step. time since epoch: 259.270. Train acc: 0.465. Train Loss: 2177.623\n",
      "Step. time since epoch: 265.046. Train acc: 0.430. Train Loss: 2306.479\n",
      "Step. time since epoch: 270.900. Train acc: 0.477. Train Loss: 2400.584\n",
      "Step. time since epoch: 276.718. Train acc: 0.488. Train Loss: 2237.712\n",
      "Step. time since epoch: 282.565. Train acc: 0.543. Train Loss: 2032.111\n",
      "Step. time since epoch: 288.441. Train acc: 0.461. Train Loss: 1953.435\n",
      "Step. time since epoch: 294.333. Train acc: 0.516. Train Loss: 2182.047\n",
      "Step. time since epoch: 300.186. Train acc: 0.586. Train Loss: 1482.262\n",
      "Step. time since epoch: 306.002. Train acc: 0.449. Train Loss: 2159.153\n",
      "Step. time since epoch: 311.860. Train acc: 0.449. Train Loss: 2268.744\n",
      "Step. time since epoch: 317.762. Train acc: 0.535. Train Loss: 1575.936\n",
      "Step. time since epoch: 323.606. Train acc: 0.539. Train Loss: 1238.319\n",
      "Step. time since epoch: 329.479. Train acc: 0.449. Train Loss: 2334.862\n",
      "Step. time since epoch: 335.349. Train acc: 0.504. Train Loss: 1879.018\n",
      "Step. time since epoch: 341.381. Train acc: 0.512. Train Loss: 1975.865\n",
      "Step. time since epoch: 347.241. Train acc: 0.508. Train Loss: 2506.472\n",
      "Step. time since epoch: 353.387. Train acc: 0.555. Train Loss: 2265.850\n",
      "Step. time since epoch: 359.247. Train acc: 0.504. Train Loss: 1921.467\n",
      "Step. time since epoch: 365.076. Train acc: 0.473. Train Loss: 1713.307\n",
      "Step. time since epoch: 370.924. Train acc: 0.441. Train Loss: 2798.497\n",
      "Step. time since epoch: 376.803. Train acc: 0.461. Train Loss: 2044.788\n",
      "Step. time since epoch: 382.605. Train acc: 0.516. Train Loss: 2106.134\n",
      "Step. time since epoch: 388.490. Train acc: 0.492. Train Loss: 2616.414\n",
      "Step. time since epoch: 394.420. Train acc: 0.500. Train Loss: 2068.930\n",
      "Step. time since epoch: 400.250. Train acc: 0.531. Train Loss: 1555.475\n",
      "Step. time since epoch: 406.086. Train acc: 0.344. Train Loss: 2574.009\n",
      "Step. time since epoch: 411.956. Train acc: 0.496. Train Loss: 1940.234\n",
      "Step. time since epoch: 417.820. Train acc: 0.453. Train Loss: 2615.064\n",
      "Step. time since epoch: 423.620. Train acc: 0.504. Train Loss: 2523.746\n",
      "Step. time since epoch: 429.455. Train acc: 0.508. Train Loss: 1669.540\n",
      "Step. time since epoch: 435.261. Train acc: 0.492. Train Loss: 1736.398\n",
      "Step. time since epoch: 441.118. Train acc: 0.426. Train Loss: 2551.541\n",
      "Step. time since epoch: 446.938. Train acc: 0.461. Train Loss: 2348.689\n",
      "Step. time since epoch: 452.796. Train acc: 0.543. Train Loss: 1616.483\n",
      "Step. time since epoch: 458.643. Train acc: 0.434. Train Loss: 2215.995\n",
      "Step. time since epoch: 464.496. Train acc: 0.426. Train Loss: 1882.699\n",
      "Step. time since epoch: 470.347. Train acc: 0.523. Train Loss: 1684.166\n",
      "Step. time since epoch: 476.353. Train acc: 0.523. Train Loss: 1635.885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 482.214. Train acc: 0.613. Train Loss: 1112.208\n",
      "Step. time since epoch: 488.129. Train acc: 0.504. Train Loss: 1451.801\n",
      "Step. time since epoch: 493.992. Train acc: 0.492. Train Loss: 1535.566\n",
      "Step. time since epoch: 499.857. Train acc: 0.566. Train Loss: 1347.285\n",
      "Step. time since epoch: 505.721. Train acc: 0.516. Train Loss: 1216.243\n",
      "Step. time since epoch: 511.566. Train acc: 0.547. Train Loss: 1441.463\n",
      "Step. time since epoch: 517.426. Train acc: 0.465. Train Loss: 1625.849\n",
      "Step. time since epoch: 523.330. Train acc: 0.484. Train Loss: 1478.458\n",
      "Step. time since epoch: 529.171. Train acc: 0.449. Train Loss: 1372.922\n",
      "Step. time since epoch: 535.060. Train acc: 0.520. Train Loss: 1414.431\n",
      "Step. time since epoch: 540.863. Train acc: 0.469. Train Loss: 1619.269\n",
      "Step. time since epoch: 546.731. Train acc: 0.543. Train Loss: 1073.806\n",
      "Step. time since epoch: 552.554. Train acc: 0.512. Train Loss: 1503.774\n",
      "Step. time since epoch: 558.426. Train acc: 0.484. Train Loss: 1519.923\n",
      "Step. time since epoch: 564.308. Train acc: 0.484. Train Loss: 1529.069\n",
      "Step. time since epoch: 570.286. Train acc: 0.453. Train Loss: 1979.277\n",
      "Step. time since epoch: 576.219. Train acc: 0.547. Train Loss: 991.340\n",
      "Step. time since epoch: 582.087. Train acc: 0.445. Train Loss: 1635.682\n",
      "Step. time since epoch: 587.922. Train acc: 0.461. Train Loss: 1530.165\n",
      "Step. time since epoch: 593.786. Train acc: 0.531. Train Loss: 1430.022\n",
      "Step. time since epoch: 599.630. Train acc: 0.543. Train Loss: 1667.222\n",
      "Step. time since epoch: 605.425. Train acc: 0.434. Train Loss: 2094.977\n",
      "Step. time since epoch: 611.251. Train acc: 0.488. Train Loss: 1647.875\n",
      "Step. time since epoch: 617.111. Train acc: 0.484. Train Loss: 1850.872\n",
      "Step. time since epoch: 622.906. Train acc: 0.508. Train Loss: 1514.328\n",
      "Step. time since epoch: 628.748. Train acc: 0.543. Train Loss: 1466.699\n",
      "Step. time since epoch: 634.627. Train acc: 0.434. Train Loss: 2069.296\n",
      "Step. time since epoch: 640.456. Train acc: 0.488. Train Loss: 1255.415\n",
      "Step. time since epoch: 646.271. Train acc: 0.508. Train Loss: 1562.694\n",
      "Step. time since epoch: 652.090. Train acc: 0.445. Train Loss: 1664.222\n",
      "Step. time since epoch: 657.922. Train acc: 0.445. Train Loss: 1903.241\n",
      "Step. time since epoch: 664.315. Train acc: 0.480. Train Loss: 2071.441\n",
      "Step. time since epoch: 670.213. Train acc: 0.473. Train Loss: 2004.608\n",
      "Step. time since epoch: 677.023. Train acc: 0.504. Train Loss: 1715.805\n",
      "Step. time since epoch: 683.775. Train acc: 0.406. Train Loss: 2392.683\n",
      "Step. time since epoch: 689.739. Train acc: 0.516. Train Loss: 1333.179\n",
      "Step. time since epoch: 695.654. Train acc: 0.355. Train Loss: 2578.494\n",
      "Step. time since epoch: 702.369. Train acc: 0.418. Train Loss: 3261.968\n",
      "Step. time since epoch: 709.481. Train acc: 0.434. Train Loss: 3272.393\n",
      "Step. time since epoch: 715.944. Train acc: 0.449. Train Loss: 4256.444\n",
      "Step. time since epoch: 722.414. Train acc: 0.422. Train Loss: 4235.046\n",
      "Step. time since epoch: 728.728. Train acc: 0.344. Train Loss: 4295.710\n",
      "Step. time since epoch: 735.202. Train acc: 0.496. Train Loss: 2312.169\n",
      "Step. time since epoch: 741.429. Train acc: 0.473. Train Loss: 2014.774\n",
      "Step. time since epoch: 747.536. Train acc: 0.293. Train Loss: 3659.354\n",
      "Step. time since epoch: 753.671. Train acc: 0.406. Train Loss: 3170.757\n",
      "Step. time since epoch: 759.792. Train acc: 0.348. Train Loss: 3510.527\n",
      "Step. time since epoch: 766.077. Train acc: 0.309. Train Loss: 5033.429\n",
      "Step. time since epoch: 772.486. Train acc: 0.449. Train Loss: 3893.382\n",
      "Step. time since epoch: 778.928. Train acc: 0.324. Train Loss: 4777.582\n",
      "Step. time since epoch: 785.362. Train acc: 0.387. Train Loss: 3524.695\n",
      "Step. time since epoch: 791.323. Train acc: 0.434. Train Loss: 2741.645\n",
      "Step. time since epoch: 797.259. Train acc: 0.387. Train Loss: 2624.108\n",
      "Step. time since epoch: 803.615. Train acc: 0.246. Train Loss: 4262.412\n",
      "Step. time since epoch: 810.156. Train acc: 0.230. Train Loss: 4495.472\n",
      "Step. time since epoch: 816.477. Train acc: 0.434. Train Loss: 2520.363\n",
      "Step. time since epoch: 822.563. Train acc: 0.480. Train Loss: 3206.496\n",
      "Step. time since epoch: 829.072. Train acc: 0.449. Train Loss: 3942.403\n",
      "Step. time since epoch: 835.228. Train acc: 0.434. Train Loss: 4352.273\n",
      "Step. time since epoch: 841.562. Train acc: 0.402. Train Loss: 3949.005\n",
      "Step. time since epoch: 847.748. Train acc: 0.457. Train Loss: 2790.132\n",
      "Step. time since epoch: 854.109. Train acc: 0.539. Train Loss: 1908.077\n",
      "Step. time since epoch: 860.244. Train acc: 0.477. Train Loss: 2089.645\n",
      "Step. time since epoch: 866.405. Train acc: 0.398. Train Loss: 2870.919\n",
      "Step. time since epoch: 872.621. Train acc: 0.402. Train Loss: 2844.042\n",
      "Step. time since epoch: 878.764. Train acc: 0.426. Train Loss: 2785.640\n",
      "Step. time since epoch: 884.966. Train acc: 0.434. Train Loss: 2869.087\n",
      "Step. time since epoch: 891.321. Train acc: 0.492. Train Loss: 1754.973\n",
      "Step. time since epoch: 897.634. Train acc: 0.441. Train Loss: 2361.376\n",
      "Step. time since epoch: 904.062. Train acc: 0.395. Train Loss: 2820.586\n",
      "Step. time since epoch: 910.473. Train acc: 0.469. Train Loss: 2625.645\n",
      "Step. time since epoch: 916.657. Train acc: 0.523. Train Loss: 1866.443\n",
      "Step. time since epoch: 922.960. Train acc: 0.484. Train Loss: 2243.693\n",
      "Step. time since epoch: 929.053. Train acc: 0.352. Train Loss: 2984.737\n",
      "Step. time since epoch: 935.433. Train acc: 0.457. Train Loss: 2192.727\n",
      "Step. time since epoch: 941.694. Train acc: 0.496. Train Loss: 2429.961\n",
      "Step. time since epoch: 948.081. Train acc: 0.406. Train Loss: 3584.595\n",
      "Step. time since epoch: 954.304. Train acc: 0.449. Train Loss: 3614.382\n",
      "Step. time since epoch: 960.361. Train acc: 0.457. Train Loss: 3780.813\n",
      "Step. time since epoch: 966.656. Train acc: 0.414. Train Loss: 3996.621\n",
      "Step. time since epoch: 972.892. Train acc: 0.414. Train Loss: 3613.998\n",
      "Step. time since epoch: 979.041. Train acc: 0.402. Train Loss: 2773.579\n",
      "Step. time since epoch: 985.195. Train acc: 0.391. Train Loss: 3880.596\n",
      "Step. time since epoch: 991.430. Train acc: 0.414. Train Loss: 3569.436\n",
      "Step. time since epoch: 997.924. Train acc: 0.402. Train Loss: 3363.568\n",
      "Step. time since epoch: 1004.144. Train acc: 0.418. Train Loss: 3409.273\n",
      "Step. time since epoch: 1010.515. Train acc: 0.398. Train Loss: 4979.006\n",
      "Step. time since epoch: 1017.132. Train acc: 0.359. Train Loss: 5018.208\n",
      "Step. time since epoch: 1023.417. Train acc: 0.406. Train Loss: 4098.422\n",
      "Step. time since epoch: 1029.533. Train acc: 0.492. Train Loss: 3059.534\n",
      "Step. time since epoch: 1035.600. Train acc: 0.359. Train Loss: 4430.573\n",
      "Step. time since epoch: 1041.856. Train acc: 0.496. Train Loss: 2315.008\n",
      "Step. time since epoch: 1048.337. Train acc: 0.441. Train Loss: 3282.406\n",
      "Step. time since epoch: 1054.450. Train acc: 0.543. Train Loss: 2369.056\n",
      "Step. time since epoch: 1060.589. Train acc: 0.375. Train Loss: 3279.703\n",
      "Step. time since epoch: 1067.001. Train acc: 0.426. Train Loss: 2773.712\n",
      "Step. time since epoch: 1073.108. Train acc: 0.578. Train Loss: 1341.541\n",
      "Step. time since epoch: 1079.350. Train acc: 0.469. Train Loss: 2692.692\n",
      "Step. time since epoch: 1085.921. Train acc: 0.484. Train Loss: 2845.437\n",
      "Step. time since epoch: 1092.153. Train acc: 0.496. Train Loss: 1956.376\n",
      "Step. time since epoch: 1098.007. Train acc: 0.492. Train Loss: 2127.979\n",
      "Step. time since epoch: 1103.811. Train acc: 0.492. Train Loss: 2352.376\n",
      "Step. time since epoch: 1109.710. Train acc: 0.473. Train Loss: 2148.647\n",
      "Step. time since epoch: 1115.542. Train acc: 0.516. Train Loss: 1733.795\n",
      "Step. time since epoch: 1121.353. Train acc: 0.504. Train Loss: 2195.894\n",
      "Step. time since epoch: 1127.184. Train acc: 0.555. Train Loss: 1955.586\n",
      "Step. time since epoch: 1133.025. Train acc: 0.586. Train Loss: 1326.671\n",
      "Step. time since epoch: 1138.875. Train acc: 0.449. Train Loss: 2280.836\n",
      "Step. time since epoch: 1144.690. Train acc: 0.500. Train Loss: 2060.626\n",
      "Step. time since epoch: 1150.527. Train acc: 0.406. Train Loss: 2466.788\n",
      "Step. time since epoch: 1156.339. Train acc: 0.500. Train Loss: 1999.138\n",
      "Step. time since epoch: 1162.527. Train acc: 0.523. Train Loss: 2034.868\n",
      "Step. time since epoch: 1168.826. Train acc: 0.484. Train Loss: 2998.586\n",
      "Step. time since epoch: 1174.751. Train acc: 0.531. Train Loss: 2114.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1180.594. Train acc: 0.520. Train Loss: 2058.463\n",
      "Step. time since epoch: 1186.540. Train acc: 0.520. Train Loss: 1510.514\n",
      "Step. time since epoch: 1192.394. Train acc: 0.441. Train Loss: 1849.682\n",
      "Step. time since epoch: 1198.224. Train acc: 0.457. Train Loss: 1955.330\n",
      "Step. time since epoch: 1204.061. Train acc: 0.480. Train Loss: 1732.397\n",
      "Step. time since epoch: 1209.913. Train acc: 0.449. Train Loss: 2448.866\n",
      "Step. time since epoch: 1215.669. Train acc: 0.461. Train Loss: 2695.646\n",
      "Step. time since epoch: 1221.617. Train acc: 0.516. Train Loss: 1917.536\n",
      "Step. time since epoch: 1227.528. Train acc: 0.566. Train Loss: 1348.324\n",
      "Step. time since epoch: 1233.565. Train acc: 0.430. Train Loss: 2203.862\n",
      "Step. time since epoch: 1239.473. Train acc: 0.531. Train Loss: 1396.080\n",
      "Step. time since epoch: 1245.393. Train acc: 0.445. Train Loss: 1687.426\n",
      "Step. time since epoch: 1251.310. Train acc: 0.426. Train Loss: 2077.991\n",
      "Step. time since epoch: 1257.112. Train acc: 0.449. Train Loss: 1972.065\n",
      "Step. time since epoch: 1263.319. Train acc: 0.508. Train Loss: 1879.843\n",
      "Step. time since epoch: 1269.215. Train acc: 0.508. Train Loss: 1793.400\n",
      "Step. time since epoch: 1275.037. Train acc: 0.473. Train Loss: 1983.753\n",
      "Step. time since epoch: 1280.934. Train acc: 0.516. Train Loss: 1622.334\n",
      "Step. time since epoch: 1286.752. Train acc: 0.504. Train Loss: 1920.637\n",
      "Step. time since epoch: 1292.616. Train acc: 0.461. Train Loss: 1992.925\n",
      "Step. time since epoch: 1298.420. Train acc: 0.438. Train Loss: 2103.499\n",
      "Step. time since epoch: 1304.223. Train acc: 0.422. Train Loss: 2508.569\n",
      "Step. time since epoch: 1310.075. Train acc: 0.391. Train Loss: 3051.345\n",
      "Step. time since epoch: 1315.924. Train acc: 0.512. Train Loss: 2108.880\n",
      "Step. time since epoch: 1321.747. Train acc: 0.480. Train Loss: 2277.287\n",
      "Step. time since epoch: 1327.583. Train acc: 0.539. Train Loss: 1954.112\n",
      "Step. time since epoch: 1333.423. Train acc: 0.465. Train Loss: 2568.977\n",
      "Step. time since epoch: 1339.278. Train acc: 0.461. Train Loss: 2419.403\n",
      "Step. time since epoch: 1345.045. Train acc: 0.504. Train Loss: 2019.648\n",
      "Step. time since epoch: 1350.916. Train acc: 0.488. Train Loss: 2268.050\n",
      "Step. time since epoch: 1356.785. Train acc: 0.461. Train Loss: 2742.626\n",
      "Step. time since epoch: 1362.652. Train acc: 0.449. Train Loss: 2422.574\n",
      "Step. time since epoch: 1368.689. Train acc: 0.508. Train Loss: 2333.621\n",
      "Step. time since epoch: 1374.599. Train acc: 0.508. Train Loss: 2516.724\n",
      "Step. time since epoch: 1380.585. Train acc: 0.477. Train Loss: 2671.758\n",
      "Step. time since epoch: 1386.972. Train acc: 0.496. Train Loss: 1942.087\n",
      "Step. time since epoch: 1393.119. Train acc: 0.496. Train Loss: 2156.077\n",
      "Step. time since epoch: 1399.801. Train acc: 0.410. Train Loss: 2932.081\n",
      "Step. time since epoch: 1406.553. Train acc: 0.426. Train Loss: 2826.643\n",
      "Step. time since epoch: 1408.880. Train acc: 0.448. Train Loss: 786.859\n",
      "epoch 5, loss 9.4307, train acc 0.464, test acc 0.419, time 1643.5 sec\n"
     ]
    }
   ],
   "source": [
    "train(model_resnet, train_iter, test_iter, optimizer_ft, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо своими \"Улучшениями\" я все испортил. Качество ужасное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
